{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36c0621390c0191cdb1fd134b5a32cdb",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem Set 5 - K-Means, SVM , Neural Networks, and Q-learning\n",
    "## CSCI 5622 - Spring 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Name**: $<$insert name here$>$\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "954b4e0f40c950adf0cee100802f90c9",
     "grade": false,
     "grade_id": "syllabus",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This assignment is due on Canvas by **11.59 PM on Wednesday, April 27th**.\n",
    "Submit only this Jupyter notebook to Canvas. Do not compress it using tar, rar, zip, etc.\n",
    "The last bonus problem will require additional files to be submitted. We'll explain its submission format later.\n",
    "\n",
    "Your solutions to analysis questions should be done in Markdown directly below the associated question.\n",
    "Remember that you are encouraged to discuss the problems with your classmates and instructors,\n",
    "but **you must write all code and solutions on your own**, and list any people or sources consulted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt #uncomment to install all required packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tests\n",
    "import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "794849a95b638c6c9cfed4aaac65d84d",
     "grade": false,
     "grade_id": "dataset_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment Setup\n",
    "\n",
    "For this problem set, we'll be using three synthetic datasets plotted below. From left to right: co-centric circles `circles`, blobs with 5 centers `multi_blobs`, and blobs with 2 centers `binary_blobs`.\n",
    "\n",
    "Each of the dataset instances has (`X`, `labels`) attributes that are split into `train` and `test` partitions.\n",
    "In the first problem, we'll be implementing K-means and evaluate it on the `multi_blobs` data.\n",
    "In the second problem, we'll be implementing Support Vector Machines (SVM) with the kernel trick and test it on `circles` and `binary_blobs`.\n",
    "And in the last problem, we'll implement our Multi-Layer Perceptron from scratch and test it on the `circles` dataset.\n",
    "\n",
    "All different problems are entirely independent and could be solved in any order you deem fitting.\n",
    "\n",
    "For this semester, we've also added a bonus problem on deep reinforcement learning (Deep Q-Learning) to get you familiar with its concepts and some of its practical limitations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c47fc79669905f45e67afacb364828ae",
     "grade": false,
     "grade_id": "dataset_plots",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Do not modify this cell\n",
    "circles = data.Circles()\n",
    "multi_blobs = data.DataBlobs(centers=5, std=1.5)\n",
    "binary_blobs = data.DataBlobs(centers=2, std=2.5)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "fig.set_figheight(4), fig.set_figwidth(14)\n",
    "for i, (dataset, name) in enumerate([(circles, \"Co-centric circles\"),\n",
    "                                     (multi_blobs, \"multi-blobs\"),\n",
    "                                     (binary_blobs, \"binary blobs\")]):\n",
    "    axs[i].set_title(name)\n",
    "    axs[i].scatter(dataset.X[:, 0], dataset.X[:, 1], c=dataset.labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95a5f6ad05319cf49aaecdf5afe86c45",
     "grade": false,
     "grade_id": "k_means_intro",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem 1 : K-means (30 points)\n",
    "\n",
    "The goal of K-means is to partition the data into $k$ clusters such that the sum of intra-cluster variances is minimal.\n",
    "We will be using Euclidean distance as our variance measure, so for cluster $C_i = \\{x_1,x_2,... x_{m_i}\\}$, its intra-cluster variance $V(C_i)$ is defined as:\n",
    "\n",
    "$$\n",
    "V(C_i) = \\sum_{j=1}^{m_i} ||x_j - \\mu_i||^2\n",
    "$$\n",
    "\n",
    "where $\\mu_i = \\frac{1}{m} \\sum_{i=1}^{m_i} x_i$. $\\mu_i$ is called the centroid of cluster $C_i$.\n",
    "\n",
    "So for $k$ clusters, K-means objective is:\n",
    "$$\n",
    "\\min_{C_1,C_2\\ldots C_k}\\sum_{i=1}^{k}V(C_i) = \\min_{C_1,C_2\\ldots C_k} \\sum_{i=1}^{k} \\sum_{j=1}^{m_i} ||x_j - \\mu_i||^2\n",
    "$$\n",
    "\n",
    "Each sample $x_i$ is assigned to the cluster of the closest centroid. Hence, finding the optimal partition $\\{C_1,C_2...C_k\\}$ that minimizes the objective is equivalent to finding the optimal centroids.\n",
    "\n",
    "Unfortunately, there is no algorithm that reaches the global optima for K-means, but we'll be implementing the most famous heuristic for the problem: Llyod algorithm. It works as follows:\n",
    "\n",
    "- Initialize the centroids with **unique** random samples (`initialize_centroids`), initial objective = $+\\infty$\n",
    "- Repeat until convergence:\n",
    "    - Compute the distances matrix $D$ between samples and centroids (`compute_distances`)\n",
    "    - Use $D$ to assign each sample to the cluster with the closest centroid (`computes_assignments`)\n",
    "    - Update the centroids as centers of the new cluster assignments (`compute_centroids`)\n",
    "    - Compute the new objective (`compute_objective`)\n",
    "    - Stop if the improvement ratio of the objective is less than $\\epsilon$\n",
    "\n",
    "The improvement ratio equal to `|new_objective - previous_objective|/|previous_objective|`.\n",
    "\n",
    "\n",
    "- **1.1 [2 points]** `initialize_centroids` : select K **distinct** samples from the matrix data `X` and use them as the initial centroids. Store these centroids in the class attribute `self.centroids` as an `np.array` of shape $k \\times d$.\n",
    "- **1.2 [4 points]** `compute_distances` : compute the distance of each sample $x_i$ to every centroid $c_j$ and return the result as a matrix `distances_matrix` of size $N \\times k$ where `N` is the number of samples and `k` is the chosen number of clusters to be found. The cell `(i,k)` shall contain the euclidean distance between sample $x_i$ and centroid $m_k$.\n",
    "- **1.3 [2 points]** `compute_assignments` : given the distances matrix of size $N \\times k$ return an array of labels in which each element is an integer in the range $[0, k-1]$ and it represents which centroid it's closest to.\n",
    "- **1.4 [4 points]** `compute_centroids` : Compute the new centroids depending on the new set of samples that has been alloted to each cluster.\n",
    "- **1.5 [6 points]** `fit` : This shall contain your main loop which implements the algorithm described above. You'll sequentially call the methods above to find the $k$ centroids. Break the loop when the improvement ratio of the objective is within `rtol`. At the end (or start, depending on how you code it) of each iteration, call the method `save_plot` to save the current clustering status and save the current objective value in the `history` list.\n",
    "- **1.6 [3 points]** `predict` : Given new samples, return their assigned clusters that were learned in the `fit` step.\n",
    "\n",
    "While we're working on 2-d data (d=2) for visualization purposes, your implementation should handle any number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87fc74015342dff10888ee3dc8e89bc0",
     "grade": true,
     "grade_id": "kmeans_code",
     "locked": false,
     "points": 21,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, k, rtol=1e-3):\n",
    "        \"\"\"\n",
    "        :param k: (int) number of means/centroids to evaluate\n",
    "        :param rtol: (float) relative tolerance, `epsilon` from the markdown\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.centroids = None\n",
    "        self.snapshots = []  # buffer for progress plots\n",
    "        self.rtol = rtol\n",
    "\n",
    "    def initialize_centroids(self, X):\n",
    "        \"\"\"\n",
    "        Randomly select k **distinct** samples from the dataset in X as centroids\n",
    "        @param X: np.ndarray of dimension (num_samples, num_features)\n",
    "        @return: centroids array of shape (k, num_features)\n",
    "        \"\"\"\n",
    "        centroids = None\n",
    "        # Workspace 1.1\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return centroids\n",
    "\n",
    "    def compute_distances(self, X):\n",
    "        \"\"\"\n",
    "        Compute a distance matrix of size (num_samples, k) where each cell (i, j) represents the distance between\n",
    "        i-th sample and j-th centroid. We shall use Euclidean distance here.\n",
    "        :param X: np.ndarray of shape (num_samples, num_features)\n",
    "        :return: distances_matrix : (np.ndarray) of the dimension (num_samples, k)\n",
    "        \"\"\"\n",
    "        distances_matrix = np.zeros((X.shape[0], self.k))\n",
    "        # Workspace 1.2\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return distances_matrix\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_assignments(distances_to_centroids):\n",
    "        \"\"\"\n",
    "        Compute the assignment array of shape (num_samples,) where assignment[i] = j if and only if\n",
    "        sample i belongs to the cluster of centroid j\n",
    "        :param distances_to_centroids: The computed pairwise distances matrix of shape (num_samples, k)\n",
    "        :return: assignments array of shape (num_samples,)\n",
    "        \"\"\"\n",
    "\n",
    "        assignments = np.zeros((distances_to_centroids.shape[0],))\n",
    "\n",
    "        # Workspace 1.3\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return assignments\n",
    "\n",
    "    def compute_centroids(self, X, assignments):\n",
    "        \"\"\"\n",
    "        Given the assignments array for the samples, compute the new centroids\n",
    "        :param X: data matrix of shape (num_samples, num_features)\n",
    "        :param assignments: array of shape (num_samples,) where assignment[i] is the current cluster of sample i\n",
    "        :return: The new centroids array of shape (k, num_features)\n",
    "        \"\"\"\n",
    "        # Workspace 1.4\n",
    "        centroids = np.zeros((self.k, X.shape[1]))\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return centroids\n",
    "\n",
    "    def compute_objective(self, X, assignments):\n",
    "        return np.sum(np.linalg.norm(X - self.centroids[assignments], axis=1) ** 2)\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Implement the K-means algorithm here as described above. Loop until the improvement ratio of the objective\n",
    "        is lower than rtol. At the end of each iteration, save the k-means objective and return the objective values\n",
    "        at the end\n",
    "\n",
    "        @param X:\n",
    "        @return:\n",
    "        \"\"\"\n",
    "        self.centroids = self.initialize_centroids(X)\n",
    "        objective = np.inf\n",
    "        assignments = np.zeros((X.shape[0],))\n",
    "        history = []\n",
    "\n",
    "        # Workspace 1.5\n",
    "\n",
    "        while True:\n",
    "            self.save_snapshot(X, assignments)\n",
    "            #BEGIN \n",
    "            # code here\n",
    "            #END\n",
    "        return history\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Workspace 1.6\n",
    "        assignments = np.zeros((X.shape[0],))\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return assignments\n",
    "\n",
    "    def save_snapshot(self, X, assignments):\n",
    "        \"\"\"\n",
    "        Saves plot image of the current asssignments\n",
    "        \"\"\"\n",
    "        if X.shape[1] == 2:\n",
    "            self.snapshots.append(tests.create_buffer(X, assignments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# show progress code\n",
    "k_means = KMeans(5)\n",
    "objective_history = k_means.fit(multi_blobs.X)\n",
    "tests.show_progress(k_means.snapshots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a89d5a9ef16455d6bc66e89a49c44c4c",
     "grade": false,
     "grade_id": "q1_7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Evaluating K-means\n",
    "The easiest way to evaluate the clustering quality is to use the true labels. The natural question here is: which cluster corresponds to which label?\n",
    "\n",
    "Let's first formulate the question using `multi_blobs` dataset. We have 5 clusters and 5 classes in our data. Let's create a _confusion matrix_ $C$ between the clusters and the labels so that $ C_{i,j} = \\text{size}(\\text{cluster}_i \\cap \\text{class}_j)$.\n",
    "\n",
    "We model the unknown mapping using the $5\\times 5$ boolean matrix $X$ such that $X_{i,j}=1$ if and only if $\\text{cluster}_i$ is mapped to $\\text{class}_j$.\n",
    "\n",
    "To avoid having a cluster assigned to multiple classes, each row of $X$ is constrained to have only one non-zero entry.\n",
    "\n",
    "Now, given a mapping $X$ and confusion matrix $C$, the number of correctly \"classified\" samples (not really classification, more of clustering here) is:\n",
    "\n",
    "\\begin{align}\n",
    "\\#\\text{correct} = \\sum_i \\sum_j C_{i,j} X_{i,j}\n",
    "\\end{align}\n",
    "The goal is to find $\\hat{X}$ that maximizes $\\#\\text{correct}$. To solve for $X$ we're going to use `scipy`'s `linear_sum_assignment`\n",
    "([documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linear_sum_assignment.html)).\n",
    "\n",
    "- **1.7 [5 points]** Complete `evaluate_clustering` to return the accuracy of K-means using the optimal mapping $\\hat{X}$\n",
    "defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1ab376987d2bb1c46a7004a4c0f160a",
     "grade": true,
     "grade_id": "a1_7",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "def evaluate_clustering(trained_model, X, labels):\n",
    "    \"\"\"\n",
    "    Compute the ratio of correct matches between clusters from the trained model and the true labels\n",
    "    :param trained_model: Unsupervised learning model that predicts clusters\n",
    "    :param X: samples array, shape (num_samples, num_features)\n",
    "    :param labels: true labels array, shape (num_samples,\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # We can assume that the number of clusters and the number of class labels are the same\n",
    "    clusters = trained_model.predict(X)\n",
    "    # Workspace 1.7\n",
    "    #BEGIN \n",
    "    # code here\n",
    "    #END\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2b602e09c7b1bd6bae2d7582ad8aaa0",
     "grade": false,
     "grade_id": "q1_8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- **1.8 [4 points]** Run K-means on the full `multi_blobs` for 20 times. Plot the histogram (`plt.hist`) of the clustering evaluation from `evaluate_clustering`. Also report the mean clustering performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3c53c216f13313a101d9db67ae9f5ae",
     "grade": true,
     "grade_id": "a1_8",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "accuracies = []\n",
    "# Workspace 1.8\n",
    "#BEGIN \n",
    "# code here\n",
    "#END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84e0ee6c0976b08521f7e17c4c291dea",
     "grade": false,
     "grade_id": "q1_9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "## K-means++ (Bonus)\n",
    "We have used a random centroid initialization in K-means. In K-means++, we initialize the centroids\n",
    "in a (slightly) smarter way, and it works as the following:\n",
    "- Choose the first centroid uniformly at random from the data samples\n",
    "- For the subsequent centroids:\n",
    "    - compute the distances $(d_i)$ between the data samples and the current centroids (distance between a sample and its nearest centroid)\n",
    "    - Pick a new centroid randomly with probability proportional to $d_i ^2$ (not $d_i$!).\n",
    "\n",
    "\n",
    "The rest of _K-means++_'s algorithm is exactly the same as _K-means_\n",
    "\n",
    "- **1.9 (Bonus question) [4 points]**  Complete the `initialize_centroids` of K-means++ class and report K-means++ performance in a similar way to 1.8. Which model is better?\n",
    "\n",
    " You do not have to implement other methods. `KMeansPP(Kmeans)` implies that `KMeansPP` will inherit all the methods of `Kmeans` unless we choose to _override_ them (redefinition).\n",
    "\n",
    "_Hint_: The weighted sampling can be done using `numpy`'s `choice` and its argument `p`. You do not have to worry about excluding the already picked centroids from the data. Once they're picked, their sampling weight should be equal to $0$. Make sure the probabilities sum to $1$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca7e54f3d0a64b7dad031546be889952",
     "grade": true,
     "grade_id": "a1_9_1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class KMeansPP(KMeans):\n",
    "\n",
    "    def initialize_centroids(self, X):\n",
    "        #Workspace 1.9.a\n",
    "        # Complete K-means++ centroid initialization. The first step (first centroid) is provided in the next line\n",
    "        # Hint: You can modify self.centroids and use self.compute_distances to avoid re-coding distances computations\n",
    "        centroids = X[np.random.choice(range(X.shape[0]), size=1)]\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "k_means_pp = KMeansPP(5)\n",
    "objective_history = k_means_pp.fit(multi_blobs.X)\n",
    "tests.show_progress(k_means_pp.snapshots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec29f9221731a01e4e4b3ba2f57439d7",
     "grade": true,
     "grade_id": "a1_9_2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "accuracies = []\n",
    "# Workspace 1.9.b\n",
    "# Redo 1.8 using KMeansPP\n",
    "#BEGIN \n",
    "# code here\n",
    "#END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workspace 1.9.c\n",
    "% Which model is better?\n",
    "\n",
    "% BEGIN\n",
    "\n",
    "% END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "357f2a925257653479afc7128d6785d1",
     "grade": false,
     "grade_id": "SVM_intro",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Problem 2: Classification using Support Vector Machines and Kernel Trick (25 points)\n",
    "\n",
    "We have seen during the class the dual form of the Support Vector Machine problem using a kernel $K$:\n",
    "\n",
    "\\begin{aligned}\n",
    " \\max_{\\alpha} \\Big[ \\sum_i^m \\alpha_i &- \\frac{1}{2} \\sum_{i,j}^m y^{(i)}y^{(j)} \\alpha_i \\alpha_j K(x^{(i)},x^{(j)}) \\Big]\n",
    "    \\\\\n",
    "      s.t. \\text{   } \\alpha_i &\\geq 0 \\\\\n",
    "      \\sum_i^m \\alpha_i y^{(i)} &= 0\n",
    "\\end{aligned}\n",
    "\n",
    "The simplest kernel $K$ is the linear kernel \n",
    "\\begin{align}\n",
    "K_{lin}(x^{(i)},x^{(j)}) = <x^{(i)}, x^{(j)}>\n",
    "\\end{align}\n",
    " with $<.,.>$ being the scalar product.\n",
    "\n",
    " We'll be also using the radial kernel $K_{rad}$:\n",
    "\\begin{align}\n",
    " K_{rad, \\gamma}(x^{(i)},x^{(j)})  = \\exp \\big[-\\gamma ||x^{(i)} - x^{(j)}||^2]\n",
    "\\end{align}\n",
    "And the polynomial kernel $K_{poly, c, p}$ with parameters $c$ (offset) and $p$ (degree).\n",
    "\\begin{align}\n",
    " K_{poly, c, p}(x^{(i)},x^{(j)})  = (<x^{(i)}, x^{(j)}> + c)^p\n",
    "\\end{align}\n",
    "\n",
    "- **2.1. [6 pts]** Complete the implementation of the three kernels defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7c34dd8635d91d306c5bb02a4889f78",
     "grade": true,
     "grade_id": "a2_1",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LinearKernel(object):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        pass\n",
    "    def compute_kernel(self, X1, X2):\n",
    "        \"\"\"\n",
    "        Compute the kernel matrix\n",
    "        @param X1: array of shape (m1, d)\n",
    "        @param X2: array of shape(m2, d)\n",
    "        @return: K of shape (m1, m2) where K[i,j] = <X1[i], X2[j]>\n",
    "        \"\"\"\n",
    "        # Workspace 2.1.a\n",
    "        K = np.zeros((X1.shape[0], X2.shape[0]))\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return K\n",
    "\n",
    "\n",
    "class RadialKernel(object):\n",
    "\n",
    "    def __init__(self, gamma, **kwargs):\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def compute_kernel(self, X1, X2):\n",
    "        \"\"\"\n",
    "        Compute the kernel matrix. Hint: computing the squared distances is similar to compute_distances in K-means\n",
    "        @param X1: array of shape (m1, d)\n",
    "        @param X2: array of shape(m2, d)\n",
    "        @return: K of shape (m1,m2) where K[i,j] = K_rad(X1[i],X2[j]) = exp(-gamma * ||X1[i] - X2[j]||^2)\n",
    "        \"\"\"\n",
    "        # Workspace 2.1.b\n",
    "        K = np.zeros((X1.shape[0], X2.shape[0]))\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return K\n",
    "\n",
    "\n",
    "class PolynomialKernel(object):\n",
    "\n",
    "    def __init__(self, c, p, **kwargs):\n",
    "        self.c = c\n",
    "        self.p = p\n",
    "\n",
    "    def compute_kernel(self, X1, X2):\n",
    "        \"\"\"\n",
    "        Compute the kernel matrix.\n",
    "        @param X1: array of shape (m1, d)\n",
    "        @param X2: array of shape(m2, d)\n",
    "        @return: K of shape (m1,m2) where K[i,j] = (X1[i].X2[j] + c)^p\n",
    "        \"\"\"\n",
    "        # Workspace 2.1.b\n",
    "        K = np.zeros((X1.shape[0], X2.shape[0]))\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3077c7ae65267526c1f8dd3c5cff93e4",
     "grade": false,
     "grade_id": "cvxopt",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We add a ridge regularization of $\\alpha$ with coefficient $\\beta$, this time there is a minus $-$ since we're maximizing (so that $\\beta ||\\alpha||^2$ is minimized).\n",
    "\\begin{aligned}\n",
    " \\max_{\\alpha} \\Big[ \\sum_i^m \\alpha_i &- \\frac{1}{2} \\sum_{i,j}^m y^{(i)}y^{(j)} \\alpha_i \\alpha_j K(x^{(i)},x^{(j)}) - \\frac{\\beta}{2} ||\\alpha||^2 \\Big]\n",
    "    \\\\\n",
    "      s.t. \\text{   } \\alpha_i &\\geq 0 \\\\\n",
    "      \\sum_i^m \\alpha_i y^{(i)} &= 0\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "Now we'll solve for $\\alpha$ of the dual form  using the quadratic solver from [`cvxopt` package](https://cvxopt.org/userguide/coneprog.html#quadratic-programming) (we're using version 1.3.0, it might affect the sanity checks if its different).\n",
    "To match the solver API, we need to rewrite the problem as:\n",
    "\n",
    "\\begin{aligned}\n",
    "    \\min \\frac{1}{2} x^TPx + q^Tx\n",
    "    \\\\\n",
    "     s.t. \\ Gx \\leq h\n",
    "    \\\\\n",
    "    \\ Ax = b\n",
    "\\end{aligned}\n",
    "\n",
    "So we'll define $P, q, G, h, A, b$  as:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathrm{P}_{i,j} &= y^{(i)}y^{(j)} \\mathrm{K}(x^{(i)},x^{(j)}) + \\beta \\delta_{i,j} \\text{,  matrix $\\mathrm{P}$ is of shape $m\\times m$}\\\\\n",
    "q &= -\\overline{1} \\text{,  vector of size m where are elements = -1} \\\\\n",
    "\\mathrm{G} &= diag(-\\overline{1}) = -I_m\\text{, diagonal matrix of -1} \\\\\n",
    "h &= \\overline{0} \\text{,  vector of size m  where are elements = 0} \\\\\n",
    "\\mathrm{A} &= y \\text{, the labels array in \\{-1, 1\\}} \\\\\n",
    "b &= 0 \\text{, a scalar (not to confused with the intercept of SVM)}\n",
    "\\end{align}\n",
    "\n",
    "$\\delta_{i,j} = 1$ if $i=j$ and $0$ otherwise.\n",
    "\n",
    "Hint: We're basically computing $\\mathrm{P}$ so that $ \\mathrm{P}_{i,j} = y^{(i)}y^{(j)} \\mathrm{K}(x^{(i)},x^{(j)})$ and then we add $\\beta. \\mathrm I$ where $\\mathrm I$ is the identity matrix.\n",
    "\n",
    "- **2.2 [4 points]** Complete `quadratic_solver` by defining the different arrays $P, q, G, h, A$ and the scalar $b$. Make sure all arrays have the correct shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2aa0302bdcfaddfefc3530b5b28274f4",
     "grade": true,
     "grade_id": "a2_2",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "import numpy as np\n",
    "\n",
    "solvers.options['show_progress'] = False\n",
    "solvers.options['abstol'] = 1e-10\n",
    "solvers.options['reltol'] = 1e-10\n",
    "solvers.options['feastol'] = 1e-10\n",
    "\n",
    "\n",
    "def quadratic_solver(K, y, beta):\n",
    "    \"\"\"\n",
    "\n",
    "    :param K: Kernel matrix K of shape (m,m)\n",
    "    :param y: array of binary labels {-1, 1} of shape (m,)\n",
    "    :param beta: ridge regularization coefficient\n",
    "    :return: optimal alphas of shape (m,)\n",
    "    \"\"\"\n",
    "\n",
    "    # Workspace 2.2\n",
    "    m = K.shape[0]\n",
    "    #P = ? # shape (m,m)\n",
    "    #q = ? # shape(m,1)\n",
    "    #G = ? # shape(m,m)\n",
    "    #h = ? # shape (m,)\n",
    "    #A = ? # shape (1,m)\n",
    "    #b = ? # scalar\n",
    "    #BEGIN \n",
    "    # code here\n",
    "    #END\n",
    "    sol = solvers.qp(P=matrix(P.astype(float)),\n",
    "                     q=matrix(q.astype(float)),\n",
    "                     G=matrix(G.astype(float)),\n",
    "                     h=matrix(h.astype(float)),\n",
    "                     A=matrix(A.astype(float)),\n",
    "                     b=matrix(b))\n",
    "    alphas = np.array(sol['x'])\n",
    "    alphas = alphas * (np.abs(alphas) > 1e-8)  # zeroing out the small values\n",
    "    return alphas.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a54a11ce9a29cdf01a08fc44999bc92",
     "grade": false,
     "grade_id": "svm_desc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Once we get the optimal $\\alpha$, then we can get the indices of the support vectors $S = \\{i | \\alpha_i >0 \\}$. The intercept $b$ is computed as:\n",
    "\n",
    "\\begin{align}\n",
    "b = \\frac{1}{|S|}\\sum_{m\\in S}\\big[ y^{(m)} - \\sum_{i\\in S} \\alpha_i  y^{(i)}K(x^{(i)}, x^{(m)})\\big]\n",
    "\\end{align}\n",
    "\n",
    "and the prediction for a point $x$ would be:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{y} = \\text{sign}\\big[\\sum_i y^{(i)}\\alpha_i K(x,x^{(i)}) + b \\big]\n",
    "\\end{align}\n",
    "\n",
    "(you can see that we only need the features to compute the kernel $K$ and everything else is done as a function of the kernel. That's the beauty of kernel methods!).\n",
    "\n",
    "- **2.3 [4 points]** Complete the `fit` method of SVM. _Hint_: Make sure to use the labels stored in `SVM.y` that have values (-1,1) instead of the (0,1) training labels\n",
    "\n",
    "- **2.4 [3 points]** Complete the `predict` method to return the predicted $\\{0,1\\}$ labels of the provided samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed443dae71d98cbd49186be9c5822c3f",
     "grade": true,
     "grade_id": "svm_code",
     "locked": false,
     "points": 7,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SVM(object):\n",
    "\n",
    "    def __init__(self, kernel, beta=0.001):\n",
    "        self.kernel = kernel\n",
    "        self.X = None  # training features\n",
    "        self.y = None  # training labels\n",
    "        self.intercept = None\n",
    "        self.alphas = None\n",
    "        self.beta = beta  # ridge regularization coefficient\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Transform y to (-1,1) and use self.kernel to compute K\n",
    "        Solve for alphas and compute the intercept using the provided expression\n",
    "        Keep track of X and y since you'll need them for the prediction\n",
    "        @param X: data points of shape (num_samples, num_features)\n",
    "        @param y: (0,1) labels of shape (num_samples,)\n",
    "        @return: self\n",
    "        \"\"\"\n",
    "        # Workspace 2.3\n",
    "        self.X = X\n",
    "        self.y = 2 * y - 1  # transforms 0,1 to -1, 1\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the labels of points in X\n",
    "        @param X: samples array of shape (num_samples, num_features)\n",
    "        @return: predicted 0-1 labels of shape (m,)\n",
    "        \"\"\"\n",
    "        # Workspace 2.4\n",
    "        predicted_labels = np.zeros((X.shape[0],))\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "72c7d30255a3d3716050982f37bb532e",
     "grade": false,
     "grade_id": "q2_5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We provide below an example of the expected plots for this problem using the linear kernel. \n",
    "\n",
    "- **2.5 [2 points]** Edit the cell to report the accuracy on the test sets for each of the two datasets visualized in the plots. How do you explain the obtained accuracies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "607d1045e1990bdff5ed846664121a7d",
     "grade": true,
     "grade_id": "a2_5_1",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.set_figheight(6), fig.set_figwidth(12)\n",
    "svm_linear = SVM(LinearKernel())\n",
    "# Workspace 2.5.a\n",
    "for i, dataset in enumerate([binary_blobs, circles]):\n",
    "    svm_linear.fit(dataset.X_train, dataset.y_train)\n",
    "    tests.show_decision_surface(svm_linear, dataset.X, dataset.labels, axs[i])\n",
    "    # Compute and print the accuracy, you can use axs[i].set_title to show it on the plot\n",
    "    #BEGIN \n",
    "    # code here\n",
    "    #END\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workspace 2.5.b\n",
    "% Explain the observed performance\n",
    "\n",
    "%BEGIN\n",
    "\n",
    "%END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d93e8991d06301ebc87c68be54fd2a31",
     "grade": false,
     "grade_id": "q2_6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- **2.6 [3 points]** Plot and report SVM performance on the same datasets as in 2.5 using the radial kernel with $\\gamma=2.0$. Describe the model performance and compare it to the linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e86e69fe805619f39cf2a0220d7ddfe",
     "grade": true,
     "grade_id": "a2_6_1",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.set_figheight(6), fig.set_figwidth(12)\n",
    "#Workspace 2.6.a\n",
    "#BEGIN \n",
    "# code here\n",
    "#END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workspace 2.6.b\n",
    "% Explain the observed performance\n",
    "\n",
    "%BEGIN\n",
    "\n",
    "%END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa08e8566afbe9abafd02bc917a5d017",
     "grade": false,
     "grade_id": "q2_7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- **2.7 [3 points]** Plot and report SVM performance on the same datasets as in 2.5 using the polynomial kernel with $(c,p) = (1,5)$. Describe the model performance and compare it to the two previous kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f87201ef3cd3b0308bdf192df6f37395",
     "grade": true,
     "grade_id": "a2_7_1",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.set_figheight(6), fig.set_figwidth(12)\n",
    "#Workspace 2.7.a\n",
    "#BEGIN \n",
    "# code here\n",
    "#END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workspace 2.7.b\n",
    "% Explain the observed performance\n",
    "\n",
    "%BEGIN\n",
    "\n",
    "%END"
   ]
  },
  {
   "attachments": {
    "network.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAABDoAAAJ1CAIAAAC3kQdtAAAey3pUWHRSYXcgcHJvZmlsZSB0eXBlIGV4aWYAAHjapZtndhy5FYX/YxVeAnJYDuI53oGX7++imhySIuXRWKlbHaqAF24AQLP/8+9j/sWvUmw1MZWaW86WX7HF5jtPqn1+9fuvs/H+e3+Ffv+n/3963ZRk/X3meSnok88bNT+P7u311xfeHl3nWfpwoTpfb4zPb7TnvtbXLxd63ShoRBrCel2ovS4U/POGe12gP9OyudXycQpjP4+v7z9h4K/RP3M/03Ovu339fyxEbykGwfsdeJl/Q3gNIOivN6HzJD7/8kGGzPPIWz08n3VPQL6L0/uvxoiOhhq//dCnrLw/+5Ktt1iar9mK/vWR8CXI+f3x29eNS99n5Yb+w51jfT3zn1+f281nRF+ir7/nrHrunJlFj5lQ59ek3qZ4n/G5wS1062oYWraFv4lLlPu78btS1ZNSWHbawe/pmvOk67joluvuuH0fp5sMMfptfOGJ99OH+2INxTc/b/aifrvjS2hhhUom5007OX0fi7u3bXaae7fKnZfjo95xMae6+NPf5k+/cI5i65xiSerdk1/vFWyGoczpXz5GRtx5BTXdAL/9/vpLeQ1kMCnKapFGYMdziZHcX0gQbqIDH0w8vsCjrNcFCBG3TgzGBTJA1lxILjtbvC/OEchKgjpD9/TMIAMuJb8YpI8hZHJTvW7NV4q7H/XJ87LhdcCMTKSQQyE3LXSSFWOifkqs1FBPIcWUUk4l1dRSzyHHnHLOJQsUewklAmwll1JqaaXXUGNNNddSa221N98CoJlabqXV1lrv3LNz5c63Ox/offgRRhzJjDzKqKONPimfGWeaeZZZZ5t9+RUW+LHyKquutvp2m1Lacaedd9l1t90PpXaCOfGkk0859bTT37P2Susvv/8ga+6VNX8zpQ+W96zxKozxuoQTnCTljIR5Ex0ZL0oBBe2VM1tdjF6ZU85s83RF8gwyKWfLKWNkMG7n03FvuTP+yagy93/lzZT4KW/+n2bOKHV/mLlf8/Zd1pZoaN6MPV2ooNpA9/GZ7it/4KpfH42ehOaPC6WuFWbQ2FML/GFk3Tu/tz1191hn2S3VddTSI+VwTrdplLP4fej+zYv91F6m3Wf7sBLXJar6EGjVZwKywhjdCeJmPanPeE5NNKwuumxO4RjSWvXfQ2/uunyqBCDNM86cOxE2Hk8r+TTGfKZfSXBeXb4jK8z39BXLMT+8lUD26XtthbeCb4zATt6pvYezXYpx6NPRtajHaY2myhNqpOWpgM5Zx/YEdnwYAgF47nTvQ3Q1iE/vmY9vahhc9NNAxE/zvv9pMM9QptU4GAUXeo3Cn9rOJoqa35MS6az3pJAR9+M7MdysWeVbqZydcVA3vMmgfsnLh7REEhm4SLDvUTC/y8SfJML8LhPviXD5SwTSpEp8GjxCjokmN6M09XzZJxY6wfeikczSNBJbwkmzMJxzCxfhGrZraa2R9/FcJ/G8zu2XqUfAcfZJabht0yJ0I9gl2hGNp37iHmevMhYMUePY9CRYsDK9TmQZonO5mAZfp2XVyqOVHXouy3dh7k8VlIobKAvQI2Q+z0yWrcRotcLnl+X18vtIhdqnAx7OismXdDoo8l4u5k/r5adyMb+tFxrnla72v9rGfNc3nyISuYaj5CuTg2m4dAdvbIU80M1nhxPVSQbkvB3WXQNUyd5VfX7XAVmRLfhF6AODnN+2sPndWG7wZ3Q3+MGnrnANaZ+0IsDtIriOVuJCGV4j9GncksvvTSSafY/K+TtgYr4ZyT8CE3O+baW8EgOKkXrOx1UER6KQWw/NhkrLNDdLBt73oDq4RW2mr6FUpNHg1NEJyFh8EYwvbq80Xe7rWKIPbw2IZq99aIU5fKy0Bk0Dnqd9sFmt7z2mJ8lZl9+rnQyP+HtNZtftyX0eB6OsPccp6qU41qCjB7GXII4JC7GLW5Gn/JFd+4eP5oc3Spu5J0it9ZHphrlG9LHP0gtcjQ3NGjuDGrOdQOMbOA/6Hsw6koyx6GjPzCBJAjtiXUgCzAOi+nT1fRf+uJx28MuPuOBpvwAm49zOviF4mqZYAC/MBaAC9CFC0DKr2TTJ0XIewiYFKB8+UXw48witikq0wrSVuhitnp1SU8nUnhtFGGamRoYwegBwebjI334LbFoJoJJuIKxNN9ivJz88rtwQ39sSjS0Jdhqq+pDx0bl3IVoWcA59GRRYjxs3BeTG5pBO8w13mkN93HY5lDHybiPccPUl9VEPsspqCWLMLs1p8uoq0NAWGJVzRWw7ZNtB2xVCQAcd9a4ntKACmFg2U8Swth0ICPKvtkHAjBWxDFJKoZXicGMACPxBLJPHONZNpFBKuY1cQ5+7F8RjCbmpoUlrjXikuE1pug5D7A32QN4CZHHERIVUObtJipj19qNtqrvUSc4XPOXCcG1DGTHw2MxJYfXR6LUxVwqTKAUwKCBRx6b40o796G9aNQQwF40I1Y1V2o4U21yYHx5NKyWHhtBF/9HsZcsHdXQVKcAcSG0R2lpQ2cjWgIAdQETrk3fKpgUTXcd0DdMcTapMWAOwWZC1rgKo0eN97eTWDBHG2gjv4imM0iN2OeaVNyDqyyi9rcnUmDHY4xeCM+GSsXaQV/Mli2rQ2L7sweyhXxnziHG4oFoUiTURAD3TCSaenEgzYnnyDWaHXN6jRHryHGT7atApygCNUHdp9DPVRHPQeGh6IA3ZDs87U2GXBc/BuxCGX5MhY/iHq6A7l2cwuxNZ4LBXqpEQ52iRDYNICdZxBDYeTI1fOIye0ADYBeszmqJKUzjdM8PMQFdefndeK5SZJesL/B7cfm7URiOSMn6V3zBenSu0gSB1E6olhiGtUPPE6ghEUTFbbgVJzmjQ851AXd6Ph9o41BEYdGYLHxgit7ceIzo0Gax0VXhxds3UZvGTsVdseK7AwKQjQjN0AFkcgaAzLVzbxCoNi2UoZU30SunZ0nebESZNGPLHadWz8GdrvY/LPAP7Mi4skT2ThnId4KcmsJiZFl2zUx3LA3VZ6SFAVDlRKt2kCbU0gDEAo5RTWvAEAEj8RkArWH+GtBHWcierwMaEpTi1eCoBo0bdh670xx6JXcYverqN2dOd43jg1YHV3K5BqyVhUkgafqagggbW1HlKrOdBUUyAzLQzRsOUAhdA03QEYkooYWcyvYc9hcW0qJLh9CoxCkM+ArXWfZgEFIyGNTvnVPvSOsgclD1TDnyygpkBaB3Loyy5bkJYgqVE99x1NdBTvbe2Q5EVMLtrSalikKm7M3PYMM3cQTqDuYCtVJLHkjYiKWJfDiHF/PtjH3l4nhj5R8ByJsAmeawRhTCr8lMhP7jkMCYUWFWx9snMbpagweT2xLajBLB1w3gmStojUmEBDLRsHVCnsopLrvAd9nRZmg+6TW4ijIlSk8KieIvUdnc2BYPhhiqVGo8IQym5CW8iFtsqQET1qizqeOAKAMYArm/djoGCZ4vqf6SjyZD8oSkXdyaVEOGAkLJMdysUXCBBopk5AIyjj4I+LttQOiiPoxc51JWQx7WQPck7/PA6OA3KgPoHj4JkUk13SNZHnIPHqzjIvyMcoV0Xuyc+SLODiPAEl1o8lhw5tFcWEK0tcJYEDFuiC7zwAVrxWagMuBaklvAO4s8OCjekVGYHsihkvisbdzYlxu1gwwwTgBy7CGfinlNrJNFR3mgf5I2oC3p3An+0GJxYiDpl1PlUR+WhVZgukgKtfarTMhsfd4Leq3r5PE13CoNpsgiICNSFlbZFDqS7LjEBdvUD3IsRGxf+oxYTHAmaAXhCSIAFfVcgouRJDrZBTy8IpzbkWCWfWk/C/rjeXS+NbEqtdmqHmLhmJc+KllptgfQ25s3XIZQy4CHhIM0JvyISE8zbSQGCD9QD0fId8sBTBh6itJQjlRgBfB353EpxKKYOD675SoXBbNEj6fABsMVRk3gaHltJyoCV7k4AqwqoJr9H0fF2cg1wW8vMsbOI3m/JMCm6yjSoAGgZykZFLEcRL8ALWzO6QG06kkLdT2hP3AkeWkOjwUVBlhhCgNAjshtvBadJG6D0GBbYyC0iCaICEN8BQYI6o9I99qDZ2Glai72MUE5CFaHXIWHuCQVUCm80C0gSHD+XBlocaoTxtaVFsDIGQaQPyEIzXutvoM+gcVw63H+LyjO5lJuG7CA2LCxZKnAo/VPion0XlArZZr7vFt4GeayWI3ppX8GT4ezaADZknTwU3hHXqnzR9qgv6g5h4iXjpUJUS/KEwxTKA3sChyDMQYI8MI+QRUdR4ecUm8RIqH00JKKvPW5OxoW63vdmUPzEHQWaoGDf0Jyk/NFJ2YHf0R4LCEWPxUK9SzwAmnxSrAnvPmskfAXxfAzgd2nRgc34KgQb4qRqnQFlghrr7VkHwH0A8QindBc9KEktEZ7L7YAjYpT+PAhehMvpkRxsmBSlPzpk6uTu8cWe4cngRcSYfCVS0d+dtOO1hElDBAOYJ+Vmg3yUEz1J3tHjUf6w4zl9QEkssBLo4G3kCIOOaB9dQXYWWne4bJhk637KP5qMmsbOdUE04S40Mi5R2GQjce8F2TdSB6hhj51WkX+cMGAxQA4if2rBt2YnFZQvwyVuiEfqkFCm23PwfEYuoOF/gYNVmDP+ZANAwO82Y2jxGYOH6m/Um6pu0LcAhJZhxVkJm7pAdHgQWPKgT8AEBvqFprsLtNACLELU4QxpM/pzq8vImR2UHB0VOmLpbO92B9cDnrAfZPyKWmgB7ZeUAZCDhqQZyu1vrDXgwbfA5rjQVSPZykh4p8Y1vFQo0ISko5W0g8SjpshQ894Gh6GVGf6IF4NNlS7e9CqIiZlwJIpwgqVIv3XyfYWGAkccCjAX0o/SjtnUJNBHUMGzXQw8e6YkMQvgGhoJjFweeadlpKzFM4uww7LKgxEfxJHHCqRhpDZIERoTVukkhw5HF6On5V4680FAkGcQCSqm9YFrGARHeXuq99NpCpgWBQBSgS8axWHEA/jyQw7PbUoKrovgKZnZltRzowJrMDtuhUF61r2w9gb6S+gUWug6lwUK4AxxHd7njCxGpyu+GMx5rXsSVyJfi2y2NFcG20BmeI3epO4cXUOd3BiMHO6aVJdF0fKNTMQCMREzWviPIM2h7Jgc3qBjW5vsOuQpfphzUCj4NCwQOEO94CVROSEhLj0p2khtCyZqRyXmKnoP2tNeSES6H2XKH9puoePJhZMmkmanS3PAi2OlXUK/gAS0BUXWg+uZ2mp474ojGs7VtWXXlTMkHZINBdBkuUEMCIHe9oIrWRkYIXiwu9qNjUNzdq1GCWnHZhBuGC2G5bs5AgcsV2vG4CMXwFsNGvtN/wF3xCSCbQ6yh2oARfAtaz1E3OWLM1fIdszpdkOkuPQP3aTYQ3mooZAROohhgjsqwEDTbC1uUFbyf0EdAR6hs4DxVKiCqi0iNxAD1NQ6lPnEHCLQlnZwMFYVGoYiNPIO+1eRTDxoMpw50o/60LIM30E3AhP5FASE1/5jLrIuZALazQlK0AEHJkwDHLwmUi7iIgjkDsZqtY7gyj4yDYSbFtL9UiwxBfiEpY1mW1AaZwFY2jnCMyTuI2cF88JCFGSEV56FQ0QMsTlaq8SBgxwIiQwwtTRi1HYSLIdpiU3db5E04OmhKBsBw4oKd2K43Wdndtqqg/BCGPclKByWhIzBDZqH7kBYbgp5UORyTc1LURUbzCDOuWt7NjstcFN0Q76Y0GUoHl0loD+8lZDrUMjWFntIjEOLIbAczg2zZSqgr4U1+D8LIDaO41y+xVWAsiA7IkYLFUo3ybfiiB692AkrtgSWI2eDhAJ24RckNtHC3moRwa+E+qL8K5IF25fjs31Al0JB8NCaFYShPJo9EHA8cH/RZgo457Y/WlvzfOAuk8NsQaXS6J5q5aAORlmLr0g1OhmCpVyWNswQ7AvORK3Sou2u4VH0LqFiChpxQ+7Mh9hTE1gLylBWHLOLbPAIMC1/oGW5XDbYjdRa0/qs0xoiJlHaC2UOoSC58S/QJFEFqhn6DlzCCQqQHWe3BDUNKFNHGRQxUB0MAfkPoyGqWllEQA2tTVLmdIuXA+ywuioLAEIEQC8UABS5azhUdhF137UOqohZxzkybYd8dnNjdO9yCXMGHzaCoUYtWiWv5a5Ga2p/HxlpQtNKvAcvetNRAMrYN7RsBX3v6qWWLy1WaVjCSe3RR2HDkJP6QjL3TAioBEMFkhQ4HVOsBRhIB5y/lBgsdYuoZ5oRvb7aRPfhypd6EuUC2OGVkNkdfjdFfpe2TYmu3tMhKegzWH9gY3YQdOOjHX0SAehlKSn5qIjJdAgRvtPkJKshIqDHRKWj0LROJUqJSLrOvSk0H5CjlWRJFGwHegVwSQZ4a4TMdd8+MF4unZ6gjIhQruAopKvFuMAgBq2+tQhSUKfIZ9+03tb5BFRXgQkxp8PfBJN9rJQR9D3vOR4t66LMpsoog9XkF9LO2heKMe1Ep2l1VadGwL2BwEu13J0atFu922Ap0pCYSTwpzpl4SKDhTBxU1rVsZG8uEJawYgFsQF9kAsIT01aMlHvQ/sPw/KaTiBX2lDFCGb46jy4DYsMmNFCWRYjIQd/FoIKfkK4s3SEiSBTNLqnWAoLOYZzIlqP1tVyB/aLAR93gGiVGkWhxKdAfQ66ga2EQ8aIYxVhruefgKKmoxozb34MBgADaGC4NDBS5jm/WKQGyukgZ4oh8k6qqIXdzJBybVOIKQsQhGqstbbSdHNPGbcajTQ8wiypGZ4PYe1hoy82oKwV8ik7WIVmQ+8KQDitXqW+d6wmoz0CjQy8BkZE7Pbu1NQPKILgojFTpZIl6NbPRWjl1TnrpVPCn7yENlhFtQYehtJiG14eLtH6MmqUGtMbC6Kl4XCSKf5QaKUhbZYEIh4NrsdYdWaQtWQz9PanQB/7yeaYTe8/jxm0AmCCvJwlExzhUEnWbmw1cmfEGi0klc1KK4OEYOgjU6Z7awSvsTo3kX3Jj16jjOFos6NHAIChszGBCTKGGKvQHP2kHgLipcp5BSH+9zlJc9YDehQ8Jf+g9Tq35w0aVWVFmFPrligUeyhV0HWnJ2gikIZ3VeZd5VDpcDyNCsoHQNgTPJ1CQ9FXXasOQXxa3TmxtQcPSgI7aw3dn4hSkQtJkgMCblXvWQRBqf9qp04eZ6FRthft7QiNjfuhLRBbY2JDqSTI7VawYpQXFMnXxfYFLiAmIkZW2WYwWOWGQ3rVUf5eZB2KG2iT2zIt2bFpKhS76shT8Qe/Y0AAXugkyvDWAYEQfwXOwNyW8gC23tUcyNsmbdyPMD9yTL1r8IygY9+rkvdIpVh20s3a45dfCWCg/nAE+vWnZOIKzThW4hBaQGhPCeAXNlel5PGtQl3udwAPsB/gJOJmdY9OyKbJPK0zaHsKoDkQOfKOsYCMLs8I0OsGMViWJEAFnQloxAo4p52SmQpW0sM74ug5MbIjvnoBYIipQYoIrOPAVKZwhyRptalrxyQRRmgumwx0xY6m83aX8INYGihBO7DUGgji1NUmOttzQpngE/O8hVji18LbcICYxe6BqXCOSagMdDgUP0Cunat9gzCEkofp56mVahuV7048GitFkNJG9ixz0Gg5TYhuYcniK1NF1Wqua6ie+6OtAywODigGGF+JelMI9o7jvUaBi8cqmgn4BaTQXomRahwlB9/OJec0Nya0oK63wMSX8Bho6R11TRMmgQUGB1TALoQD8TPASnqAVGCdplB6JEM+gKQFI7TrjKnjZKYnYumQX7qYMHQ1EwlUshNb8uZxWQOEhxvObvc33xwJVUtoQd4nY54HvDw0re8T1sCN4FC/EF0e1x0lPkLwpLqM5+g1BroRgjIxgskno2MUv2syEPKaWprv2BwtQG6EATEKflFviNs4mqD4hVbUyginU9JFlJBsJGbXF6e8pjTiC3mxHDtKizZ9r2delMhBpncPIYf61DylLSnYx8EV7ifdEhUGD0ZqwY4/aGWAaGc/AC9AmqQNGG7QBs2qpOtC6tOocVDHGte7JW1W13YxWiWTqtIQj+NpNHLR6Q0wTsq3FAfoRv6zNJ4/+QVVjE7aXo3NNZ+cw9VqHRJWi5yV7uEXTdiAXA4CtHDIjo4Go5TMQoIXyubOs4JvV5hoWG+CjhXSwEmfVsq0O5NxEQMYZP1zVgjUQJAeK6vrwjYdd9W+lGeQLdO64HOlWI9OAQmaC1NkI2q72XYd18apLqKJFu2PFBbCRv/tuHgh6dr7SrVxe6eiju6aHAMYWx6ushnq2oDYQLmDyyogZ/CxSZOm4JTYoaaEv6PS3Tm/UNEM0vQrE1ShQTSAdDY1S0XgkeODa+rOojxZyJ7wfnSi0SpgRiYKYh9jONGgcNB7AAVvjnbBZJAvZLs9r70ZHoktjRlhR77tLeDVtBGjjB60AF1QJCYPEzHehFHGO9moUFZQXoAAqELwI2uoCz4lZhrV0DGvpzFTTpvCRBoDxMCcG1EMDYmUlD4V+Womdd40F/4pCdFoHDdevjQ1MopHQkwPbrJW6ol0Y7d8ZBCcSQiFARietUzVGmwfAvKS0m9WuD7Mh8qP8emH33D2Y95sTV0dgmCPAh1OQXjw6GP5QATarqBHbBuaClIWAfPm38Jsfj6YkhgDCLu3VukITcwfKB8UuOTuiLCm95xBHOrhmOoq7EVTozNv7JdqDoUMZlXanLbT9CQo6QEM/keDaVQMgDhU3iIPMeyimIa4sJndqeQjaX61fcSMAfJwtdQymPOeiAOTwFp17nA06INwAjhlDi2bSiYAuHJUKzDRa9lhD1EjU2k7MqhQwmzLF0FSJXEAgZ51d0V79Ofg1LTLApcrFc+zsLfQMrNHYSVvRHWYUnlmlS0AGVGvp/7rE+wMq5vVTKXwVa+pTvvsIXos1KFfExIQh4H+tQmsJOM2t5R7GjDoA7crWkaWEqj2oM1gFPZ2v20ZqTL1LpncucAvCDUAvBYAL1VO7ED9G0aO+qluYp6llq2Hg0UgDYx95gW90rS+jCcGSpXUmlMdC4ETXN2/UmhChaIYs76SNHy4b8W3Z2MRVkvBaO9XryOMDQJ25tXa0OgkodKfDLzBibY+CPFra1Y5KiTrHhbc3Zcs8HK2foL3zjJP0NcmSqW2lrpMQyMRnJ6JBzuUpg2f7A0GmHYyO798Ocxxfm4HPFoWWs7RKLpjCgfpNjNFeVJtW95HcMAyKDrMQgY4mn6xlH+qR76PNILe8DpCgHQlSvu8ofrrRPVNXtKGjncqRzFOnaeD0tdNLYVCWZ8SIhtHRKWq64a/669je6uITSKXTDKQBwZ5HCdgsJAyFglqxNCTmKt3l4Hr501u02zm3+iD6mGRjsg7Hodv2gR+fFk+Aovniev7uI2anaw9uc7Gkw+6m6dRQGFELUnOAHISPRCfcLQYQPAtOsE+9S85RoZWch4ODDIiYA8BKPZxmLNV86nMWlEijrYfKE+Xl4WtgrGpXawniBwZgea1Hiup6RhdWaTqkeOiGT/u4mfnJ2nu32ulBkD1HGU9+tTFitmiL8AGY9QIYmlZp0onz5xQrQkJncNECXSsud83t7oDejDJ1/6wD6hzIPkenyrYGNvgSRZpUBubXu9zkh+cG/QVj2sgaRQ5Z5z/v7hYFlZfGeQ/QNrFIenS+XuDp3pIFXWL0NK0t0VcMDylxtLBFyeZJOihsyNSW+3NN3WHXhdQUqQB+6dQMs2sUrHbu7y7DQNm0oUW/ZGvJFfIPaJKNBBM7vA3JaFp3UM+Qfhl8ahNNjKUHDPQzCMy94YOQ8ol5VaoEn38QWgUMe8VL4XqCpVD1ntZqu5UigcNUnNfxDP2gAwEDLD7f03yM2KfRcR8E10JKnbC06aH9v6GsVV9eqakokHIPbHXDJRlB6SrWEwX4mLl07iLrkRShNpp2N2xT4HQCU4YT/QZyU97UcFcpGgZmGbk2VOmfQ4VV0FsnA/gIspIK1okQxBp+dqJnus7CInz1cyOYyKrxLv8UJPmFILdOrNzTKUK/oIPUOtH2Yfhvoz8O2arDJ9qcAaSjjlZpm48eadrwOzoScBwQ+CwRbeIqSpMuA2X1Q2DCPEi8qPELragTOUE0Ypr8oMys9x6lE9w9KXpPSqN/wy1HFLlHWVbvI3QK3etUkU3CoVDtc6TYZJygchjLU99gAIj+XcfVpzvP+dCa+lmVclvwxujbLvxcVW8N+LTfN81nvnbfl0q/ffhX+ykvrwbU067NqwdyzJ9gzu8gx/wVgf64fQJ8j2j38lcdR+Xsayxfg3lGQoy6TkJQUy9c+Qwr3wEQV8KEnI1rPktL29r/dyZoGelrIHFqw42Gq6raddRP1+lu38ax8IT/G+lArUh6L0c350Dng1FhOEgOZ7oAJHQ65ad28Mg7/eBV1bkgip7GOioCTA3c+ZYDBJ5oC51zUNk//LASmjSlFftQ1VRtc42V0WhGexB9tyiO6cgxbgqN1VGjW/fnhMOlRGRBpDXhbqcN6Ri0bMnrOeeHbc3/cUj806ORA6R4m/kvu7WTtJYbm4kAAAGFaUNDUElDQyBwcm9maWxlAAB4nH2RPUjDQBiG36aVilQcLCLikKE6iAVREUetQhEqhFqhVQeTS3+EJg1Jiouj4Fpw8Gex6uDirKuDqyAI/oA4OjkpukiJ3yWFFjHecdzDe9/7cvcdINTLTLNCY4Cm22Y6mRCzuRUx/IoQzTBG0Cczy5iVpBR8x9c9Any/i/Ms/7o/R7eatxgQEIlnmGHaxOvEU5u2wXmfOMpKskp8Tjxq0gWJH7muePzGueiywDOjZiY9RxwlFottrLQxK5ka8SRxTNV0yheyHquctzhr5Spr3pO/MJLXl5e4TmsQSSxgERJEKKhiA2XYiNOuk2IhTecJH/+A65fIpZBrA4wc86hAg+z6wf/gd2+twsS4lxRJAB0vjvMxBIR3gUbNcb6PHadxAgSfgSu95a/UgelP0mstLXYE9GwDF9ctTdkDLneA/idDNmVXCtISCgXg/Yy+KQf03gJdq17fmuc4fQAy1KvUDXBwCAwXKXvN592d7X37t6bZvx80aHKO5w6/IwAADRppVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+Cjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IlhNUCBDb3JlIDQuNC4wLUV4aXYyIj4KIDxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+CiAgPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIKICAgIHhtbG5zOnhtcE1NPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvbW0vIgogICAgeG1sbnM6c3RFdnQ9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZUV2ZW50IyIKICAgIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyIKICAgIHhtbG5zOkdJTVA9Imh0dHA6Ly93d3cuZ2ltcC5vcmcveG1wLyIKICAgIHhtbG5zOnRpZmY9Imh0dHA6Ly9ucy5hZG9iZS5jb20vdGlmZi8xLjAvIgogICAgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIgogICB4bXBNTTpEb2N1bWVudElEPSJnaW1wOmRvY2lkOmdpbXA6NDUyZDkxOWMtNzk4Ny00NzE0LWE4ZDktMzU1ZDA1ZWRjOWY3IgogICB4bXBNTTpJbnN0YW5jZUlEPSJ4bXAuaWlkOjQ1ZGU0ZDE1LTRkMzgtNDgyOC04YzNlLTQwNTczN2I5ZDU5ZiIKICAgeG1wTU06T3JpZ2luYWxEb2N1bWVudElEPSJ4bXAuZGlkOjQzNmFhZWE2LTc4NWQtNDEwMC1iZjVmLTBmZmJmMjMxN2VkZCIKICAgZGM6Rm9ybWF0PSJpbWFnZS9wbmciCiAgIEdJTVA6QVBJPSIyLjAiCiAgIEdJTVA6UGxhdGZvcm09IkxpbnV4IgogICBHSU1QOlRpbWVTdGFtcD0iMTY0OTA1ODE1MzYxNzIzMyIKICAgR0lNUDpWZXJzaW9uPSIyLjEwLjMwIgogICB0aWZmOk9yaWVudGF0aW9uPSIxIgogICB4bXA6Q3JlYXRvclRvb2w9IkdJTVAgMi4xMCI+CiAgIDx4bXBNTTpIaXN0b3J5PgogICAgPHJkZjpTZXE+CiAgICAgPHJkZjpsaQogICAgICBzdEV2dDphY3Rpb249InNhdmVkIgogICAgICBzdEV2dDpjaGFuZ2VkPSIvIgogICAgICBzdEV2dDppbnN0YW5jZUlEPSJ4bXAuaWlkOjk3M2I1NjljLTQxYTktNGNkZi05OTY5LWZlMjI2YTA4YTUyOCIKICAgICAgc3RFdnQ6c29mdHdhcmVBZ2VudD0iR2ltcCAyLjEwIChMaW51eCkiCiAgICAgIHN0RXZ0OndoZW49IjIwMjItMDQtMDRUMDE6NDI6MzMtMDY6MDAiLz4KICAgIDwvcmRmOlNlcT4KICAgPC94bXBNTTpIaXN0b3J5PgogIDwvcmRmOkRlc2NyaXB0aW9uPgogPC9yZGY6UkRGPgo8L3g6eG1wbWV0YT4KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgIAo8P3hwYWNrZXQgZW5kPSJ3Ij8+oPcxVAAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAAOwwAADsMBx2+oZAAAAAd0SU1FB+YEBAcqIVBmqVsAACAASURBVHja7N15XBtl4j/wJ8mQmyuBACEcgXK0BFJKD1vcttR6fF23rtfWsx67/mp11++3ul7tum1dr1Vr1V3vXe/1rFqr1ragPZQelEKBcBcCJFwBkgDhyP37Y7oxcgYaIITP++UfdphMZp6ZZOaT52I4nU4CAAAAAAAwukde3L/lDzmBAs40vy8TRQ8AAAAAAGP77mjVrY9+3ttnRlwBAAAAAACfY7CGT39iQVwBAAAAAIDxUWz+9CcWxBUAAAAAAPDRxIK4AgAAAAAAPppYEFcAAAAAAMBHEwviCgAAAAAA+GhiQVwBAAAAAAAfTSyIKwAAAAAA4KOJBXEFAAAAAAB8NLEgrgAAAAAAgI8mFsQVAAAAAADw0cSCuAIAAAAAAD6aWBBXAAAAAADARxML4goAAAAAAPhoYkFcAQAAAAAAH00sDKfTiTIF8KJ1f3qvqUWPcgAAAAC/CiEUFSrL9Hx9m6U/NKDj3b9dEyjgIK4A+JCF17wQHr8E5QAAAABznFcSCxqDAQAAAACA93mlVRjiCgAAAAAA+GhiQVwBAAAAAAAfTSyIKwAAAAAA4KOJBXEFAAAAAAB8NLEgrgAAAAAAgI8mFsQVAAAAAADw0cSCuAIAAADnJUkm/Oap5e9vzRLyKJQGAHg3seBrBQAAYApx2awPtmYFCwOGLLfYHLc/XaQzmFFEADAXE4sl/NZHP/dkBknUrgAAAEwHfY+lpXPQ/T+UCQDM6cTiWR0LalcAAACmnMXm+NNLpahLAQD4RWLxoI4FtSsAAAAAADBDiWW8OhbUrgAAAMy8tVmS61ZLE6QC+p8a3cCLu+tK6rpdKyTJhLvuST90pmNvftuDNyTFR/Lb9INfHG29+7dylbpn8z/LXGvecknMhktjR1y4v6B95ydnCSExEt6Na2W/Sg/jsJn0273xTcOJcv3Yb3f/KyqdwUyxGLddFvvbC6UcNtPucB4q7sgt7MAZBIDJJ5Yx61hQuwIAADDDbrkk5qEbkxKkgrL6noIqQ0Nbf4yE99zdimtXSYesGR3G23VPenwkv11vFgWxi2qM3SZrcoxQEvrzPT5GwieEhAWz3cfpipHw7Q5nvkpPCLlggejVzQvXZkl0RnNBlaG+pS9Gwtt+W+oFaaKx345e+OANyevXyCiKUVBlaGzrX5sl+fvGNDr2AABMMrGMXseC2hUAAIApx2IyHr4xecBidy1R1fd89L2WEJKtEG+4NNZic2x5o8JVnXLZ0oj718+7/fK4o6Vd7j1e0hOC2vSDm54vMQ3Y6CVFtd05mWErM8S7j7QQQrhs1qKkYEJIeAhHkRBEV5jQCzuMZlV9D70zlU29HxzUuN6OrntZnxPtXsEy4ttlK8Q5mWHuw5rJo/jP3qUYPvQZAMDEEssodSz4LQQAAGA64kp6QtDS1NCf/5sfSv9p1cIwQsjb+xrdm37tL2g/VNzJppgrM8Tu27HYHPe/onKFB0KIRtdPCMlOP7daVnJIsDCgoMrAYjKyFSL3hZ3dFvqF+aquB15Vub/diQqD2eIYvtvD347e2x+KOlwhSt3a/8ibFSO+HABgQolFbxbduePLoctRNAAAAFNttFlWKBYjSsy1O5zaYeMa0zkkLpLvvrBGYxqykRMVhvU5Mrrpl2nAliDl2x3OvMKOFJlw4bxgeiGdMfLLutxfGCPhZSaFLFsQSqepEVtzDXk7197SjcoAALzI6bBzHB07Nl2GuAIAAOArKBYzSsSxO5z1LX0jriAL5429BXVrn7qtP0kmUCQEFVYZls4XdRjNJWe7W/XmBCmfz2UNWuxRYq7F5jha2uVKHX/ZkJKtEKP8AcB3sgprsPGlBy9LkYcjrgAAAPgKm93RqjcnyQQJUsGIs7JoOwbG24KzoFKfGivMVoi6ui3ySP6hMx36Xgu9cGWGuKSuRx7Jd68nefCG5GyFuE0/+NzHZ+kmYfQ4YDgdAOBrWYWg7woAAMCMxhVna9cgi8mQhXHdl1MsxtL5IkJIY1v/uBuhe54snBecKBVw2Ez6JfTC7HTxBQtCOWymqyWYq0HXy3vU7t1XzmdvAQCmKKsgrgAAAMywI2c6CSG3Xx6nTAx2LVybJUmNFbbpB/cX6MbdAt0eTBTEXrs43NXoi16YHCNcqQxzbwk2HMViXLc62sORiOm9vfLCKNcoyXTNDAYyBoCpyCoEjcEAAABmVr6q61BxZ05m2HN3K8rqewYsdkkIJz6ST1eAuI/KNRpXezBlYrBK3UM3+qJrQlJjhfGRfNdC95W335Za0dBrsTkU8UGeh42TlfqqJlNqrHD3Y0tP1xjDgtgJUkGH0dynt3ORWADA21mFoHYFAABgxj35QfXOT8626830YMcxEt6Zs90PvVY+ZBaUMbhGInbv60LXhJBhY4K9f1Dz9neNNpszPSEoKzlEZzQ/+u/KbpPVkzey2Z2b/1mad1rHYjKWpobGRfL3/NS64cnTgxjIGACmIKsQQhhOpxPlBeBFC695ITx+CcoBAAAA4DyzCkHtCgAAAAAA+GZWQVwBAAAAAAAfzSqIKwAAAAAA4KNZBXEFAAAAAAB8NKsgrgAAAAAAgI9mFcQVAAAAAADw0ayCuAIAAAAAAD6aVRBXAAAAAADAR7MKIYRCOQJ4F5/H7mg4hXIAAAAAfxIYGMgVp05zViGY1R4AAAAAAMa18JoXwuOXTHNWIWgMBgAAAAAAXuTFrIK4AgAAAAAAPppVEFcAAAAAAMBHswriCgAAAAAA+GhWQVwBAAAAAAAfzSqIKwAAAAAA4KNZBXEFAAAAAAB8NKsgrgAAAAAAgI9mFcQVAAAAAADw0ayCuAIAAAAAAD6aVRBXAAAAAADAR7MK4goAAAAAAPhoViGEUChxAAAAAJ+ya9cunU6HchiXRCLZvHkzysGPswriCgAAAIDP0el06enpKIdxlZWVoRD8O6sQNAYDAAAAAABPTH9WQVwBAAAAAIDxScSB059VCBqDAQAAAADAuA6+8fsZeV/UrgAAAAAAgI9CXAEAAAAAAMQVAAAAAAAAxBUAAAAAAEBcAQAAAAAAQFwBAAAAAADEFQAAAAAAAMQVAAAAAACAUWGaSAAAAACYMYmJiQqFQiAQEELa29utViuHwzly5IjFYkHhAOIKAAAAAMyY5cuXy+XykpKS8vJyJpN58cUXR0RE1NXVIasA4goAAAAAeIdMJlu5cuWIf+rt7W1rayspKRmeQNLT0+VyeV1dXXl5OSHE4XCYTCaxWNzd3Y0iBcQVAAAAAPAOrVa7b9++iy66iMPhdHR05Obm0stDQkKWLVuWlJQ0b968o0ePNjc3//wMSlHJyckmk6m4uNh9U06ns7e3F0UKiCsAAAAA8DOJRJKamhoZGUlRQ58PTSbT/v37x26g1dPTYzKZOByO+0Kj0Zibm3vxxReLxeKsrKyOjg7XRiIjIzkcjlardS1hMplCobCvr6+jowOnA1wwMhgAAADA3H4cZDKXL1++du1amUw2PKucJ4fDQbf1EggE4eHhruVxcXGEEPd2XyEhIcHBwQMDA+i4Au5QuwIAAAAwpy1fvjwuLs7pdJaWltbW1no9LfT399tsNoqiAgMD3ZcPafc1f/58iqJ6enpwRgBxBQAAAGDWS0xMzMrKoiiqvb39xx9/dMUMkUi0du1aup7EvSfJiEQiUXR0tNPpHNK3xIv4fD5FUWN3SpHJZPRuaLVanFlwh8ZgAAAAALOPTCaLjY3dvXt3V1dXREREQkKC6096vf7YsWM2m40QMm5lBV2nUV9fP0VZhRASGhpKCHE4HEaj0bWwp6eHwWDIZDI6d8nl8vb29iHrACCuAAAAAMzCBzgmMzU1taCgwOFwtLS0EEJiYmLcV+jv7yeE2O12lUo19naEQiH5ZR8S76JHACOElJSU9PX1uZaXl5drtdrExMQbbriBy+UeP348LCxsYGDAarXi/MIvLiEUAQAAAMDs4nA48vLy6P83GAyEEB6Px2azXe3B6PZXHR0d7glhtLgydWMHSySSJUuWsNnskpKSqqqqIYdw9OhR1z9FIhGLxXIfKAwAcQUAAABg1qM7stPjbrkadIWGhjqdzoqKCk+2wGAwVq1aNcYKngxk7BIeHn7jjTe6/tna2pqbmzvua6OjoymKwgSRgLgCAAAA4FeMRmN3d7dYLHaNu8VkMqVSaWdn59R1RxmDq3M/3eM/KioqOzv70KFDY78qKCgIpxIQVwAAAAD8jcPhMJlMYrE4ODiYXiKVSkUikXtTq7FN0bBger2+srIyPT09KioqNTV1SGOwXzyPUlRkZCQhZNGiRYSQMdYExBUAAAAAmGXch/9iMplpaWkeVq24os6QGVG8pby8XCqVisVipVKp0WhG60hjs9k+//xznEcYEUYGAwAAAJjd6N72dHsqqVQaEhJy7NgxT15IxxVCiKtmxrtcU9qzWCyFQoEzBYgrAAAAAHMO3duex+Px+fxly5Y1NDSMPSCYu8rKSpvNlpCQEB0dPRX71tLS0tXVRQiJj48XCAQ4WYC4AgAAADC39PT02O12Ho+nUCisVmtxcbHnr9Xr9c3NzQwGY+XKlWlpaWw227v7hgoWOE/ouwIAAAAwu7m6oCQmJh49enSiU5ccP35cKBTSPUyUSuXwFTwZyDgoKIiecVIkEgkEAvfqHbqCRSwWJyQkdHd3oyc9TAhqVwAAAAD8Ia4QQurr6ycxwJfD4Thw4MDx48cNBoPNZpvEDshksssvv5zD4RBCWCzWlVdemZqa6r79U6dO2Ww2BoOxaNGidevWeb0OB/wYalcAAAAAZjd6cnqTyTShZmBDqNVqtVo9uddqtdoPP/xwjBX0ev2nn36KMwWTubxRBAAAAACzWlpamkgkOn369ESbgQEgrgAAAADAFEpPT09PTy8uLp6ROewBEFcAAAAAYGhEWbduHZfLzczMTE9Pr6urQ/918FfouwIAAAAwy9DDcF199dWEkLq6upMnT6JMAHEFAAAAAGYe3bGeENLf319RUVFTU4MyAcQVAAAAAPAJ9LjDKAeYK/kcRQAAAAAAAIgrAAAAAAAAiCsAAAAAAIC4AgAAAAAAgLgCAAAAAACIKwAAAAAAAD4AAxkDAAAA+BYul1tWVoZy8KSgUAh+j+F0OlEKAAAAAEDbsOXT0uoWD1fOSJG+9+TvUGgwdVC7AgAAAAA/s9gcIZGpAdzAcde0DvZabEaUGEwp9F0BAAAAAADEFQAAAAAAAMQVAAAAAABAXAEAAAAAAEBcAQAAAAAAxBUAAAAAAADEFQAAAAAAAMQVAAAAAABAXAEAAAAAAEBcAQAAAAAAxBUAAAAAAADEFQAAAAAAAMQVAAAAAABAXAEAAAAAAEBcAQAAAAAAxBUAAAAAAADEFQAAAAAAQFwBAAAAAABAXAEAAAAAAEBcAQAAAAAAxBUAAAAAAADEFQAAAAAAQFwBAAAAAABAXAEAAAAAAEBcAQAAAAAAxBUAAAAAAADEFQAAAAAAQFwBAAAAAACYDhSKAAAAAGAOKizXFqq0w5d3GkyEHeLhRjoNptc+OTF8eYo8PGdpIgoZzh/D6XSiFAAAAADmGrPVdteOr0pqWnmBEUP+xBGKWRRn3C3YbWazqWvoZvs6ZRHC95/8XaCAg0IGxBUAAAAAOK/EUtsyyAuN98oGbaa2YG4/sgogrgAAwPhKa1p7+8xlNW3uCw+fbhjjJcvSZTz2z+2EU+ThgQLO4jQZChMAiQVZBRBXAABgkqrVHb395kKVVt8zUFrb3t7Za+juCw0JYTBZZgfXfc0AbuAY27EOmgj5+b7AZpoJsRv0hkABLzoyODkuTBomTE+ODBRwMpKjUOwASCzIKoC4AgAAI+g09pXVtB0vaTpW0qRtNQQHBzJZlMXBZzBZFJvPpNietDv3nMNutVsHbdYBp93GYQ46HXaD0RghDl6mjFm8QLo4TSaVBOGkAMzZxIKsAogrAABAWnQ9pTWtx0o0J0s0vX1mDl9oJfwAbiDF5s/I/tisA9bB3gAyaBnsYVPMxWmypYroxQqZPFqEkwUwdxILsgogrgAAzGn5xQ17fqgsLNdabA42N9BKeAHcQCqA51M7abeZrYO9LOeAw2JyOuyZ86Mv/1VSzrJETgBGzAfw58SCrAKIKwAAc1S1uuM/+0oOnawL4PCtzKAAbqB323dNHYfdah3sYTlM1oGe5QvjfrtmfnZmPE4ogP8lFmQVQFwBAJhz1M36fUerd+eqHIRpp0QcfiiTFTBLj8XpsJv7DQGOHqu5/39+lXzNWkWKPBynGMA/EguyCiCuAADMIb195r2HKj7aX9pjspKAEIovmi11KZ5w2K3mPj3LbuBSzGsvSbtqbVpYiAAnHWD2JhZkFUBcAQCYKzqNfa9+cjL3+FkSEMziimaq3/z0sFkHnGaDfdBwQUbM5luyMZ4YwGxMLMgqgLgCADAnqJv1r3x8Mr+oMUAYEcAXM5isOXLgTqfD3Kd3DLSlJUb88YZlmMIFYBYlFmQVQFwBAPB/heXaN3YXVqk7nZxwrjBszpaDpd/ItHREiLkbr12SszQRFwaAjycWZBVAXAEA8HP5xQ0738039NkcVBibH4ICIYRYB3sZlk42w7p5w4rLLkyZy0Wx7k/vNbXocUn4n1ipaO8/Nsz2xBIQwEVWAcQVAAC/pW7Wb3/lB41uwMGRBHCEKJAhbNYBMqgL5Tu3371mzjYPW3jNC+HxS3Ax+J+OhlNnPv+/2bv/dGIx9CKrwAzA7F0AAFOut8/8wgf5ucfrGXwpOyiKhRIZ8YYUwCMBcXqz6X//fiB9XthfN+Vg9DAAH8EJoF7bdqXFYkdWAcQVAAB/89F3Jf/afdpGhXLE81Ea4wrgCAkn6Uxj13X3fbz+UsXtV2dxAnCrAvCJxIIPIyCuAAD4lcJy7fZXvx+wcUlgAnvWTvU4Mw9GArGTF/LpYc3neeVb7lyFXvgAAIgrAADgNb195kdePFiu1hOulBLwUSCTwGCyWPwou0302JvH3/mqeOcD/4O2YQAAiCsAMEm7du3S6XQoh3FJJJLNmzf79zEWlmsfev6ggyOhgubhjJ8nFsUhQfIGQ/d19318/63ZV6xKRZkAACCuAMCE6XS69PR0lMO4ysrK/PjozFbbix8c++6YmhmYQKH1l/ewecFOjvCFj4oOnVJv37QGnX0BxnWooK7TMHDdpQoUBcx2TBQBAIBXqJv16+//+LuTnVTQPCayircxmCyGIK6o3nrd/R+V1rSiQADGVq3uePqtw58dUKEoAHEFAADIW1+evuOve7qdEZQgAqUxdSie2MKJ/d+/H3jm7aMoDYCxcYURb+xRIbEA4goAwJzWaey7devu/xysZwUnUWz0qp9yLIpDhSR9d7Lz6v/7j7oZE8ADjIkfg8QCiCsAAD7kUEHddN6Y1c36W7d80WDgM/lSBgPfqNOHEkTobWEbH/va1xqGTfMVCDDNicVstT20a39vnxnlCogrAACTMZ3NtQvLtRsf+3ogIJrNC0bJT78AjtDBl9+3M/ebI1Vz8woEmObEYrbaNu7Ye6Jq4NZHP0diAcQVAIBJmp7m2p8dUD3y0mEHX86iMErVjGEwWUQgf+Gjon9+dGKuXYEA05xY6Kyi6eaxhRKDNRyJBaYNBjIGgMlgMpkXX3yxWCwmhNTV1Z08edIHb8yEkCkaxHPnO/n7T2qcgjg0AJv5xMJgEkHcVz8112n27Xrw8jlyBYLf2PHqD5XqKZmzq9NgIiTYW5elK6sw2UGEEIrNN1jCb33083f/dg0GFgfEFQDwRQ6H48CBA9nZ2XFxcd3d3b64i1PzvGi22h7edbCiyUz4MQxcB76DG6nSGDZs2f3y1t/4ysMTEgt44Mu80pDIqZn8lB3CGz74x6QuyyFZ5dwTJBILIK4AgI9jMplCodDpdPb29vroLnr7ebG3z7zp8b3tJh7hSHAB+Bx2aHNvz62Pfv7Ph6+QSoKQWGC2COAG+vJlOWJWQWIBxBUA8FGJiYkKhUIgEBBCdDpdcHBwX19fR0eH7+6x954Xe/vMtz76ud4smu5nC/A8QrODDBbqrsf2vPbX3yKxAHjlsrzn8a81Ri6TM/IHimLz9WbxHdu++OCp6zgBeKoExBUAmFHLly+Xy+UlJSXl5eV03xWKogYGBiwWy/ls1rtNt73bXNvFbLXdse0LvUUcwBXiSvBlEuvAPG3D/z3yn1d2bggLEUzz5Td1V+DsFSHiXP0rqZBHPftx7bgrsynmS/dmHCzUfXOszWJz4Hqe8cSy+Zl9jfoAJmeswQ8DOEK92bFxx97Xt61DYgHEFQDwAplMtnLlyhH/1Nvb29bWVlJSMjyBpKeny+Xyurq68vJyQojD4TCZTGKxWKPRnOf+eLnptveaa7tnlY079urNIQEcZBWfFmbqUGqKlJrii1QdDz3keOH5P4zbQMX7PQem4Ar03WcIFuP+9fN+lR7GYTMJIa/vVe8+0uK+wiVLJL//ddwnPzS/+pXakw1abI4tb1bccknM+3/J2vJmRV1zny8c4182pGQrxIQQjW4gWBCwadcZncEvRsQa77Lc/Mw+lcZB2KHjbonJDtJ0EyQWQFwBAO/QarX79u276KKLOBxOR0dHbm4uvTwkJGTZsmVJSUnz5s07evRoc3Pzz98UFJWcnGwymYqLi9035a2OK9PRvOo8nhfv3LanuVcwvN02+JSInrYMTbFSW5zaVik1aqM/0W4mzl3P3zluYpmm1n1+l1goFmPXHzNChNT1j52KEnOf26TQdg66r5CtED9wfdKfX1GV1E1gNA59r+XFz+ssNseO2+bf/2pZu948RXueGjv01weNbmBvfuuen1qHH+NVfzk5aLHv+mNGAMXoH7T7z8dm9MvS86yCxAKIKwAwAolEkpqaGhkZSVFDP8Umk2n//v1jN9Dq6ekxmUwczi8e44xGY25uLj08cVZWVkdHh2sjkZGRHA5Hq9W6ltD97B0Oh9Fo9IMb8xg2P7OvtZeLrOLjorpblJpipbY4ua1KatRSDltKd/O9u5/bTFEvv/AHX3l48q/EcsNFsiSZYPs7VaYBW63WdOXWX0x9EyPhbbkl+f2DmgllFZd/f9s4Py5wx23z73r+jNf33GZ3/unFki03p+RkhrlqhORR/C03p9xzVUJitGDnJ2ddx5gg5d/+dJFpwEaxGISQM2e7TQM2v/rwjHRZTjSrILHAlMKMAQCz7UPLZC5fvnzt2rUymWx4VjlPDoeDbuslEAjCw8Ndy+Pi4ggh7gMWh4SEBAcH6/X6vr6+2VR8E5wobXL3bJhm0QZtZmNhZlNhSluFzKChHOeeJjP0jbd//erDD71jttpm6RXosygWY+l8UYfRrKrvGXGFK5ZHEkK+ONoyue1bbI4vf2xJjBYoE4PH3ZOHbkz6YOvi3J3Z7v/dv37e2C/U6Prd/6lu7X/mo1qzxbFmUbgklOM6xh+KOuimXxSLGSXiNLb1++FHiBIeK2nyyvcekx2k6eZt3LHXhz504AdXKIoAYHZZvnx5XFyc0+ksLS2tra09z27uw/X399tsNoqiAgN/0UJmSLuv+fPnUxTV09Mz+0rQ41+4d76TX9FkxpjFPi5G30jXq8zT1UQbtQyn0/2v2ZpSsvsfDxPy9N9vQx2LF63NkqTGClXqnhGrGtgUc3VmWMn5VUTkl+ktNsevl0eOUT+TJBPuuifdYLI8+3Ht5KpxfhlgBgYtdiGfSpAKdAYznU+OnDk38uF1q6U8LutoaZe/fYQsBkUM0zXF6o5XfyhtsDB54ZPeHpMdpDE673n863/tuApfUIC4AjD7pKWlpaWlURTlPhM8k8lctmyZXC4ftx2XSCSKjo52Op1D+pZ481GKz6coauxOKSKRSCQSkV/Wt/hZYnnry9P7TrYw+VJctL4srkv936xSKzVqR1wnW1Pa9fU7T4iDH9t63azLzGOjmzMNWahS9zz678qpa7DEZbM+2JoVLAwghCjkQbk7s+0O5/Z3qk6U613rKOcFiwLZ75ePMA7HjWtlN14UQ1EM10suWxrxx6sSDCbLpudL3HfbYnOcqjJkp4tGfYJhMe69JnH4C8+T3eGsb/m50jgukk/v9oXpYn2Pxa86rgzLKjvfyT9W3s3kne9vNExOcKPesPmZfa4tAyCuAMwO6enpfD5/9+7dF198cUJCglarpSMHXWFCCBl3UGC6TqOurm6KsgohJDQ0lBAypFNKT08Pg8GQyWTNzc1yuVwmkzU0NCgUit7eXrlcPn/+/Ly8PK/X88zg82Jhufaj/ZUMQRwuWl+W0FGXoS1SaooTO85GdY/V6Gjd2fzCH9L3Lkled4nSbxILxWJEibmucEJ3Ck+Q8p/6T81oz+63XBKz4dLYcR/Wh2SPIQYt9mu3FdxyScxNF8eMtmaEiEMI6Ru2G9kKcZSYe+22gg+2Zq3PiT5Rrs9WiOlWWyP2CekbsLMppiiQre8d4etFHiWQR/IPnenwVlbJSg4JFgao1D10669Bi/2r/NYNl8ZevFjy7v6mxvaB8BC2X3VcGZZVDhbqHN6qT2aHqjRILIC4AjDNX+w2x0u76yWh7MRogSiQPT9uYqMJURQVHR39448/OhyOlpYWsVhMP/3LZLLY2NgjR46IRCI+nz/GFuje7WQq6zToEcAIISUlJe6dUsrLy0NDQxMTExMSEmpra3/88UeRSDR//vxVq1a1t7fPvqxy7miFx0qahj8sdhr7Hnkp18GTMxno3ee75ulq6HoVeWddZHfruOtvPfKve0Ii4uMlGclRPn4FekgeJZCKuZt2naEfoB+8IZnu+D7GGLvvH9S8f1DjlX2PkfCH1EL8Iq6Ecggh+h7rkOX5qq58VRchpKi2OztdFBfB33xd4v6CdlfX9iHaDWY6/IwYVy5YEMphM73VmWRtluT/rk1s0w8++u/K4SVG1yl9/IMWWQWJBRBXAHwXm2K2m7UsYQAAIABJREFUGQYPnGp3LYkUcSNEnPlxgYtTQsZ9uc1m279/P/3/BoOBEBIUFCQSiVasWFFcXNzc3DxuhQkdV7w1dvBwEolkyZIlbDa7pKSkqqrK/U8Oh+Po0aPuS/R6/aeffuo3t2oXs9W26fG91gBpACsA17zPSm6vorNKfGd9RE+bJy/h2G2P7f/HZmHIv17ZNO7QxjN4BXquVmu65q/nGpTeckkMPcjVGLUiXsRlsxYlBY/RMioilEsIaTMMjrYFja6fxRQ/8YcFxyv0o2UVt29aTmXjqF96G9fJN66TD18+Rgoa8eV2h/Pd/U0ffa8dJZ7xAijmkJGakVWQWABxBcDnrFaGlZz9uWajTT/Yph9kU8xbLomZ0Hbo7uwCgWD58uWNjY1DssHYGAzGqlWrxljBk4GMXcLDw2+88UbXP1tbW3Nzc2dlVYmXnhSf/tdRfT8vgIfpIH1XamuFUlOk1BbHd6nDeycwIb20X3/vobcffjTo5efvmO1ZxR3dxGt/QfuQKRqnToyEx2WzjlfoR2sZZei1EEJEgezRZk05UWFYnyPTdAx4kiiG19K4Gz435YTQL5dH8Z+9S3HrZbHqtv4RI98FC0L5XNajG1Juf7rI63NEWgd7p+hMjTyn0LRlFSQWQFwB8AVLUkO3357KpibWashoNHZ3d4vF4uETL04z1zSRIpFo7dq1UVFR2dnZhw4dmptZ5Yvvy4+eaWcKY3Fh+6wFLWV0vUpcV0OYqWOiL8/WlJb99N1r/4696/dr/SOrZCvEdFbx5LnfK31XiAetsOhGXKJA9mgrJEoFHDaTyx7nmzNUGEDGrKXxFnVr/67P6rbfnnrPb+Wq+hGGO/NiO7ohViyU63unZPaqToNpwCLiBUWMcflN05gi7NDSho4dr/6wbdMafIkB4gqA95kGbKeqDMfLDaeqDInRghgJT6MbOJ+s4q6mpmaiVRlTNCyYXq+vrKxMT0+PiopKTU2dUIWPf2SVanXHyx8XMgITcM37rHRtiVJbrNQUx+gbxX2dk9vIXad23xOZlK+IzV6WPNuzSpJM+MhNySp1jydZxYvP3HTHlTFaRtGVKqFBAaNHrJiGtv6wYLaQR43ReV3Ao1xbG46uoslOF3ulWulkpb6qyZQaK9y4Lt7D8vSKVx69coq2/NonJ4ae7l9efp8dUH10sJbJj5mGw2Tywo+V63a+k3//bdn4KoMJXz8oAoCRH997Ld8ca9v+dtX67aeOnOlanBLy/tas5zYpVi8Mc91xJ51VpFKpWCwmhAQHB3v+KofDYTKZGAzGkBlRvKW8vLyrq4sQolQqBQLBnMoqZqvtj09+7eTHMNC93lcpNcWZTYWZTYWxevWkswrt6f0vPPfC153GPt+5AieBy2Y9decCg8ni6hq+5eaUa1dN+dDb9IhkY0wQSQipbOy12BwZCSN8v122NOLBG5Je+qL+aEmnKIjN57LGOunzgsaYTUXd2qdu60+OEdKzOp4nm9358fdaQohrmkj//gL87IDqjT0qMi1Z5dwtjCM5WKjb+U4+vs1gwl87KAIAdxrdwKkqw8FCXbvenK0Qr1oo3nJLsnsmyckMf/+g5tIlEX++ft7k3kIkEi1fvvzMmTMKhSIoKGiicUUsFk8o5Exo++Xl5StXrmSxWAqFwjUtzDTwbtNtT5prD/HMW0ctzFA2xcFHwAcxnQ6lpohuAyYzaEL6Dee5wUDrwL1H333imYhdT95MpqDnwCSuwElkhmc3KQYsdteUI5ctjVipFP9Q3DHVp4MePri22TRGrYi+15Jfpl+SGsKmmBabw/0nHkLI/oL2E+V6FoPBppgrM8QldT13XB73yBvlQ7NKYrAokP3aV+oxAsZLn9ftuif9hT+m//3DCU8TGSPhk/9Oq0LLV3UdKu7MyQx75KbkKZ27Zg5mFffEQgjqWABxBWDi6pr7DhbqTlUZrDbn4tSQTVfKlYnBo9zheJ60/x71I0dROTk5TU1NNTU18+fPF4lEAoHAfcjgsVVWVkZHR7vP2eJdLS0tXV1dYrE4Pj5epVJ5vmPnw7tNtz1prj1EaU3rDwVN7JAkfBB88S5lt9JBRaktjjZogwe8c6nktJQdKCrcf2ih13sOTOIKnIQHb0hOjRUSQr58fNnPb2JzjDaysBdJQjgcNlPbMTD2at8eb8vJDMtOFx0qPlcVtmphGHEbsItufLVxnfzM2e4d74zQ+vTXyyPp2DPGu9RqTX96qeTWy2Kf+MMCzi97wozRn4eeo4YuwMuWRhBCXGt+drh5RZpIIQ/6ZPuSqehVP5ezChILIK4ATMapKsOxcv2xMr2Ax1q9MGzrzSmJ0eM3gppEVhGJRBdccMEPP/ywatUqq9VaXFxMV5WIRKKQkJC+vj6ZTBYdHT1uhYZer29ubo6Li1u5cmVpaWltba13R/GakQoW7zbdHre59hBmq+2v//ye8KPxcfBBHJtZqSnK0J5RaoulBm3QYI8XN/7nI2/dKY577427vTuu8USvwMl58oPqJz+onpGTsmphmN3hzFeNM2JySV33F0db7r0msaKxl+58MmSfbXbnn14sGe3llyyRZKeLtr9d5aqcGY26tX/72xPrazfGW9dqTVc8ctyvPkW+lFWQWABxBcCzr26bI7+sy9V1fkWa6KV7M+g5mKcOn88PCQm5+uqr7Xb7N998Q2cM12SRra2tCxYsKC8v92RTx48fFwqFYrFYqVQqlSNM0e3JQMZBQUH0jJPDq3dcFSwJCQnd3d2zvs/9eE+Kb39xusfKpcacoBNmBM86QLcBS28uiTZqhd5ushU22Htj4VcvvZaw9f4rZ/AKnGUPDR50XHF59St1hIiz9eaUFz+vq2ueQLVPtkL8v9cmvri77lSVAR+E82EdNCpSBK7LL/f42dc+L2EGxs/4jjk4kn0nW0KDT99xVRZOEyCuAJyj77UcK9MXVhvzVV3ZCvEKheiuK+PHGGfTu0JDQwkh/f39x48fd2WDysrK2NjYxMTEqKio48ePt7e3e/Qt73AcOHBALpenpqYGBgZS1IQ/xTKZbOXKlfT/s1isK6+8sqioyBVLHA7HqVOn1q5dS1HUokWLkpOTPZ/FZdZlFXWz/pOD5axgNAPzOQKziW4DpmguiTY2C8ymqXiX62qO/OHohYWXZS1OkyGreOKGi2SpscLX96o97Nfx5Ps1lyyV7Lht/sFC3XsHmjx5yXN3KwghW96omGhfFBgiUMDJVka7Lr8jhern3itg+MxA7Uy+9KODtYF8znWXKnCyAHEF5rR2vTlf1XX4TKdGNzBi1/npUVZWVlZWNmShzWb79ttvJ7dBtVqtVqsn91qtVvvhhx+OFe1m+4z1Hj8pPvLiQSdXitHAfO4xa7BHqSlWaorSWsqijc18yxT2x9h66M2Hd0a89/omTgA1/VfgLMJlsz7YmiXkU2/ta/R84GCLzfHNsbZvjrXFSHgevuTZj2tHG7kYJuSmKzJvuiLTlVWe/PdxO8/HBj/kx7yxR0UIQWIBxBWYi+qa+w6XdOaXddFd52+5JGZJaiiKZQ7x4Enxi+/LO7qdAcJAlJZPCR4wKjVFCzXFC1pUUqOWZx2Y0reT9+pyVEfffm++lyeO9Lt6lUGL/dptBZN+uWu6qnEhq3idj2YVJBZAXIG5ie46X1hlDKAY2eliD7vOg58Z0lx7RJ3Gvn/85wSagfkaUV+XUlOcoS1e0FouNWq51sFpeNPbi/ZsOLDo0ssWyaNF03YFAiCrILEA4grMFXTX+dPV3fmqrhgJb/XCsOtzZFPddR581pDm2qN59ZOTjgARxWShxHxHmKlDqSlSas6ktpVHG5vZtmn6lZ1jt92V/9FLL8fQ07BMzxUIgKyCxAKIK+Dn9L2WwirjMZWe7jq/OCXkjl/HTlvXefBZ7s21R9Np7Dt47CxHPB/F5TskPe1KTZFSW5zaVik1agPs1ul895yWsteqG6rVHSny8Gm4AgGmQWlN69/e/JEI5LOjex4/5rXPS0KCuBcvn4dzB4grMLvRXeePlevrmvuWpIbOVNd5mNVe/eQkkxuOHva+I7K7hR4HLKWtSmrUUo4ZmE38rhOfvvZmvFcqWABmXLW644FdeYQfP4u+6BjC2OfeK2AHsFYtluMMAuIKzD51zX30AF99A/YV6aL1OdHoOg+Tg6oVXxNt1NLzqyTpqqXGZpbDPiO74cUKFoAZzyr3PrPfzo1jzKr2rgwG086LefLfxwkhSCyAuAKzRkld9+Ezneg6D16EqhWfEqNvotuAzdPVRBu1DKdzBncGFSyArILEAogrAONz7zofIeJcslhy9a+kno/ZDzAGVK34lLguNd0GbJ6uVmrUzvj+oIIFkFWQWABxBWBUpgHbMZX+mEp/qsqwJDUUXedhKqBqxXfIO+qU2mKlpjixozaqu8VH9goVLICsgsQCiCsAvzC86/yfr58n5OHKBO9D1YrvSNTV0m3AEjrrIrtbfWfHUMECs1SLrufuJ79hCBMZfjE+O51Ynnj1UORfhPgwAh4KYWbQXeePlesNPdYV6aKrfhWVrRCjWGBK7TtaTXFDULUy45Lbq+g2YPGd9RE9bb62e+sqDu/9dtEDf8TEKTCbssr/+9teJz+O6UdzSYUOdF9YX/rEX7q2Pn4bEgviCsD0Kanrplt8BVCMJamhD6xP8puu81wut6ysDKfYk4Kaqbf+9GAZYUtxCmZWamuFUluk1JyJ71KH97b74B5e2lCw4XjNvRsv4QTgFgmzJqv0M6Usyn/mRw4a6M6pyltTlXvr8aY/28wPPL0RiQVxBWAKWWyOU1WG4yoD3XV+tTLsyTsX+F/X+W3btuFc+7JqdUdvv40dykdRzKAFLWV0vUpcV0OYqcM3dzJssDelq+lYcWPO0sTpf3c+j93RcAqXiv/h86akK6ZfZpXAwZ41Vbk51XlJuhqWw7bryyc3E+KviWXdn95ratHjAzKGWKkIcQWmCt11vrDamF/WpZwXvCJNhK7zMIM+PVhGAkQohxmkaC6hs0qsvlFs6vTpB4iyvL17Fs1IXDn2wd24VGAuZxWB2ZRTlZdTnZekq2Y5bISQQOuAHyeWphZ9ePwSXMxjFVHDKcQV8LJ2vflUleFwSWdlQ292unh5Wui91ySg6zzMLLPVduCnGm7YAhTFTMnQFC/UFis1xTJDk6ivy8f3Nqel7Ina9k5jX1gIJnoCZJXpw7f0natXaa+m7DbXcv9OLDAuPESCd2h0A4eKO+iu80tSQ6/6VdRzmxQoFvARh07WBfCCGH7UCXUWYTodSk0xPQ6YzKAJ6TfMit1e13Bi78EVd/xuOc4g+KDePvPGx/b2MSMpP8oqPOtATlVeTlVecntVgN065K+B1oGn9z5zH8V5etdGqSQI1wDiCoCnXF3nCSErFKL/vSZxflwgigV8zUfflTmoEJTDDNxjHDalpohuAxZt0AYPGGfLnv+m+uh9+1YhroBvZpVbH/3cxIigAvynFyjHNphTmbumKi+5vYpts4y4Tthg79N7nv4rxXjs2f+HxIK4AjCOfFXXcZXhVJUhNCjAX7vOg9/oNPbVNnQKItNRFNOMbTPTQUWpLZYamoMGu2fRzst7dYHdXaU1rRnJUTiV4GtZxWANp9h8P/qusORU5uVU56W0VXJs5jHWlPbrH9v91F8JQWJBXAEYwfCu87dcEhMh4qBkwMd98l0pxQ9DOUwznnVAqSnK0BRnNJdIjdrAwd5Zdwi/KTn49b6sjOQrcDYBWWUKn0Tt1pyq3DXVualtFRzb4LjrI7EgrswhLbqelo6e0urW7j7zyTLtiOtkJEWIgniLFTJxCF8ePUfHFKK7zh8r15ec7c5OFy9OCUHXeZhdfixuZLLREmxaCcx9dGcVRXOp1KgVmk2z8Siy26vePl2PswnIKlOH5bCvqcpdU52X2lrBtQ56+CokFsQVP1et7sg7cfa7/BpDzyCbw7URnsPBDOCO/CijLTA4HZ2f5FXbrVYem7VqSfwVq1LnSMMAjW4gv6zrcEkn3XX+18sjtt+eyqYwHTjMMmarTa3tCoyMRlFMm8DBHroNWFpzabSxmW/pm6UHIu3Xk8HBFl0PnocAWWUqMJ2OnKrcnOq81NZynnVgoh9PJBbEFX9TWK49eKw29/hZB2E6WcEsrpQfzh/3+AO4ga5islgH9hUYck8csFnNFyhjL/9V8orMOP+b87iysffwmc5TVQarzblCIdp0pVyZGIzPCcxex4ob+YJgBgNJe5oEDxjpvvVprSqpQTvRRxBfk9NYdKig7qYrMnFmYQaZrbZNj+/Vm0UBXL+a6DanKndNVd6ClnK+pX9yPyhs/fLZh1nsl/+xMVCApumIK7PZe3uL3tx9iuJwrSSQHZjInuyQf1QAjwrgERLBtFtP1HQXVh23Dub+7rKM23+b5QcfknxVV2G18ViZPjQoYEWaaMft89F1HvzD8ZImK+Gj8eL0CO3T023AFrSWS41az5t2+KzFzRV7j5UjrsDMZpWNO/a2moSun1D9w5qq3JyqvAWtqvOpgJX36rZ+8czmAOau5+9EYkFcmZX2/1T997eOkoBgtiiFyfJaPQiTFcAVhhESxhLavzzaujv33T9cvXj9/2TMupoW04DtVJXheLkhv6xrfnzgamXY9TkydJ0HP3PkVEMALwblMA3CTB1KTXGGtnh+a3m0sZltM5M77iCPPkri4wkhRK0mWVnEYJhdB7W44+wT9Z1mq83/6tJhFmUVTTePyfar9k6rq/JyqvLSWlSC8+7YltLd/MAnT28mBIkFcWWWOVRQt/O9n/osAYzAxKmb7ZXBZFHCSBY//O1vz7715en7NmSvy5kFc2brey3HyvR01/klqaErFCJ0nQd/1aLrMQ1a+IGoKpxykp52pbZYqSlKaauMNjYH2C3ko4/Ib39Lfvc7cuAAefddIpPNuqxCCAm0DsQPdJbVtC1Ok+EsA7KKV6yq/iGnOi+tpVRo9s6AgUgsiCuz7+nkvuf2tRtshCulAqejiSeDyaKE0Q67ZNdHJbvez3/x4St8sy++RjdwqspwsFDXrjdnK8ToOg9zQWG5ls2drbd5Lpv1wdYsHpd1+9NFOoPZl3c1sruF7luf0lYlNWoph41s20auv5689Rb5+mtCCLnhhtl7FS1WlxSeaUBcAWQVr/hVzaGc6jxFc6l3BzdHYpkrcWXXrl06nW7a3lgikWzevNnrjyYPvZBrZ0cFBE13+04mK4AZGGu3me/bmXvbbzJuvmKhj5zguua+g4U6dJ2HuSnvRL2dKUDV4ZSSGrVKTbFSU5ysq5YatSyHnQgE5J57yOAg2bHDDw5wRXPZcz+V33XThTjXgKxyni6sPbKmOi+9uSRosMfrG0dimRNxRafTpadP36zPZWVl3t3gB9+cefdrFUOYGMBkzVRpsiiOUyB/99uaOo1+26Y1M3heh3Sd33pzSmK0AJc7zDUFZY3CCExmP4Vi9E103/p5uppoYzPD6SCEkIsvJuHhRK0mvb1+cIwZ+kZ1Z19vnxkPQDBt7n/2u0Y9m+L5VVZZcfZoTnVeurYkaKB7it4ipbv5ri9ffJjHff7Z29DfzD/jyvmQy+VxcXGEkNra2ubmZm/t3KGCuk7DwHWXKsb9EWL7Kz8UVhmdgrgZH66UwWASfvTRso7rH/z4zW1XTej25uHxjsbVdf5UlSExWrAiTfTSvRnoOg9zVqexj8lgMWbu9wu/F9fVQGeVRF1ttPG/k+2y2eT3vyeEkObm2dhZZeR7nK1X3ayfI5NuwYzb/My+6lYGxQv1p4NaXvfTmqq8DO2Z4AHjlL7R4o6z5i/+8TCTPP336U4s5/kUN9XWZknWr4muaurd+cnZ6XnHWy6J+Z9lEZ8eat7zU+u0xpWQkJC0tLTS0lKlUllbW9ve3k4IEYlEYrH48OHDXj/OanXHm18UEkLGOPe9feZNj+9t7WEz+dEMn7kmmLzwtr7eGx/67KVHLpdHi7x4vMPRXecLq42nqgx01/m7rowXBbLxjQ9zXLW6g8v350rFGAnvxrWyX6WHcdhMQohGN/DGNw0nyvWu+8SGS2P3F7QPuTMNX07fw+Ij+YQQu8P53Yn2f+9rNA3Y6L8myYS77kk/dKZjb37bgzckxUfy2/SD97+iEtRW0P1VEnVno7r/+yvVRx+R668/9/8XXkicTkIIuf9+8vzzs7qoUzrU1eoOxBWYnqyi0jgI26+yygX1+WuqcjO0xSH90/ETRramlOz+x8NkuhPL5J7iJnmMCvH221Nd/3x9r3r3kZZRn/VZjF1/zEiSCV77Sn3+ycFz7x/UtHaZ16+JvmaVdNPzJa7bypTHFaPR2NjYuHTp0h9//NFisdALo6OjQ0JCVq9eTSZeu9Ki62npGLX9YktHD1cY8cYe1WjnvrfPvP6Bj/sZET44GHkAN9BkpTZt/+rFLVekyMM9OeRxj9cd3XX+8JlOjW4gWyFetVC85ZZkdJ0HcP+sORgB/lq3csEC0V9uSeGwmRrdQKt+MCyInSAVbL8tdfs7VXRiOVFhWJ8jWzgvWMijXDcJisVYOl9kdzjzVb9INXaHs6y+Z8BiVyYEX7EicnFqyJBbS3QYb9c96Rw2s11vFgWx4zrVMU2nlZrihM6zkd1uN78bbiC33kp+/JEsWkSuvvpcP/vZL6pD29pmwGcKkFUmYWn98ZyqPKW2OLR/+j5EM5VYPH+KO0/5qq6dn5y9f/08Qshb+xrHyCr0qC0DFvu1fy04n8AwOXmndYfPdOz6Y8Yn25ecz7AxkzmFJpPJlVUIIQaDwWq1VlVVTWJT12z+YOyfPyl2GOGHjHju6UlefTOrnLvDDfZu/P6NJyzG51/8f2EhAk8OeYzjpdU19x0u6cwv67LanItTQ37/6zh0nQcYUW1Tl83JDvDTo2MxGZVNvR8c1JTUdbsHj/U50XRcUbf2qdv6U2OFly2VuO5ky+aLUmOFKnUPvU6STLg+R9amH3SFE4rFePCG5JzMMPdXEULSE4JcqyW1V9NtwOSd9RE9bcN+qgkgcjnRaMhPP/lNactNur3VGnymAFllopaoT6ypzl2oKQrt00/zW89UYiH8mOlJLL39NkKIxeb4vqhj1KdKFuPZTQoel3X3CyXTn1VoNrvzgVdVH2zN2nm3YtJ1LBM4f0wmMyMjo7+/PyAgIDk5uaamhl7e0tKyYsWKydWuDAxahJHKyZ377a/80NrD9tmsIulp/8u3j85vrQjtbn1YyHv5hT/QnxaPDnnY8Z6qMhwr1x8r0wt4rNULw9B1HmBc1Q1drAC+vx5dvqorX9XlvoSuTnG/QxRU6lNjhdnpYlfwWLUwjBCSX3buhdetjuawmV/91Oq6f9jszs8ON69IE7m/ir4j3v+KyjRgS22roMcBi+tSS3rbR9gzup99dbXfdFwhhMT3tje0GPGZAmSVCVncUJBTnbdQUyTq65qRHfDvxJIg5RNCajSmMaos6J+o9he0z+xo+IMW+1f5rRsujR3yQ9iUxBWHw3HmzBlCiCuouJb/NA2/ov3y3L/15emCqm4mX+qbH9HI7tat325LbasghGToG6/97u1t4qCnH7txoser67Z3W3inqgwxEt7qhWHoOg/guXpNF1sU5t/HGCPhZSaFLFsQSghhMRl0JxaXzw63XJkdlRwjlIRydAYzl81alBRssTmOlnYRQigWI0rMJYSsUIgzk0Ncr6K3ExbMdm9FRt8RF7SolJoipfZMXJc6zDTK73lKJSGE/PI2MdvJe3UtJhvmtocp8tS/j6oazIQn8aeDWtR4Kqc6N7PptNjUOYO7ka0p7d3z5jYhf2LPYLMhscRI+IQQbcfAqI/4LMb1F8ksNsf7B2e+cpi+H115YdT+At0kKlhm1TcvJTxW0nTdpYrc42f/810VMzDeN3czyti8dd/2lLZK15LL1AU1P+x7KzHyjlvXTOh4VbVtV12Sia7zABPV22c2W21clr+2BSMUi/GXDSnZCvEY6wxa7EW13TmZYSszxLuPtGQlhwQLA1TqniE/s6UneDRYqqK5hO5bH6tvHOv5IzWVEELKy/2swOOdpgatwb0jIoBX7Hwn/3Bxl59llcym0zlVeZlNp0f9XWMaXaYusOx+868U87G/Xu83iYX+vcm9I+Jw8iiBPJI/YvWLPIq/5eaU+Ei+3eF09Xgkbj34LTaHJ11NhvT4dxmyWdf9aKVSrEgIcl8+rXFFJBJJJJLJdV/xlMWgiGHuevDyanXH02/lMwITfPMjGm3QbNm3I7l9aFHcm/+fzcFRh+ZJJ3i8l+KrHGAS1M16gV8PC/bgDcnZCnGbfvC5j8/S3VfoIbyGrHbkTGdOZhjdsmtIS7DRbiojEpj7MptOKzXFMYamsdp1CATkoovI4CDZvdvPClze065u1iOugNezysFCnYPjV1lFqSnKqcrNaioM79X5yC6tqzxMPiZ/JWTcxLLj1R8q1ZPc7U6DiZDg6UksdBSxO5z1LX2jrXPBglAOmzm8+oXLZj1wfdI/v6gX8qjtt6fe81u5qr6HrvHIV3W9d6Bpw6WxY7cxc1m1MMzucLoPOLbl5pSczLDcQt3w24pG189ihmUrRNMRV0JCQsLCwhwOh1artVgsFEWlp6dzOByNZpI1TbaeMYd/5kopNt+VVQgh9+/c5+BKKYYvDoEVo296ZN+OJF31iH/d+sPrd4ZICWGMdcjDjhcAJqFF10NYflsn6fpd7eU9aldX+xGdrjF2m6zJMcK4CP6ipOA2/eD+gnN3Ypvd2do1mBorlIVxx9gCw+lgOh1Cs2lR0+loQ9M4Y/ukpBCBgLS2+scEke6kndoWXQ8+WYCsMrYM7Zk1VXlZTafCR+zb5vOJ5cu80pDI1Em+BzuExx7WYXJqEoskhMNhM9v0g/2D9lEfSiV8QkhjW/+Q5YMW+927Sujc0m2yioLYfC5rSAOtIT9sjXEn+tc3DUO1+IuuAAAgAElEQVSySmG1ccSpXepb+gkhsnDeZO56E32ByWRKT0/Pz89funSpRqMJDg6uqalJTEw0GifTDfGT527q7R81ve09VPF9sZEiZtez+zdHqgZtAZTAF7vPxnU1PPzdY/N0o7bYDhvsvbbo2/IN91y9bomHxwsAk9PQbLDY51A/A4rFoPvND78t0R0cH7tjfrAw4HiB3v2eRNe9DG9MvDZL0mE0l9R1Uw5balsF05kmMPfG6BvHn9/tN78hfL4/TRDpEm9oKazRELIEHy7wm6xCD3HL47LOZ4RZd4rmkpyq3KzGAklPuw+WuYeJxftjOE1BYqH72Z852z1aPxDXr1razsHRNjKkwbAr5Lj/sDUGm935pxdLXP+85ZKYnMwwlbrnkTdGbgysM5rNFseQjpFTFVdoDoeDwWAQQhgMRmxsbFBQUHR0dM3E+1aOXbFeqNJaBxsVKQL62d1stT33zo+s4CSG730G4jvrH/7ub4kdtWOvdm3tkf+cuey+TZe4xjUe43gBANgU8x/3ZgxaHK4lLV2DT7xfTY/6tf221IqGXovNoYgPGp5VaPSIYdKwEVo556u6DhV35mSGffn4Mnr+FhaTkZUcQgh5fa+6srpDqSlKERoYTgfHZuF7Mhc13XHlyy9x4gB8PKt4XVpz2ZqqvMWNBSOMbz7bEov3eTWx0DNokZFqTiZKo+snhMRFnqsGSJIJV6SJ3tnfONE4QY+k36YffPTflVNRfpOJK3w+PzMzs6enp7m5eULDFk9UoICTrYx2Pbt/8l0pgx3M9L2+swkdZx/a/3hCx9lx1+TYbXcV7Xnp5bjHtl437vECwKS1dJoYLD+pXBEF/aJVG5NJCCHvH9TYHc4bL4qhO8prdANvfN3w5/Xzhr/cNQFLh9Gsqh/anOnJD6qLaow3XxwTI+HFSHh2h1OjG3hlT71K1ZqpKVZqilJEVobTyXR4cOtis0lCArHZSG2t/11R4sGerk40BgMv+OCbM/tPNhN+tD8d1IIWVU517uKGk7+YN9ZXE0vn3pCXwoLuvXt6H7e8l1goFjNKxBm75sRDQxpoXbAg1GCyeFK14i5bIaazynlOXe/luNLf319WVnbRRRfV1ta6zxfpdTddkXnTFZn0/3ca+978vJAjnu9r1/08Xc2D+5+Qd9Z5+jk5m/+fosuq1R3Da5bcjxcAzsfAoJXhkz3cPDdosV+7rWCMFT7M036Yp3VfMuL6rj4q7vOruNtf0L6/4BctNwTmvkWaogxtcXpzqVilZXjY/lahIAoFsdlISYn/XVEch81steGTBefpswOqd7+tIvwYfzqo1NaKnKrcpeqTUd0ts2KH7zi95zU29zUW866Nl83GxBIj4XHZrBF/gZoo9wZaUWLutauin/qwZkKRI0kmfOSmZNfcXFNUchO+nQcFBbHZbCaT2dLSkpk5fc/Wr35ykskN97Xnj6T26of2P+55VqHddeLT1948gG9tgKljttjpBqswZLqVcQUO9mQ2FWZqTmdoz8gMGqHZ5Ok7xcYSPp8UFpKmJv8rRrbdarHYcTnBeWaVN/aoZldWWZslef3+hbk7s+n/3npokTLxF4NfpbRV3pZovuKjJ6OMWuJ0EquV7N9PQv873+UttxCVijidI/xpRt11/GPy7ruvvb5/ut+YH/PGHtVnB1Tnsw16yK/ObsuQeLDl5pRdfzw3PiT9QxWLyRh7MBW6+p3ubX/d6uj61r4JDdtFj0hJUYy/vVc9bvcneniA4bvtiQnXruj1+u+//54QUlZWNm0nt9PYd/DYWV+rWklpq3zgwJNxXeqJvjCnpey16oYRK1gAwCt0BhOTFYJyIIRct1o64nQrIwoeMNKT1qe1lkmNzTzLRBpGr19PbDbyzDN+WYxhg72dJjMuJ5hTWYXukEAIKavvGbDYJSGc+Ej+c3crXt+rpntmJ7dX3RRpzPrbn4nNRo4eJX19RColycnnXv/b35L33hv5T76RWF4j5DVCZl0dCz3k15DBu1zdTlxLhvRLGRGdapJkgvt+Ny89Iej2p4uGrEDPrKJS92z+59DHfi6b9dSdCyiK4T4a/pabU8JD2MNXJv8dHmCMeS09iitcLnc6EwiXy/V85WPFjRQn0KeqVua3lv/5wFOx+obJvTyn9uShY6sRVwBgStE9Mu0O5yeHxu9nGNqnV2qKlNriBa3lUqOWa51Iq+g77iDXX09++ol8/TWKHcAPsgrdIcFic2x5o8I1YPplSyPuXz/v9svjjpZ2BVWXXVR3OOu++4nNRq6+euhnn80mjzwy8p+QWP477/lknp/ZrEVJwUM6rsij+E/duYDBJO616PQ4K+MOHExPh5KVHPL6XrXnA8RRLMazmxRCPvWvbxpcWeWypRE5mWGv71WPlrLGntfSo7iybds2n/3MfJ5X4aCCZ3w35FH8/1kWkV+mt/74058PPh2jb5z0pi5tKLgv98xdN12IL3GAqWAwDjC4YSiHIQNNjkFs6qSzyvzWCqlRy7F5XJMgEBC1moSGkn/8g9x7r7+WpNjc0zXgwBUFcySrEELoiWXf3tfoPrnT/oL2RckhOZlhVyU4nV/lLtUUsG2WWX12ZiCxnMfcevRs9MHCAELI3+4Y2uZoSC063dArOUYoCeWMkUPo3vYqdY9rLGNP3HCRLDVWSAjZuE6+cZ3ctXy0AQDolDXp/jazYOSc3j7z2cZOniTt/H8niBJzJnQyhhT0hktjd7xTpWgufeDg0zLDeTXOlvfqiMmkbtbLo0X4Kgfw/u3AZpvtXe2nk6S3XakpztAUp7ZVRBubA+wTef7o6yMSid8XEcduMztxpcBkHCtpIpRwdu3zGLN20E2MsoT9VP0xmb6RPPUU+fJL8sUX5Pvvydat5PTp/34LW0b9k49J11Z8WD1dgwSc3zzg6tb+O58t9nBlm9358ffa7ben3nJJzIjzNtIn+vqLZGMMQEy34Bo+a+T7BzXvH5zABPF0s+SP92on1x1/FtzO84sb2PwgLz55XLBA9PTGtGc3KUSB7C03Jwt5VJJMeMNFMorF2H576rObFJJQzgULRA9cn3TPVQmuV61eGCbkUXcrHH8++NR5ZhVaTuPpQ/nV+B4HmAo2mwNxxUOR3a2ZjYWZTYUL2splRs3EsgoAjGfXg5crYpjEMpvmTnUNlVvf0jfkTyH9BkKIVCI418Zkzx6yYQOpriaXXnpupI3Vq8+tOsaffOchMyZj97V/ev7vG3w/q0zCyUp9VZNpzaJwSShnxBUevCE5SSZ4eY96xBTBZbOuzI4qrDZO+rd+9+14OPvkbI0r+36stTO9+bPEiQr9X/5VUVxrTI4VNrT1KxKClqSGqNv6f5cT/cPpjo++1163OprFZKhb+17+st71KlFQQNHnPy6778Zog8Yru7G6/tThQ6X4HgeYknstxXQ60XRnfFKjlh4HLLWtMtqgoewYqxcAiYXY7I5WvZnFZCRIfzGrdVxXg7yznhDCqXB7gHn/faJQkPnzyfvvk5gYkptLfvOb8f/kM1nl6b/fxgmY+tZG055VCCE2u/OBV1UDg/addyuEvHPHeMslMfevn0exGP/4X+VKpdi9o/wQ162WHq/QjzZLvcfRl/HsJgWPyzqfkY59Pa6YrbaiCi2b580Rfm5cK7v+Ipm+xyoL+//s3XtcU/X/B/AXMMZljjsoA5GpMBQGcglvmM5LIimRWqKmeYfyftf6JqiZZl4q9RuWaVmm9vWb/tBSvqhoXjNA5ZIgJshVLgIyLgMG+/0x4iYiwgZn2/v58A85Ozvb+eyz7bz2uen/mVQ8xNmsp5XBzcRCnrkBgMqqmu/PtdB4ItQvG//jZl5xpqKehmvho+yC0oLiMvocJ4R0CduidPf0GPf0GMHjezZFGTq1NFEvIZRY6i5zn50Gt2fho1F/Rzl69gaAxGcuYZOSMHMmQkPBYsHBoa03UVZRMklVTeCmP4tLpSc2eQf4WAPoaWXo69397PYhDracxgPln/XD/zKe14usjUZ7Wp36eJC5ke7sbbFtH8evenElOTVfl62vpa2jkKP5DeqxZX5/Z76RlYme78DuAFIyS/XZOn9nlQH4v2s5Y7ysXnEyHe3ZfMIu76wY5yf3rbIUvFSzV3FadEImCCGK1t2CWyulTk2t6fUkzeNRtEd6tGNukm1RhjY1RrUq29CMZ0jdC4kGJZbLdwoAzPbrJV9oxbYoQ5R0foyHhZ6HG1JTcegQAHA4iI5u0sXLyanuP63cxOysUi0Rt/sf07JKffhc/MXdHccevD64x9siG2tzfQD5xZVrwxI72MurdUNdzOf42R34NW3a5uiOZBUwf6h9cmq+TEdfMVUz4cm1hBZWSauqrls9LSWz9KODLYw08kr7Y0V+hEHOeBQp+CPGMf3e/b8f+/oI6EOcENKZ+AV/u2Xcdsu83Sf/gXVxFhUIIZ2WWJZv/y0howhsU4Y8JTZLe88SV0lVww8W2U8kW35IvpbwJOp2gcjdYsf7Lsn387s9MbI09WQ7OUAqxdKlDVdEdnaIikJSElJTYWcHZ+eGMNPKTUzNKkMG8AvFxe07bEFRaUWVmYFRd0ZllXrnY/LOx+QB+Dmqkz7zn3fhrYZxJTOvpLqGpau047N0tM7+8biVzOedemPplS/Nly7Ajh0Kf3ReeeGltMf08U2Iwhlx9HPE1LWpZX3yUtwyb7tl3O5d8KDH0xyGPks2GwcOYNIkGBpCKsWFC5g6VeG/GbWdWNeAq8+iykM6btvy14I2hmc8LdFmGzHkKZkZsRv/qf1PO+InPybH3i9+d5S1wNESsIRUiosXsXkzLl2q26OsDKNGYdMmBATAyQlSKSIiGt6qrdzUdZKNbQ6Nm79784wW+4D9+6M32n3ksOM3m0+WxZisouqY/uF772EBi22gvONLa2SJaeLn3Tro4bXFF3ZZiXPx0UfKeHS+OO9Q5hOqhYQonHE3vdpa6gzWAofcZPn6KvyCh91LmPpzCZuNK1fg4VG3wNyMGQgLQ0wMPD276lpHzDbgGrKp/pCO09Nl7Q/xD9oYnvEUXZtYJFU1k0Nutb7Pncg7Znu2v3o/qk/+c8YwxMfjzTdf+qauyyqfTVm3e9d8LkdP6Q9GWUVz4kpJmURLW79LHnrIgyuLonZbivOU9xDc6gqxhObhIUSt6LN1fvzQU76Ml1xNrSz+YcmP/8tovNpalxA8/kveB8y+INVKnMvcQly/Ht7eWLmybjHsH35A794IDcWOHZg7l+oYocTSOaxKckVJkcNSLj03q6gUyiqqi+kDB3MLxNqsDv2gNdTF/OBaj21Bziun9H2Je6VcXnxxV/Os4uGh2An4aJlkQpSkj61p1w61l0eUW0lFt5KKCoqrBvQ13vG+y+ThvC58Sv2zEzzSYzzSY3oXPGx/VmGz8ccfqK5W4mykbDb8/CCR4MSJho2nT6O8HCIRTLumx3+2oRnPmlb1JQpOLD2NK2qrSpj5DC3FeSOTIl9NudQ3L0UNCpyyikrTiJ64v918fOZG7mfvOY/2tBrtZamjrbXxuyQXvtEwV/PyypqY5OKAYdaNN3pY6xh+fdFwcySOH8fOnTh+HEZGCA7G6tUYPhw8Hg4dqts4ezbS279kJC2TTIi6qqmVbfvpfv24uBmv9Zw51m62X6/f4550cIKU9nHJinPLiHXLvGNXmGZeWsDosnNxgYtL3aJy9RISkJAADw/4+NQ1uRCiFomFmW0s5qUFoqTIV1Oi+ubdp6xCWaXLMb11RSFLU/ex4ayb7nD5TsH5mDz5ApEuvY3qF4KsXzVSvlEr7i478C1DSxN4e0MoxKZNOHIEW7di8WIcP44dO7B/P1avrtu4ahXVIUIYyNzEUFeHQUPtj17ITEovZbO0X3U17/xHd828LV8LsteTVKZnFQB2djA0fOYKoAoPH3bhog0FelwLa3N6ZxFlJBamtbGYlT0ZmRQ5/H6UQy5llZdTLSmmrKKJcUUhS1P/nVUWeijpxOXsxgtE1t/aeKNL1l2fB78bVTTqX96nDwCUlyMk5AUbCSGMwbc105JVMvbp9bQyWDvN4czWwZE7h0buHHpwrccg5yYdjRxsu53ZOnjllL4Ott2+We0euXPoDx96WpnqvdR9+daGG2c5Re4cuvP4oqkntvTub2tW9gRCIRISIJNBJsOFCy30rZoxo2GH6mp89VXDPkePorIS3t5gsRAeXrfPihVtui8ADw+UleHbb+HhUbfbw4ews2v+BNzcAOA+s66T0qx729tZ0juLKCOx7Fn/urFukbSqnAnPx7S8SJQUOfz+RYe8ZEDle4BkG5p99sayTZtndkJW4XL0hrrZUFbRxLiicPULRD67sW/u/XEJZwyafV7s34+ZMzFuHN55B+npGD0a06Zh796GjYQQ5rG3Ma0sr2DQLy862tZmejW1sswCyaD+Zl8tHzDa0yqvuPJWUtHD7LKeVgahs5yapQ4ANhYGuxcK7XsY5hZWymcafan77lniNqi/ac71uMrkB7q8HtxTP2PvXsTFwcwMZ88iLQ0jRyImpkmiCAnB4cMQCPD77zh7FlVVCA5u2Oe333D2LMrLAdTtcPo0YmPbdN96ffviyhU4OyMtDdbWL12Uzs5dE1dMbextTOmdRZR0mfv95kmmuvldnliMK4pFSZEjki845CZrydQhq2yYvH7TZwt4Vp3R1276eHfKKsr6DmX48zM1MiyUVuuw2p+JG69Q89P5FpaQl28c/VdE8OU9nIp/1gaSfwFPmwYA58837O33T0X09+/42RXocy3YWlQLCVE4CxNOraxGVlujpa3DhOfz1giecTfdx4WShIclbn2M76WLG08UJh/ZMkVkczOxsPG9hL2NHhdK3tt1t7SibgpBB5tubb9v2r2s24s2Od27yinP1/vfGXh7Y+FCHDxYN7kWh4PUVPTs2TAaxMMDa9YgNbVhvmA2G99/j8BAzJ6NXbvwww84frxuiuEdO5qMIXnhfeu9+mqT3Z5nzhzMmcOcGpXK4vJtaKg9UW5iefej/xZVWbLYhl3yHIwkJaKkSFHyeYe8+9oylZ8HqJOzClEqbea/gWW1Su+APibx7HuXvzSuKO7ksxPrGnD1dKgWEqIMPCsTaXWXNbDoaGutm+a4ZX7/LfP7n9k6eOZYu5pa2b5TqaUV0msJT1Z/ldB4UuObfxVVVrVwcVAlrV3574T6rCL//aVt95UV5T69uzC0/19XbIsyjZ7m47ffAODq1YaJgMvKsG9fk9Egq1fD0BB79zYEiaoqfPYZystfvHhC2+8rkWDEiBcvn3LwILS0mvwLDQWAxMTOfzUL9Ll6LJ3OGKRLND6xdFUbSzeJWHQvcmTS+b6593VqVX6NXcoqaobprSu9eCZ/54uV+hBjE34N+n0fV1LSJW8nnkU3qoWEKIOLQ/eLd8W6el3zFtPR1hL2rvuaLCypiowu/Pa3R42DR08rA3cHk4H9TeU767Fb+PHofkZpi9OItX5f/eoKbVltTU5Ov7+u8oozu1WWAsDdu8BzBoTIu1ex2ejdGwDeeAOjRzf6lmDB0BA2NjA1fW7GeKn7Npvyq+2cnLqqLiUb2whsjOk9RTonsXR+GwunsmzkP+0qrFqVXw5OtbKKoQE7P+1PqvytFxHT44qgl/mlO0pc931c/OkFv/+7W6W4S84ujdvdvi+PKiIhqvjp0boqae3sbbEthg2Wjta/ZgqGurRnmqkX3pcrETvlZGvL3DmVZYZFGYZVZS/9GK++2v7T7sh9m3F0bGGjVIqULlgCgj6riRonFoOqcnkfMMfcJFZNNWWVTnb9x/ep2r/4u4/hz8/expQFZa315hcXvuDKvznynx4bGz4cAgH+858Xd1fo4Fdgd3tHfg+qhYQoA8/KSAdM/OpdM9VxqIv540LJjmMP5N26HGy77V4o7Ph9jSuK3TJuC7hPtWW1etJK7XZkFakUEye2c2GTjty3MXlDUDPyBhyptOVblX0BZNqDZ0vTgpHOSyx7141fsDm8XMrryNjdttCvrhiZFDkyOdIxN0lX9bOKWNdgw/jlq0PfpT5gaobpY1dcHa0rK8pkShjyNf7uqaDf97WQVTw8MGkSjhzBgQPKPrvoHk5eLrZUCwlR0o8dNdUSpj0rlo6Wtbm+fBxL4yEoHb+vaVmhe3qMe3pM37wULZnspUfKdmRhE8UuihIZifx8eHk1meNYVxd8fvs7knVMmpU9TQtGOhPPyujrj/wNa7NrpEqckF1PWjkyKVKUdN7xcRJbWqXqhSbWNVj+5gertwUJ+PTjAsWVTv+NoSfPRFpZptjD+t/5ZcGVf9d1kxg/Ht99hy+/rLtt3DhERqK6GpWVLaxIoDjZhmaVBoY01QwhSsK3MSsvr5Axfn4blo7WWyNsWhy70vb7smqq3dOj3dOjnbPjLUty2/lUjh8HgEWLmn/0zZiBESNekEzact82KivDhQvQ18fkyQ0bV62CpSVOnuyS1yjZwJIugIiaJRbdmipRUqQo6bwg956etFLVi4uyinpjMf8pThrVf99//4I+V1EHfOP2iXlX9+vXTxnEYiEursk8m35+sLNDN+WO0D1n/4rvCGeqgoQoT197y8dlZbqK+/ToOGmN7Na9Qie7bqGznP5KE1dJa13sjdqYVVq5b7fKUveMGKecv2yKs3Tt2jso/NQpHDuGwEAUFiIpCampYLEwZgwArFyJS5fqdktKAoBPP8Xo0eDxcPgwdu1q633baN48jBqFTz9FSgpOn8aMGVizBlevNvmg7izZhmZsfV0LEw69oUiXJBZl9Apj1UpH3osUJZ13enxPn3mt0JRVSDMqsEzkUHf7aslTRR3tzdj/zLsapt/K9KYsFlJS8M03KC1V6nld7+s1ZJCAqiAhyjPhVUFt1VOmPasf/pdx6OwjqVQm7G3k6WiSV1z50bf3npZWt+++u768Vv60rFtlab+cRNviDN2ajvXomDoVc+ciLQ1OThg3DiIRkpLg69skJ2zciB9+AIuFceMgEDSMfW/LfduorAyjRuHMGYSHQybDwYP49lsMG9Ylr1cUTyga6kTvJtKFiUWxbSw6tTWie5Gi5PP9Hv+lX12h6kVEWUUTaMlUYdXSicuOFEotOj4h6aSY47Ovfd280TMgAL17N3yhcjg4ehT/+Q8MDbF/v5LOqECfGxiw+fzRpVQFCVGe5NT8BZvD2aZqe63JK85yy4h1y7ztmJvMK85Ug9USGGj52OX+mxaKvPuo0HOeErw/Ob+CXjtFEVgaHA8L6sInkJ1XsmBzeLm2AtpYtGSyUfciRiVF9s+ON+yKBV4oq5B2YKnEsxzn43Ak8hE6FlcmRx+dfe0b9rM/PZ461eTPsjKFrFjfuihroWhgH6p/hCj3IoNvWSuV1tZUa+voqt/Z2Ralu2Xcdsu47ZCXzCvOUoNVqBmoUocVb2S7yVnF5kRJzq+488tyevkUZcDE3V38w4SV0c4VY5dsP1ej3UtLu0OrS8vnLO6Xk6AGWaVSh7XBb9nsFW9TVlF72irxLEcP7ltb2aEeHW//eWTOta/ZNUyZ+OJS/2EjhrtQ/SNE2Qa52VVVPFW/87J7kub+KMY9PcYxN8m2KJOyipLEm9nbWxvRevakywn4ll+u8dWRPJJ1oBFVlBQ5Mvl8/+wEjqJnMOqSrLJu/OrJ62cNHehI1YPiCiPwbcyc+BZV5cXtu3vgrR9nX/uGOROKJxvbFFjbDXW3l/8pLqvcsOsM1UVClGGYRy+WrFzNTopf8NAjPdo9I9ohL9mmOBOQ0QutJNE9nLy8aeAKUYfEMiL5gijpvHN2fLfKUlUvCsoqFFcYauXMoah83I47Tvvj8Kzr37Bqpcw5l7BBbwfPH1ufVZav+Cb82gOqi4QowxD3XpVlatW60ic/xT092j09xiEvhVecRS+xUl3v4zXkFeq4S1Q+sbx6/6Io6bxLdnw3iZiyCqG4osS36DB3u+qy/Je61/Sb3717/QCjhp/GmfV6whfIR23Ks8rq49uoIhKiJBYmHDNTA2mVmjSwOOQmy/uA9clP6fE0m15fpRLrGqSyjV0drakoiEonlmEpl0YmnXfJusuVlFBWIaqIpULPddmMIZeXHmEZmmtptSllzbhxcMaNQ1oM6yaxZcS8TWsmNs4qgqdZXFn1gEmfv8SnVVfPUkKIChniZvfbrSIW21DlL1Me/+WWcdst87Z9QaqVOJdeWWW71t1paH/KKoShiWXJ9nM1+i8eee+TclmUFOmSddeIsgqhuNIJLEw4E0c7/3o9F4bdX7jzu9cPvHPzO6adQhRPyBPYC/iWjbMKgCsn17zUcbp8lhJCVMik0S4RN8KB7ip9Fv1yEuTzgPUqTLMU59HL2gkinEf4j/OiciDMTCwfzPX55NsbNQY9W/kNd8iDK6Lk866Zd43VYsaRLSODRPMnUlbRQNqq9XTfDxwolTypfdGg+VnXvmFgVqnUYYUNnbpkoV+zrEIIUfb3OteQpdL9wVyy4jwexbinx/CfPKSs0jkK9LnJ5nZD3HtpygkLhbhzBzIZZDKkp2PCBKoDDDfci//B3ME6FRmy50wMOPjvq6LkSNfMO8YVxWpwvhvGLPRaOsv/dfoFQROxOn8xqY50ZNLTZa2aNezzo7HgPPcrZM7V/VNv/cDAsj7kESAa+wrfxmze0gPBJ7/oSFYRPM1CaGjD35cvN/x/924MGEA1m5DG3n5NeOjXB1DN/mCumXfcMmLdMu/0LHxkVvaEXs3OEWHvLRrsqKfL0oizDQnB3LmYOROXLkEoxIUL+OUXTJyI06cb9gkIwMmTDX+uXNmwvDLpusQCoMU2loEPr4uSzrtl3DEpL6KsQlQ+rnT+YlId7Mg0frhT/IO8izF5MLB69tZ5V76a8ucRBhZ0VC+PZNH43XNHA1i97I3PHj/effITbnU7g2KysQ3uXm6+wCWAHj3gRHNuEtKc36uCb/4brcOxbuPIN4vTjiYAACAASURBVIbQksnki9a7Zdy2LcowLS+kl7LThPcfsen1VzTiVD08sHgxPDyQng4A8fFYsAAnT2LNmiZx5dQpzJ2Lb78FgA8+oKzC5MTinXpjZFKkW+Zt9fjQoKxCtFXxSa+f+2ovSzy7cOT83//NzKySbGxz6LW52z6eLv9TwLdcvS1o+ZsfiHUN2n/Qo0dbaEUJCoK+PlVrQpqxMOH0621VXaFKI011aqXyCYvd02N6Fj6irNLJH9owM9OUpbJjY2FhUZdV5CIjkZ8PGxuYmjbZs7AQACQSHDlClYRRiaVxrzCvtD9ESefdMmLVozGWsgqBag21b2zfvyZMWXnsaZVu/Ww/QZf3To45xsCnKtY12DBuye6P32ncqaAusQDyNpYpb4Qm6xi3/ZhcPR3o6+PkSQwejMeNlqPJzcXjx+jRg2o2Ic1MHSfc9M0NwEQlni1bWuWaeXtARqxr5h2b4kyjiqf0Cnam8P4j/DWkaaUV1tbgclHUqCuRmxsAREc3yTaEGYkFwKavr3kV5o9MinTPiDGnrEI0NK4IhZg7F/fuYf9+TJ0KfX0cOtRVz1tPl/Xvf/nPCTlVrWOnraP73qUvJ8b+zMDyrdRhrfNbsfpf03hWRs1uapxYknWM7/x32Usf3d4eZ89i8GBIJADg6wuJBHw+AgKwdCkGDaL6TUi9Ie69ZNKLtTXV2jq6DH+q+tUSeR8wYeYdm+IsNVgqQbVU6rCieg44PKI/FUVz8s7G9+9TSTAzsbxXIL7wzf+5p8eYlxaowRmFDQ7kTRpPWYXg5TqDxcdj2TIMHAg7O/Tu3byNuNPxrIy2Lx8jK02bc3kvY7PKlpFBY+cHeDnbtrhDfa+w9j/GgAE4erTu/yEhOHQIOTlwc8PUqXB3x3ff1SUZQjSeni5r1KA+0gqmjzo1rCqT9wGTj1ehrNL5rnfvJ+jTw8KEo0Hn3GxasEWLWtiHzUbv3pBKWxg2Sdog/NfoqFt/K/UhJvu6+s71+3Lw2+qRVfDuu8FBvlRzyEvGlRkz8PnncHUFgD59cOJElz97V0fr7ctHn3JwT+VaMa1kxboGC9/48IWNmPLEwjPpwICTgABs3YoBA+qaU0xMsG4dUlOxdi2+/x58Ptavb9JhjBBN9fZrQlQzegRIN4nY/VG0e3qMa9Ydm6KMbpWl9Kp1wWWlcLR/wGANOuGQEMTFwcgIIhG0tBAQgJUrYWmJnByIxQ27ubjAxQVSKe7epUrSjqzy2YGLyan5yn6gN/w8vZbO2jBmIWUVopFxJSAAlpZYswb376OqCvr6TT7Fuo6Xs+3uL4JDJn8Y1cuDOcWabGwzb1Lokq1BbWnEFPAtf/s2uEOPt25dQxtLvcBAREUhKgqPH4PPx9SpuHmTajzRZAK+paCXeVU5Q5cgMK546pEe7Z4RI8y6Y1uUwakqo5esSz69s3v2FXn30ZQTDghAaChSU+HpiUuXACA2FhcuAEBWVpOBK3Z2MDRsnmFI27JK9BffTU+O6pyH83/dS6UTC2UV0oG44uyMlBS4uKCgADwe9PRQVIQhQxTSJayDLaQ8K6N9e4LCpywJe2UyE8r0HN97y9sf7P4i2NXRuvMe9XnzFzs5UQ8xQuqtnDkUlUxsbDQtL5T3ARNmxdkWZRqo8qKWKi1s0NvB88cq+2uLKdhsrF8PAHv3NkkmSUnAM2NU5OPso6Ka7EnallU2Re7rzAdV3cRCWYV0LK7cvQt7ewQHY8cODBgAExMsXIgNGzr+saWQFlIuR2/3p+8iKGi536oOzQ7cYZ/5zLz0ztJv9i14dmx9V6IeYoQAYGoDi3lpgfujGPf0aOfseJuiDP3qCnqlukQbm1Y6rWOP0vn5wdsbqanNJ86R//6VmNgk2Pj5Nd9IGJlV6hOL8P0ZW0TzVai4DnoGVL0zg7IKeVabZwY7c6ZRhTqIgwcBYN8+hbyTp2f+nZ0/IDoxsyOH4lkaBc8dHeVkO8XIevqd3yanXNarkXbqp1Iv77BXJk1/22f1W0OY+4IHBiIwEElJ+PRTmkOMaKaVM4cu2BwOQ6bMaGwpzpPPA+b0+B6vKJNdU0WvUVdpS9NK/dcW8KrKn3CLDSYcDkaNgkTSZISqri74fEilSEmhesL8rCL3VsDAsNyiMIk4+MYxFSiufiPS/Kdset+Pag7pQFxR5js5iieMjvw9LPL3jhwt2cDyyrGloqFOXgP4YYec3rziO/vOmbfuX+6EE4niCcMGvS14pf+BOaOZ1ajyPPIeYrt3IywMU6fCxARLlyIwkJaYJJpA3sCS/LiYzYDE0r0kxy3jtlvGbUHuPZviLFZNNb1AXaUtTSv1X1th/dTiB+BnW1EAjBkDS0tcvdpkcRWBABwOMjJw9SpVFZXIKnLBQb5hQBjA8MQS3m9EdGDQpg2BVHMIs+JK43eyKDteFB7fwQMOmLhb/h8uR2/1Ir/Z7wzf/62D302/1dd/FGXHK+ksoi37hg2ewnV22jR/rOqtfyzvIbZuHY4dw/79WL8es2Zh6VJaZZKoPYY0sPCKs9wyYl0z7whyk3jFmTq1NfTSdKEXNq0w5AJU6aZMgVSK7dubbJwwAYaGzQffAzh6FLa2GDaM6k9bqkr4udjo6wmd9jQEvbuvXjqB+YmFsgphaFzphA99CxPOhyvfyM4r+exz3pf3M8fevyZKvy14mqWQg2cbmkXxhBEuIradTfAC3+ctq6IyqIcY0TBMaGCxLcqQ9wFzyL3PK87UltXS69KFXti0op5ZRT6k3tm5YUtAAAIDcfUqTp9usqe8HebkySYbPTzg74+PPqL605aqMv3BZa+CB535TOYNW7h6KcDsNhbKKkShcUUme+5NWlov+6jRMQ+8MjtjuB7Pymj3J++kZhVGXPLZcClOXFwqehQrSovxym/PR0aysU0E/5WoPgMrDQxFQ51WjRR26txfylbfQ+y776iHGFF7XdvAYleYJu8D1jf/Pq8oSwsyekW6VutNK2rbrrJjBxYuhEgEU1MUFWHGDISFITUV/v5NdpOPZmk2cEUoxLlz0NZmwiJszM8qALjVFe279lAIZiYWyipE0XHl5TNJKzZtCNwA4Bj8713qhJPk25gFT/cJnu6TnVcSdevvsMiY5OwSUX4SLy9DWJjGra5wLXz0vHwiZhtEW/R9YtY9ylpobmIwdtwruwb24duYqW2NMDHBsmVYtgynTlEPMaLGBHzLYe52VxPzdTmd3Y3TvuChvF2lT/4DXnEWvRZd7lp3pyoX1+c1rTCkY08Ldbh399VLJ3ToEGVlGDUKR4+isBAAcnJw+DA++KBJjy+hEEePwtISAMLDmx+h2RAXyioMjrXBQb5f1tQerJLMiTnFhOdzju99ffL8bZRViCLjivwza+5c3LuH/fsVm1iSjW0+Gz6rE86WZ2U0fbz79PHu4rLKqFt/Z+eV/PRnkrisMi6v5WlDBWZsriHba4iLo4lh0MA+FiYcDaoaAQEICEBSEr74gnqIEbX0UbBo7IJDtfom2jq6nfagffIfuGXEumbe7p3/t/XTbHoVulylDmvL8LmH//XWS12Adn7HnmfVd/XpkPh4uLh0aAcGEgqxaRMCAgAgIwMxMbCwUPYAG5Voglvyvt+GgpLw8uLO+bG4td8IerpGBMzf9tHb9BFEFB1X4uOxbBkOHsTZswr5NaU+sWRDnzfmVX9R/44cjWuo9xI7c/TqHm4KXX+3yskJX32FrVuphxhRP3q6rC1Lxnz07ysw6t05j+iQm+yWcdst8za/4O/uJbTwESPsGDpz9gxRi79GMbZjD2mNhweuXEFuLkQiXL+O779HYGDd6guanVWaXXp1YWK51tP1xOTF2z6dpafLogpLFB1XZsyApydcXeHqim3bEBKCTz7Bvn24dKmDb5vka3dElkZdOGA9OjFz3obmvW8PbJqs8mPoFYV6iBE1NdTdvj8/PjGziGVgquzHEjy+J88q9gUPrcS5VPhMEGfWK7m/94fjPVX6AlTNhYQgNLSF7Q8e4Pz55l3X2Gx89RVyc+HpWbc9KQlSKU4psfuTylWVrk0slFVIO7R5VfuAAFhaYs0a3L+Pa9fw888IC8OCBR3JKvVvG8HQAVyOXtcWhJe04M4vy+v/eUkLqHK0XA3OnkVUFIqLwedj6lTcvEmlQlRa6PsjIcmVKXkS4X45ie7p0e4Z0fyCvymrMESlDmvLqKCNLXUDo6zCIBs34s03AUAiQa9e0NKClhZcXVFZieBg3L0LO7uGnf384O2NvXsbMoyTE6RS3L1LWaXZpVd0YFB4vxGUVYh6xRVnZ6SkwMUFBQV1nwJpac3nX+/A22b6eHd6MVSGvIdYTg4GDsTUqXB3x3ffQSKhgiGqyMKEs3j6IFm5Eoe8O2fFuadHu6fH2Bc8tBTnUZkzxCGPANHYV56dOoWyilIIhTh5EmVlkMma/1ux4gX3TU9HeXmTLfHxGDgQ+fno2RMhIQ3bp0yBRNIwWRmbjd69ER2tvPkAOm2mUzVILJRViPLjyt27sLdHcDD27MG2bejZE0ZGWLyYSlBzyXuIpaYiJATHj4PPx/r1eEzd8YnqmTjK2dJYq1oiVsbBXTPveKTHuKfH2D9JtSilZlumSOVaRbm8OnvmCMoqnSEkBHFxEIvx6qt1zSON/+3a1Z5jlpXhwgUAdRMx14eTnByI/3kvu7jAxQX376vTRb9in/z1yfPP8b074bGiLfv+NJGyCmmnNleaM2ca/r9uHQDs2UPFRwCaQ4yog12r/Kat/Y9Mz1FLS1tRx9SSyeQTFrtl3rYtzDAtL6RyZtD186j3P1w3udmVE2UVZX1HhIbi4EHMnavgI8uXuXwe+TgWQ0MkKrf1gwmD19tt40dvryst556QDM2IU96jJBvbhL25dPeWGZRViJLjCiGt04w5xKYE70/Or6BXu40ElgbHw4JU4qnyrIxWzRr6+dFYcHop5IA6tTV1WSXjtk1xhkl5MdUH5vhy6PQRAcOeXedXdTv2MBebjfXrIZFg40alfO8AyMqq65peVYWHD+HhAR8fRETgyBFkZzfpG0aJ5Rl6uqxtn85aB+DEHiUllmRjm8+mrNu9a36Xj1ImFFcIAaD+c4gl51fc+WU5vc5tNGDibhV6tuOHO8X8lf17fL62QUcXjtStqZIvWu+WeZtXnGlc8ZQqA3NE9fJIHTpm97sj1emik7l0dcHnK2X0CIeDUaMglWL79oaNn30GoRDh4cjIwMyZCApq0jeMEkunJxbKKkQxcYWrp9PJlxRcPR0qd/VHPcSIClo379WUDSczS8S6+tx2H0S/WuKacXtAZqww845NcRZXUkIFyxzZhmZhw2cceP5C2pRYFEwgAEcJKyyPHo3PP4epKSZOxOnTDdtjYxsWteRw8PPPOH1aUdMCUWKhrEK6LK5c+YmGyxOloVUmiap9Z3++1m/q2p9ra/Tbt9S9YVW5W0asW8ZtYdZdXnFWt0oxlSpzVOqwlr++atsnM1u/eKLEokh2djA0hI8PZLLn7rNyZZtG2+vr49Gjhj8jIjBsWGtRRJ6Uyso683RbrzzRln01J7FQViGKjCtUBETpaJVJojosTDg7V/qu2Bkp4/Bfdth9t0qxvA+YS3YcrziTU1lG5ckoW4bPmz7P79mZizU0sbSSH9pHS+u5NylknL1EAoEA6ekQCnHhAsaOxY4drR12wgQYGmLxYnA4ih/l//KV50jf4Ud83uYZsTvtmYhMXq6VWJ5YVtRC76dPvfIfdOShU7lWWyau2UdZhVBcIarn2R5iQUEYMYIKhjCKq6P1NF/nI/97qGXIa/u9jCqeysfWO2cn2BRnGlSVU0kyyhGhL9ffz/81tw5edKqPVtKFAsmXTHF0VOQx4+OxYAFOnsTMmTh1qklnsMY2blTK+P72Vh6xroG/r0fwFEZ3itbTZW3bMmN5hWT18W2Cp+1cjSrb0GzLm6u3bZtFWYVQXFGA6MTM6IRMANn5LXQuD4/6S36rgG8p8u5DdUVhGvcQmz0b+vpYu5Z6iBFGmfOmZ+LfebEPn7AMzNuyv2l5kWtGrFvG7f45CTbFWfrVNH0cs8SZ9Yoa9sa+98d1/KKz4RuEwR17GCQ5GWVlsLGBqakix5D89htu3YK3N9aseW5c6VKqG3e5HL3du+YvB9qXWLINzTZMXr/pswU8KyOq/oTiigIIHXsc+v5iXHL29JTLXk2XRPC/G5mdEhPOH8i1t50+fgZVFMVr1kNs+XIEByMoCPb2VDaECT5ZOiZoY3jG0xJt9gu+dM1LC+QTFvfLSeQVZ+pJK6n0GCXb0OzL8Ys2hUxrx5oPzOnY86yX7erTNaqrkZpaN7mwAnNFVRW2bsXJk/DxwYoV7VxokhKLohMLZRVCcUXx9HRZu7ZMW/HhT9n53YPvnWsSVx7dCnMP4NrbHtg+g1ozlatxD7F+/aiHWEvBWogffoCbGwBkZGDhQmb+mqh+nw/7Q/ynrDz2tIrFYhs+bzdLcZ68D5jT43u84ky2tIqKjmlZpYPXT6rbsYcR6nOFwptB6htYFi3CoUOdNv0XJRbKKqTzaWv4+csTyxOfkRsGv9t4e5h7QNTg1ymrdB55D7GcHAwciNmz0a8fvvsOEgkVDEJC8OuvWLYMWlpwdYW+Pn75BRMmNI98MlnDvxUrqNgU9fnww9a3THXzpc8ZiNK95LF7erR7eky/nETbogzKKkxToM9dF7Cu49dPmzYERgcGhfejn1Ha5dQphIbCxwcXLrTzpyj59GIsVt2vNvVB6L33UF4OPh87djD27FW38sgTy2dT1iUb21BWIRRXGJdYKKt0GXkPsdRUbN2K48dhbY3165GWprkF4uGBxYvh44NLl4B/BpiyWFizpvnVQP28Nx98wMx+ESqKy9H7fvMkveqsmme6eFkXZ7k/inZPj3F6/JdtUQarppqKi1HEugbr/Nd8+PEshVw/aURiEQpx507drx7p6c1/FumIjRsxYgTMzfHrr01+W2nLLywhITh5EgBYLISHN9k5Nhbh4QAwZw4qKmBnx+TEEtXTTeVqhDyxbJm4JpVr1Qm/CxBCcaWtiYWyCiMEBODsWdy4geJiuLtj6tS663VNExsLC4smq0FHRiI/v27camOFhQAgkeDIEao+Cv/CPrhpomFtduPEYluU4ZEe7Z4R4/T4nm1Rhk5tDRUU07LK8jc/WL0tSMC3VOxFp9omlrY05HbE5csYMAAcDrS0mv9r/ReWjRtb23nq1LrtBgZNPiqZl1gEQweo4nUFl6O3bdusLW+uzjY064TfBQihuNKmxEJZhUHkPcRSUzF8OPUQa8LaGtymo2zlfSSio5n8ha26eFZGX3/kz67KrK2pBmBXmCbvAybIvWdTlKEtq6UiYpRKHdbyCWuWbJ6rwKyi5omljQ25pGOVZ/p4dxX9ANz02YINk9c/m1iU8bsAIc9S+aH2U4L3J+creM7QYTO/UtShBJYGx8OCqJ51iIkJgoMRHIxz5/DFFzSH2HOjHYD796kklPeF/cWacUu2n7Muq3XPvOuWebtPfgqvOItKhmnEugYb/JbNXjPN1dFaSRedG4Dka3dE6lRq8obcxho35DJyFDvpgsQCbDqxlffPTKqUVQjFlbZKzq+488tyxj69ARN3UyVTGF9f+PoiLQ2ffgp3d/j6asQcYs2mBdu3r4V92Gz07g2pFKdOUTVRHgHf8ss1vus//q9l/oO+efetn2ZTmTBNtqHZhvHLZ694e+hAR+U9yqYNgRs2QSMa4eUNuRRXyDOJhbIK6UzUGYyoGnt7DeohFhKCuDgYGUEkgpYWAgKwciUsLZGTA7G4YTcXF7i4QCrF3btUQZSdWPZunRYx1PehkQWVBtMkG9usm/yv1duClJpV6hOLinbsIaSjiWXy+mRjG8oqhOIKIS8i7yGWmordu9V2DrGAAISGIjUVnp51HcpjY3HhAgBkZTX5vVM+y2ezDEOU9oX9xc65JyYvpmltGeVaT9fPpqzb9cUCun5qp2bTgi1a1MIn0rOTeslkqK5W5Ih8ogqJZfkb6yirEIoryv9Q/vxzBAUBwNSpmD37ubcS5vP1xdmzuH1b3eYQY7Oxfj0A7N3bJJkkJQHPjFGRdxWLiqI+G52Dy9Hb9ums6MCgL4dOp9Jggv/0H/XT5KW7d823MOFQabRHWxpyp0yBVIolSxom6Tp2DAAOH6aFazUtsfz2/SLKKoTiipLFx2PZMgwcCDs79O7dfELYxrcSVaF+PcT8/ODtjdRUHDrUZLt8SH1iYpNg4+fXfCNRMj1d1qYNgd3mz1k3dmmlDosKpAt95jPz/rvv79s1h2Z0bKe2NOTKB8itXYs9e+rudfQoAgMREdGw6BMhhCiHRn7LzpgBT0+4ugJAnz4IDW35Vk9P7N2LykqUlNDHsWpQpznEWmww4XAwahQkEpw40bBRVxd8PqRSpKSowWsY/ms019JU5N1HJZ7tnHdHnrOzWqHfbWPElxYS6onX2cS6BltGLhDOfXv6W0OoNNqpjQ25VVUYOLDh1pAQBAbi6lX4+lIREkKUTfNaVwICYGmJNWtw/z6qqqCv36S7f+NbL13C5MmorsaqVVRRVIwa9BB7thUFwJgxsLRsvriKQAAOBxkZuHpVDbLKZwcuJqfmq1JdE7nM3hI8f+LGa92d6J3XmeLMes2bFDpi7TzKKh3S9obcxllF3hrj70/lRwihuKIEzs5ISYGLCwoKwONBTw9FRRgypK5LWONby8pw5AjWraPxAKpK/XqIyfuOb9/eZOOECTA0bD74HsDRo7hyRbWySvQX301PjlK5l8XL2fbw1+//9M7aLaL51DGsc4S9MnnH2+t3fxHsK3Kh0uiQtjfkyjXuOUZfjoQQiitKcfcu7O0RHIwdOzBgAExMsHAhNmyo+9htfOuBA6ioQGgozXmi2lR0DjF5Twxn5yZXCYGBuHmz+ahW+Y+gJ0822ejhAX//5hsZn1U2Re5T0VrG5ejt2zHLccncmRM3JRvb0NtOebINzWYGhCIo6PBXQTwrIyqQjmp7Q678g+XIEUgkGDGCsgohpNNo3g+BZ840/P/gQRw8CKBh6b3Gt86cSfVDrajWKpM7dmDhQohEdUtKz5iBsLAWel/IfwRtNnBFKMS5c9DWbuGXUcoqyvRWwECvVxxCNhqP+OO3OXG/0ntO8VWl79AjQyZ/+OEUJa1YT+q02JDr4YErV8BmY+LE5jGGEEKUidZdIRpGVXqIlZVh1CiUl6OwEDIZPv0Uhw83730hFOKPP2BpCRYL4eENyyDExbX8yyhlFeXj25h9s29B6cIlC19fW6DPpTecooh1DTaMDI6etfTAv9+jrKJIbWzI5XBw7lxdVqnfrmo9TgkhKoq6WRONpBJziMXHw8WlQztQVukKerqsJQteu/aK43zj7hMSLlAziwLqSd+hh7zenD17tP9rblQaCtaWhlw2GxcvwtQUa9c2ZJU5cxAYiJUrqQgJIRRXCFEm1eohpmbXoM/JKuHnYqOvJ6jc6Qh6d1+9tGGc21B3e9ev3z90xPnN//msuvr90NwkesXbIc6s145XZ9t79f9moR8tAakU8obco0dRWAgAOTk4fBgffNCkIXf9enh7A8DOndi5s2G7usyfTgihuMIwMtlzb9LSesGtRF3Je4ht3YpjxzB7NvT1sXYtAgOhr09l08lZZfqDy14FD1TxjOYNW7h6aZMtXI7ekgWvTXjda8fuHj8lJa36/RBfnEcvfRsV6HN3+Lyb3ddl1XJ/6v2lXC9sp924ERs3UjkRQiiudJbWUwdlEk2mTqtMqmZWAcCtrvDKf6BOJ8u3Mdu3Y9a122nr9tgM/eva7NhwbnUF1YFWVOqwjjiPPe0yKug9P18fARUIIYRoOI0cai8U4vPPERT04lvZbEydirFjqaJoFjVYZVI1s4oaG+puf3j/e92WLJw5afN/HIdTNXieKJ4wcOKW0oVLDn/9PmUVQggh0NCxK/HxWLYMBw/i7NkWpk5qfGtoaN2/e/do3kaN01IPMb0aKRUMZZX20dNlzZk2zN/PY/+3fUffnDA74az/39eppUWuUocVYesR9sokgQNv3zJ/WlClg7h6OgMm7qZyUGB5UiEQQnGlc82YAU9PuLrC0xN796KyEiUlmDu3hVtLSymlaLqmPcSOXYulIqGs0hEWJpwPV74RVFx26Md+U675+T64MS0hwkIi1tgCEesa/Mfh1RMuo73cex+YM5qCikJc+WkxFQIhhOKKygoIgKUl1qzBd9/h0iX8+iu++w6rVrVw68CB0NXFwoXo3x9iMdUVTefrC1/fwIAdf/zfaioMyiodDy2rF/kFzx71n18Hz/y/oV5ZfwX/+V9eeaFGFUKBPveQu39ULw/f0W6HJw2iib8IIYRQXAEAODsjLg4uLigoQFkZjhzBypUNMzY2vlUsxrVryMqCQNBkSkeiwSp1aO5vyioKw+XozXl78PQ3X4m4en/eQRdBftr02NNqNtNAi5KNbY4M8Ltu7Tx7ypDjY1y5HD2qDIQQQiiu/OPuXfD5mDABH3+MAwdQUYHQUJw8Wbf0VeNbPTzg6IipU7FwIVUUQjoiOuaBV2YilUOL9HRZ/qL+/qL+Ubf+DjvSPy376dhHf/rfvyp4mqVmZ5rKtYqw9w4XDOOadJs+bcQmUX969QkhhFBcecaZMw3/nzmztVtp1AohCrJpQ+AGAMfgf+8SlcbziLz7iLz7FBSXRVwdueH/XhUXl/onXxmbdkvVV2vJNjSL4gnDXUdXcU3GjhlwYIwrDVAhhBBCcYUQVdbKcqXtw4AFhSixtJGFCWf6ePfp492z80rCI4esiLyD0tLJd8+JsuNVa3BLgT43yloYIRRlG1mJhjptGusu4FvS60sIIYTiCiGqT02XK6XE8lJ4VkbB032Cp/ukZhWeOO0x71oSJBKv/AfC9ESvggfMbHLJNjSLM+sV08s1uoeTWNdAD387WQAAIABJREFUNLBP8JgBXs629GpqjmNR+wNFQVQOhBCKKw0YPrs8TdZOCCWWDuLbmK0Ofm118GvZeSXRiZnxdx/+dCdNXFbpVZwmTIv3yn/QtaNcUrlW8Wb20fZu0ZZ9oa/v2re756B+01xs+TZm9NppoOwnj67GR/gIaXllQgjFlX/Q7PKEUGLREDwrI3+r/v6i/gAKisuiEzLjEx5tiHmQXSwRVBUKch5wS596FTzgVlUoL8Ckcq2e6BvFmfYqNeTG2TmnsU25HD2hE89roFOwsy0NSiFzfFd+dGiBu8MQjj6XSoMQQnGFEKKGiSXasi8V0QtZmHB8fQS+PgLgNXFZZXJafnJqvrisMux6gri8KrmwiqddxasqcU1P7FYudi161Pi+rc+VHGfWq0pHt/7PZGMbsa5BtIPnE91uqTJ9Ppdlbqzv6uHQjWsYLLC2tzGl9VJIYybdzMcPmvrj+b1B49dTaRBCKK4oTHRi5rwNJ5ptPLBpMnW5JqSTE8uRvsOP+LzNM2Kr3BmJTLrst2QuR8/L2bbu82rKIPnG7LyS7PySuOScUnF5WGxKk0+8zNJWjuZqZcBmN/RiFfSz45oaBbvYmpsYUv8u0hZjX5m87ptZ9zPjHW2FVBqEEIorCuMlLTgQvqX+z3n+H1KZEKYQCvHDD3BzA4CMDCxcWLdMkDomFrGugb+vR/A/19yk3XhWRjwro7oM8+5wKhDSmYImrN9/euvm2V/rsthUGoSQDtKmIiCE0UJC8OuvWLYMWlpwdYW+Pn75BRMmqMfJbdoQGB0YFN5vBL3OhKgTfg+BC9/r9I0jVBSEEIorhKg1Dw8sXgwfH1y6BADx8ViwACwW1qxRm1OkxEKIWpoyYkFE9C/FpU+oKAghFFcIUV+xsbCwQHp6w5bISOTnw8YGpqaUWAghjKXLYs/xXRl25hMqCkJIB9HYFUJUkLU1uFwUFalTYpGPYyHKM2/tj9EPCtq4s1dfiwOfvkOFRjpiYL8RUXdP/3Hv0kD6MYIQQnGFEKIeiSX52h0RlYWSSCQHruxrfRZjuWjLvmG2a6nASMcFj/9g7TezPByG0Jh7Qki7UWcwQphNKMSdO5DJIJMhPR2LFjXfwcMDCQmQyfDwIezsGu4l37hihWolFsHQAVyOHr3shKgH+TIsP5zfQ0VBCKG4Qog6CglBXByMjCASQUsLAQFYuRKWlsjJgVhcl1W+/x7DhiE0FHw+QkIAgMPBhQtwdoZEghMnVOuMN20InD7enV55QtTGhMHTElJjUh8nU1EQQiiuEKJeAgIQGorUVHh61s0MFhuLCxcAICurbuBKbCyEQhQV4fRplJfD0RFsNi5eRGkpzMxgYNBkmD4hhHSFxW+G7Dm5kcqBENI+Gj12JToxMzohE0B2fsmzt4ZH/SW/VcC3FHn3obpCOhWbjfXrAWDv3iZD6pOSAOD+/eb7JyQgIQE2NtizB5aW8PRUp4H4hBCVxu8hcOF7nr7x04TB06g0CCEUV16C0LHHoe8vxiVnT0+57FVe2Pgm/7uR2Skx4fyBXHvb6eNnUEUhnc3PD97eSE3FoUNNtjs5AUBiYvP9q6rw8CG8vTFuHHx8KKsQQhhlxujFi/ZMGiYca9LNnEqDEPJSNLozmJ4ua9eWaa4CXrZJd/9Ht5rElUe3oK/Ptbc9sH0GDfwlXcDNDQCiopoEDw4Ho0Y9d0SKvOHl88+pAxghhGloGRZCCMWVDiWWJz4jNwx+t/H2MPeAqMGvU1YhXabFVpQxY2BpiejoFgKJh0fdUvdvvkmFRwhhIPnqK3/cu0RFQQihuNLRxEJZhTDUlCmQSrF9e/PtQiHOncOnn6rfgveEEHUSPP6Dg+d2VkurqCgIIRRX2p9YKKsQRpD37HJ2btgSEIDAQNy8idOnG7ZcuQKhEBcuIDkZmzbhwgX07AkfHyo/QggD0TIshBCKKwpILJRVCCPs2IH8fIhEdU0lM2bgyBGkpsLfv2EfNzf4+CAuDqWldduTksBiISAAbDauXcOECVSQhBBGoWVYCCEUVzqaWCirEEYoK8OoUSgvR2EhZDJ8+ikOH24+PbF8fMvFiw3bd+zArVuYMwcPHmDbtoZ2GEIIYYzgCev3n95K5UAIaSMWFUGzxKKnS2VCmCE+Hi4ure0wdSqmTm0ecgYOpJIjhDCZo62Qby2I+PPE2FcmU2kQQl6IWlcIIYQQ0qneGb3ozM2jxaVPqCgIIS+kuS0JBcVlO744E/cgN7u8tvU9eYbagp5mSxb68W3MqMYQQgghHcTR504ZseDguZ0rJtNKLIQQiivPySozF36z5PfDSwof8ZquZ/+sbEOzZBObdanZ23bMo8Si4bh6OgMm7qZyaHtxUSEQQlrkIxwbdffM7ZTr7g5DqDQIIRRXmtvxxZklvx/2zbzdlp155YW88kLz//075GPjw18FUaXRZFd+WkyFQAghChE0fv3mHxbv4nvpsthUGoSQ59HQsSvX/soZmpv0UndxLXwUl1dBNYYQQghRCCsTnmjA+OOXvqaiIIRQXGlOLAW3mrIHIYQQ0pUmDJ6ekBpNy7AQQiiuEEIIIYRxdFnsOeNW0jIshBCKK4QQQghhovplWKgoCCEUV16EzcbUqRg7lkqCqLEyiZgKgRDCKLQMCyGE4krbhIXh2jVMmQI7OyoMopbyirO3HVtFiYUQwij1y7BQURBCKK48n4cHSkuRnk4lQdSYlQlvju8KSiyEEKbxEY4tk4hvp1ynoiCEUFx5jnHjoKuLhQvRvz/EdCVH1Ba/h4ASCyGEgYLGrz94bme1tIqKghBCceU5fvsNN27g1i0UFVFhEEoshBDSmaxMeENdXvvvlUNUFIQQiistSUyEoyNWrUJICBUGocRCCCGdb9Kw2beSLmcVpFFREELqsagI6pw6RWVANDOxrAvcwdHnUoGojejEzOiEzGe3Z5e8RB+b7JKqsOM3n90u4FuKvPtQIRMlkS/DEnZm6+ZZ+6k0CCEUVwihxEKJRQ0JHXsc+v5iXHL29JTLjbf7A7yywrYcgVdW6P/HafxxuvHGcP5Arr3t9PEzqISJUrnYe0aZWF+8fXqk+wQqDUIIxRVCKLEI5viu2PzD4s2zv9ZlsalA1ICeLmvXlmkrPvwpO7/7phvft+MIvPLC4HvnGm8Jcw/g2tse2D6Dy9GjEibKNmP04k0/LPZwGGLSzZxKgxBCY1cIocQimDJiwc4T62lCHjVLLE98Rm4Y/G7HjxbmHhA1+HXKKqTTmHQzHz9o6g/n91BREEI0N67oaaFSh1qWCKnj7jBkrOckSiyUWCirEIYY6T4hrzgnIS2GioIQoqFxRWjTLd7M/qXukm1oxjOkxihCiYVoUGKhrEK6UPD49QfP0jIshBDohIaGauBp8+ysvnxQMywtxrBtn4NiXYOQ0e/PXz6Jb2dBlYaoK2vznhw97g8X9gx0Eulo61CBqAGWjvboEc6nHpT+ITMWZd6lrEJUiJGhSVFpwb30Oy58LyoNQjSZlkwm08wzv3Y7LWT7/xVUten0uSx8GDzaV+RCNYaovdsp1yNi/rty8lYaea82KqulKz78yfzqxbaPvKesQpigWlq19ptZK9/6xMbCnkqDEIorhBBCiYUSC2UVwiwJaTHHL31Ny7AQosk0tDMYIaQV1CtM/bS9VxhlFcIoVia8xLSYsgox31pApUGIZqKx44SQFtDIe/XTlpH3lFUIA80YvfjMzaPFpU+oKAjRTNQZjBDyXNQrTP200iuMsgphrIg/T6TlpgSNX/+ydzwWtX+k+wQrE179lgf5cQ8K4qhIyUvpa+Ha19KVyqGr0NojhJDncncYAmDnifWUWNTGP2veYwPQOLFQViFMNvaVyeu+mXU/M97RVvhSd0x8FOvC92oSVwriIu79SEVKXk6/dyiudCHqDEYIeUFioV5haplYGvcKo6xCmC9oAi3DQgjFFUIIocSieYmFsgpRCfweAhe+1+kbR6goCKG4QgghlFg0KLFQViGqYsqIBVF3zuQVZ1NREEJxhRBCKLFoSmKhrEJUhS6LPcd35f4zW6koCKG4QgghlFg0JbFQViGq9SnE0edejY+goiBEc9DMYISQl7tWKCp9Enbmk8UBoZpZAlOC9yfnV1BNYCyBpcHxsCAqBzU2x3flR4cWyHMLlQYhFFcIIaS5ke4TAOw5FaqZiSU5v+LOL8upGjDWgIm7qRDUm0k38/GDpv54fm87lmEhhKgi6gxGCGlPYnHu5bnnVCgVBSGk8419ZXJqTvL9zHgqCkIorhBCCCUWQgjj0DIshFBcIYQQSiyEEIaiZVgIobhCCCGUWAghzEXLsHS+jPjCk5tjIr6Ml1bWUGkQiiuEEEoshBDyXLos9jujFx88t5OKotNYO5kAKCuqpKIgFFcIIZRYCCHkBQb2GwHgj3uXNOeUZ3qv/9fY7wx1u3XJo5cXVT5+8FRXX4elp0PVj1BcIYRQYiEtEQpx5w5kMshkSE/HhAkqc3BClCB4/AcHzzFxzP3Yfu90Ya7oWtLq2pObYy4fTKL6SSiuEEIosWiYkBD8+iuWLYOWFlxdoa+PX35pHioCAuryhvzfihWKPDghDCNfhuWH83s04WTZLP3eFi4n48LKq0sZ+yRra2R/XcwysTYcOt1BsUcWF0guhCVGHbhHI2corhBCCCUWRvLwwOLF8PHBpUsAEB+PBQvAYmHNmia7nTqFuXPr/v/BB9i1S5EHJ4R5JgyelpAak/o4We3PVOQwOelxdGLOzS58Dj36Glvac1u7stTRch3bUzSvn8I7jMlqZfdv5OYkF1Od1zS0qj0hRMGJBRq85r1yxcbCwqLJlshI5OfDxgampigqatheWAgAEgmOHFH8wQlhnsVvhuw5uXHXez8x/HnqaLOWDN9pZyoAIK2p+iRyXlF5HgAhb8icQRvk+zwpe7zr4qLy6tJnN0bc+7H+UC3epcUHra2RleRXiPMlD/7IdR3b07xn+/unaWlrARAXSLqwDHt7WdLIGYorhBBCiUWlWFuDy22SKNzcACA6Gunpij84IczD7yFw4XuevvHThMHTGJ5VpLXS5b/4Apjpvf6DMQc+iZzHYRtN81x14EZo42YTW5O+z25s461yd35Lv3H8QWVptfxPMxuO82hb857damtkN449+POXh2Y2HJa+zpNHpU6vWnsG8OPOpd/7PUe+v0Uv7rjlrvJgU1ZU+fetvGs/pdQfqo+3VSunWVsjO7P99sPo/LFLhIWZZfIHKswqA6DD0vZ8w37INAcA146kZCYWAjCyNCgrqsxMLJQ/qCmPI7/7uOWuAh9raXVtxBdxpYWVvdzMb/+WXllaffPnv2/+/LeZDee1xcIeDsZU+SmuEEIIJRYV5OQEAPfvU0kQzTFj9OJFeyYNE4416WbOzGfYv4c3z4j/SeQ8+Z/HYnc7jB3gZuNzPfU3aW210Hpw4+yRV5r57MY23ioPA7HhaW997N3Dwfj375JjT6c5Du3h6W8vv/VJuliHpT3w7T4CH+v6jDHg9V4+7ziy9HRK8irOfh4XG542ZqGLuEBy/qvEbmZ6878eztLTyYgvPLPjTpuyGUvblMfJTxUDkD+QtLr2+0VXbp955D6+l4ERW77b8NlO8shRkldxZPWNn1bdmLzplWaHepzyVCKu9l/nbudq/vO/bvXxtpqw1p0qvEahsSuEEGUlFhrHonjNZu5atKiFfdhs9O4NqRSnTin44M0G8df/q66mEfmky+my2HN8V4ad+UTlnnmVVLI54l1n60G7J57b+eavztaDnrex9bvUk1bX5j0sselvamHXDUDfgVYA8tPEzR7XuLthw+WgjpY4X3JqS+znkyIOvvd7TnJxfpq4qkJ659dHJtaG9QNRjLsbmNlw9LvptnZlqaNlYs2pkdY+zS3X1dexdTaz6MUFoK2t1cPB2FpgIt+tpro2J7n4aW65/E8jK4NX3xXUSGtL8itMrDmND2hm281aYKKrp9PNXF+v1YcmFFcIIeSlE4ulsfWxqP1UFIoREoK4OBgZQSSClhYCArByJSwtkZMDcaMLERcXuLhAKsXduwo++JQpkEqxZAm0tOr+HTsGAIcP4/Rpen1Il1PdZViqpJKPfp2y/Bff7/7YMmfQR/WJ5dmNrd+lXk11bXrck5SbueICyfWjD3T1dEa/5/xsnJBvqa2RhW+NPfVxjPMom2X/Hbvo2BiuhX5RVllhZlnCxazGQ9tLn0jkSab1ubnM7brpsLSNuxtWS2oyEwsLHonlj9tTaG5qw6nfp9m9nqQ3jL2R310ectgGOrU1smqaDYziCiGEKEOgKAgAJRYFCAhAaChSU+HpWTd5V2wsLlwAgKysJmNL7OxgaNg8w3T84PJGm7VrseefGWOPHkVgICIiGiYiI6SrMXYZFgDJebESacU7r6yt+3j0WF4prbiV9r/G+xSV51VJm68Z3+LGVm5l6WqPXSJ0GNw94sv4b4MuS0qrJ218pb7/1bMe3y9+GJ1vbtfNYVD32hpZVmJhlaQGAMdUj62vk/ewJPpU6kud6ZP00sZxqD4UFeeUJ0RmPs2tqA8nRVll8lsf3SlIjMryntTbYXCP4pyy+rvfu5ydciM398FTeViqLK0WF0gepzyNOnDvSUYpVXgNQWNXCCFKTyzHovYfi9ovjy6kPdhsrF8PAHv3NkkmSUnAM2NU5OPso6LaOj6+jQevqsLAgQ23hoQgMBBXr8LXl14fwhz1y7DM8V3Z5U/GnNNjy4QT8v8/fJK45/LKzRHvfjT2+90Tz+E5M4AB+L/4rxNzbra4sf7P1m+trZHF/F9qRUn166sGdO9jZGRl8ExsKKtvvgDQw9Gkt5flw+j8vdPOA7DqY1RZWm3Ri8tia7+12ft/exNu/vz3n7+k1khrrQUmQ6b27eFg0spZ19bIamtqrQUmxt0NCx6VWgtM2PosALW1MnFBhbXARFe/YV4v+bh5qz5GbH3Wm//ylI9j8QrglxZVnt0dd3Z3nJkNR+BjzTbQKX9aJe8Mlvew5PxXiYMD+3ZkijNCcYUQQiixKJSfH7y9kZqKQ4eabJcPqU9MbJI9/Pyab1TUwRtnFXlrjL8/vTiEaSYMnrbiq2mpj5P5PQRd+DQi7v3YeN7hutQvlXz065RmG+Ozr8vnCnvhxjbeCqAkryIzsTAnuZilr1M/o5f3pN7ek3qz9HT813s03llbR6vZlnoGRnh27HvrtHW0RsztVxeEGs3cxdLVfn3VgGY7y6f/araR18902vbBLR78ve9HUg2nuEIIIZRYmKfFBhMOB6NGQSLBiRMNG3V1wedDKkVKiuIPLte45xhNcEwYSVWWYVGSsqLKnq7mQ99xrG9/kE8ufOu/D83tuj0bD7pE975GwjG2dq7mVF3JizMwFQEhpNMSC2gcS/u02NAxZgwsLZsvriIQgMNBRgauXlX8wQF4eODIEUgkGDGCsgphLH4PgaCnMOLPExp47iV5FT+uvJ6ZUNi4r5S2jpa5HVeBj1JbIyt+XN7iv5K8irYcQVpVGx+ZmR73hKoreSFqXSGEdGpioTYWhZHP07V9e5ONEybA0LD54HsAR4/C1hbDhnXo4B4euHIFbDYmTlTAApSEKNM7oxet+2ZWN0MNXUYwLbbg3uXsfsN5AIoflydeyIr7X4b3pN6KalpJOJ+Zn1oCoCC9yXh3I0sDnpOJ80ibFy48b2ptSLWUUFwhhFBiURfyUe/Ozg1bAgLqRro3m0FY3lRy8mTzmOHvj48+6tDBORycO1eXVeq3v2wKIqSzcPS5U0Ys+PbcDk07cSMrg3d2Djn/VWLEl/ERX8YDMLPhdO9r/PbH3gocm+46tmcHj1CUU45GM4MRQnGFEEKJRZXt2IGFCyESwdQURUWYMQNhYS2MdJcPOGk2cEUoxLlz0NZuYRRK2w/OZuPiRZiaYu3ahqwyZw4CA7FyJb0+hJl8hGMPRuyUVJVr2olzLfTf/MiT4U/S1NqQ1nwkbURjVwghXZNYQONY2q6sDKNGobwchYWQyfDppzh8uPlId6EQf/wBS0uwWAgPb1hyPi6u5VEoL3Xw9evh7Q0WCzt3Nhz5229fbkw/IZ3OxoKvz6ZOR0zEYusMeruPw5AeVBTkxbWFioD8f3v3HhdVnf9x/MPMMCDD/SYIoiCIipBXTNPM0qjMIs2u1O7a7ffbtK2sLXdz1Wp3y1211fZnu6uV5iW7mGmZlmmspWaoxCVUEBBBkOEil8GBuf3+ODRcRPLOAK/nY/4YzpzzPV++Z1p57+d8vwfoqMRCjeUCpKfL4MGXtMOlHLtggSxYwEUAYHcivSJlU56bl/amJwb94kyVswX28wzs58kw4nxQXQHQkYlFqLEAQCcUPMBbRAyV9QwFiCsASCwA0N1NGnD/63d+umTqtlnjF4nIw/FzXkp41825w57sXldZX5JT5eyqvojSCkBcAUBiAYDLLGFgUkclhISBSaP6JCzY+uC2rDX6mkKuBYgrAEBiAQCHoNW4jo2Y8m3u5jpT7fasNe8fXKLVuEb4D/4k7a06U23X+31ryoxfv5W5a0WWud7SsY2AuAIALRKLvqp456EtDAUANDc0dLyb1l1fe9K+ZULU3YdLUjKL93Vsx4IivQL6elz2Zm1W29G9p4qPnO7wRuAgWBkMgKOYlTh/2ab5InLj0CmMBoBOQa3SPDV+UZhPtIiYLQ1/+erRyrrSh+PnhPlEL945U6l+JAxMGhk2cfHOmfUW49k7azWuf7h55e6cT28e+KBGpXl73yvNc8jD8XOGho4XkUdHz7cfsj1rjX2H2F5jZlz7J+V9uaHEftKzWS22av2ZGr0x5/tTcQm9L/GpkU4qJxGpKTNeoYGNGBFw6bNiLksjIK4AAIkFQCfOKocKk5fs+p0SLZJGvrAsefahwuRrQsaG+w/OLN6nVmkGBY3M0f+oZBWz1fzMxluUDPPkuIWLd84028xqJ80tA5OUKNLqFKv3/1VEvHr4L0tu45Gsod6RDwx/bsXe+e1UWlK3FuzdkFNfa1J+9A3RxUwM9evtbrXY9r6f88PGXN8QncZVXX68dsD1wcMTw9O2FWT9t1jZ37+Px63PxNmDjaGy/tj+0u/WZdtb6xcf+IujVFNmPPBpXurWgsB+nqXHqkNjfCc8NtCnl+6zhYdyU/S3PhMXPTbYbLJu/0dabUV9n2v8Dm0tqK817fvg2L4PjvmG6G6eFXtsf2lhZoWIeAb0MFTWF2ZWKB27oEaCorz4xhJXAIDEAqAbsVjNSlBRnKo5EeYT7ebs/lPJ/sLTObHBozOL9wV79g107/3l4fXKmzUpC5Wdd2V/NDr81nD/wdn6VBH5/Kd3z84qSiLy0wUVV+W32YHS2kKz1aScqM0dvlubfXBz/vRX44OivP777pGDW/L7Xxc0/I6+yqflBTVqjWrUPf2ixwYrW6wW25DJfcYm9de4qKtLz3zxRtrBzfmTnhyspI4dyzPdfV0e+/d4jYv6RHrFZ39P/cUhqi49s/b5vV6BPWaum6hxUZ/Mqvzgpf3vv7Dvnr+MarVnSXaVscZ0x4tDw+L8Pnhpf7/4wCkvDFU+Ora/VETG/2aAEjmUNtc9t/ful0eefyMgrgAAiQVAtxPqHTlr/CKt2qUxABhKlBjzU8kPI8Mmujm7xwRfa2iozivL8NUFqVTqR0fPb354gHsvJa6ciz3ttPlpg9n4yvZfzU1YtWTqNqvN0upGMrPJWppbHTLIxz/MXUQiRwUe3JKvz69p1YhXTzf7e5XaqUZv3PF/mUo1Q0QsJqu53qLSqFI/P+4d7Dbuof7K7VVePXv4huhc3Z3b6bzZZP1w7n6ryXrX3OHKUUH9vSNGBOSm6CsKa72DdSJ6+86+oe42q83ZRe3u5+rSslmLyVp85HTVqTolrngG9rj+V9Ff/TOjWn/m/BsBcQUASCwAumNW+eKnVd9kb5Sf56goH+3K/mhsxJQxEZMHBY1UFvXyFbFaLSv2t75xS6txbecUPm6BGpXmZFXuuXZoMBvnfn6vNE5imdsqsVhM1sLMiux9p0JjfPesz3F2UU/83xh7MvEO1uWm6O0xwGqxfbbw0PHU8om/jbn75ZFmk3XVzN2VRQZTvcVU1ZCxs8grsIe95dpyY/GR00qYOdf8kLrK+gajxSdE5/zzDspJ1Zpyr55up3Kq1RqVEpZUKidtD/WZapOprYW8/MJaT7MpL2ian3OejaDzYmUwAI6bWDKPH2CtMLHZLvPryrXcvHGgm1GWG26eIrL1qZNjftPLM/zHom9FpLg6v7T2xI39p19Qs0NDxxeczm7zPrFWKutKG8wtnjGvcVYlPBUbNbrn9qXpK59INtaapi0Y2cNTe64WSo6ezk3R+4W5R13b02qxFWVWNBgb/+5383HRuqpLc6tTNuWdf+ftRx37obH/1aVnMncV+YW5+4bqThcbLGZr1ak6EclKPpm999SpnColCNXXmmrKjCXZVbtWZJWfqFXCSWWRQWnkeGpZ5q6i+GkRUaODzr8RvqKdF9UVAA6dWKixiJNT52sZ6KL8dEF/nvKR8j63PHNZ8uydRz+8M/bxO2Mft9ose/K2DuzZNJviUGFy87BhsZqXJs9+avyiJVO3KTsoK30ZGqrbiUBRAUPamUbffFkwEfk0/d/Nd7ZabAc+zTtTbZr83JCe/Tw9m9VGlE9PFxvspQlpdqfWmw/sEJHAfp71tSb/Ph5K8pn+SvyXb2bs++DYDxvzLGZrcLT3mPsjg6K82/sr01l1z59HbV+a/sWStPQvC316uZUV1N4wY0DUtT01LuoRieG1lfVfLEn7Ykmab4guemywtoe6rqpBuY+rNLd6x/LM0fdF2if6K/PmA/t5al01d700XKkIXWgj6JT/DNr4P8MAOLZlm+bH9BnuIIllyLQ3Ujc+w0VxWEOmLkn9+GnGAYq57z5x7w2PD+473L5lW9aa5qsAX1E2mQEbAAAgAElEQVSh3pFPjlu4JmXhRT8g5RJbUG7uyk3RqzUqjavavpxX/LSI+GkRnWiFX2WRAGX5rw7pQMLApFsGJvEfVEehugLA0VFjAdAZ2SfZX9zhapXmxv7TL6UFQ2V97zi/65L622sLSoDZ/3GuX5h7R/3pfxF6RnrGTgoNi/PjS9U9MXcFQOdILMxjAdCJ2B+3cq6HNrZPq3Gdf+vacL9B7x9cfHEtVJeeWTN7T2FGRfP7oFRqJ7+wy/wceqvFdrqkrs1XdemZy3IKc4M1/avCgrRyvlfdE9UVAJ0msVBjAdBZtHoky4Wyr/d1ifIPlmUlnxw4vpeInC6py/y6KO3LE/HTIi5jaSVjR6E+r1pEygpaxCrPgB69BnjH3Bhy6Xed+QS78Y0irgAAiaXziI2V996Ta64RETlxQp58UrZscdxmAXQEz8AeSYvG7FieuX1p+val6SLiG6LrGel1z6vxl3feeVxC7yv9u1QW10mzlcHQ3XAzGIBOlli6+11h8+bJ55/L00+Lk5PExYmrq2zcKFOmXL1mtVp57TUxGBpXLt62TXx8+GYCDsjD3/WuucOf/jhBeT28dGzCU7GdcY0sn2A3nvlIXAEAEktnMGyYzJolY8fKN9+IiKSny+OPi0Yjv//9VWpWp5ODB2X2bHnxRXFykuHDZdw42byZryWAK0ejVV97T7+oMUEMBXEFADpNYvku88tD2Xu63W9+8KD4+0tBQdOWr74SvV5CQi6pxHGezWq1snOnREfL1KmybJmISEaGZGTIiBESFsbXEsAVEtjPc+jkPjw7hbgCAJ3Ji/ct2n7g4+6YWNoUHCweHle82TlzJD5eVq9uPadFo2mc8QIAAHEFAETEWaOdffdfSSxXj04nTz4pRqMsWMBgAACIKwBAYmlLbKykpjZOcy8okJkzW++QmNj4aauXydTejPxfbPa55yQgQNata3HPmLOzhIeL2Sw//sgXEgBAXAGA7p1Y5s2TtDTx9JQJE8TJSRITZfZsCQiQ4mKpqWnc5957xWyWp54SJ6fG1/vvi0gbN3Gdf7Nardx2m5jNsmlTiwOjo0Wn43sIACCuAEC3TyyJiTJ/vuTlyfDhjUt4HTwoX38tIlJUJJWVjbkiIkJeeKFxKryIrF8v990n27fLI49cfLNKFUWjkc2bW1RsDhwQN7cWYQkAAOIKAHS7xKLVypw5IiJvvtkYIRSHD4uIHD3a+GNDg4waJYsXN/44b57cd598+63ccsslNTtpkgQEyLffNlVsmtdtdu1qcSwAAMQVAGgzseSVHOmav+Ftt0l8vOTlyTvvtNg+YICISGZmG4fMm9dYNrnjjkttVln4y55eFDqd3HTTOc8OAMDloGEIAHSlxOKs0XbNX08JDK3qGEpgMBrlo49a79/8Fq92Sh8X1GyrWKKUXNo8OwAAlwnVFQBdKrF02d+tzSqKEhhSUlqs1iUiw4bJ2rViNMoNN/zCbVrn2ayyWyv33isirdcKAwDgsqK6AgCdlrII2MKFrbPK7t2i1crUqRcZJNpstpVhw+SOO3gMCwCAuAIA+Hnue0xM05bExMZp9M2XJ9bpZNu2xqxi375+vYSGyrhxF9+sspudVivLl4ubm8yeTWkFjkzn6q5zdW++JdI/TgYmMTK4IJH+cQxCB3Ky2WyMAgCcpyHT3kjd+ExH/Nmlk7w8qa1tnIvy0EPy1lty6lSLqSlarezeLcOGyQsvNC0ONmOGrFwps2c3bbnQZuXnio2y3WCQVavkvvvk7bfPuThyB16gqUtSP36aLyoAdBnMXQGAzsBgkJtukro6qagQm01ef11Wr24dKubMkfh40Whk0aKmR6OsXClms2RnX3yzInLwoIwb17hbfb0MGSITJjhgVgEAdD1UVwDgAnRYdQXneYGorgBA10J1BQAAAABxBQAAAACIKwAAAAC6ABYyRjeVo0/LKUtjHLqYn3LShoSPvnHwXVfuFB4u6iFTlzDUDsvDRc0gAABxBej8caUsbXvWGsahiyk7UaNWaa5oXNm9bhbjDADAVcPNYAAAAACIKwAAAABAXAEAAABAXAEA4JxO15YzCAAA4goAwBF9n7Xrxf/8uqgsn6EAAFwcVgYDAFwpCSPvDg+OXvThH8YOnjR13G8YEADAhaK6AgC4gvqHxr7+2Lt19QbKLACAi0B1BQC6kUdfWJOSU3aeO4+I9F/xetKln9RZo02aOPNoYTplFgAAcQUAcG5G44rd/xyhz/nFHVMCIt8KfeEynlkps2z45t8v/ufXs+6aH+Lfl6sBACCuAAAcBWUWAMCFYu4KAOCqYjYLAIC4AgBwXEqZZcatsxd9+Icte9cxIAAA4goAwLEoZRZ9VfEra2bxQEkAAHEFAOBYnDXaGbfMvn3U/XPfeXznoS0MCACAuAIAcCxDo8a89ti7mccPUGYBABBXAAAOR+fqMStxPmUWAABxBQDgoCizAACIKwAAx0WZBQBAXAEAODTKLAAA4goAwHFRZgEAEFcA/LIT6RWfvHJg+9J0c72F0cBVRpkFAIgrANCe4AHeImKorGco0CEoswAAcQWAA5k04P7X7/x0ydRts8YvEpGH4+e8lPCum7N7R/WnrrK+JKfK2VWtcVFzddBRKLMAAHEFQKOEgUkdlRASBiaN6pOwYOuD27LW6GsKO9GgmU3WT145kPz2Yb4/uEIoswBAN6RhCADHodW4jo2Y8vXRDXWm2u1Za5QtEf6DPzy0rM5U68g9t1psP+0s8g52u+7BqMvbck2Zcf9Hx1Qa1biH+lPegShllt6xb29b9F3ml7MS53u7+zEmAEBcAXBV/g4LHe+mddfXnrRvmRB19+GSlMzifR3bsaBIr4C+Hu3soFI7xSX0vhKntlltR/ee8grswdcDdkqZ5VD2nrnvPH7X2F/fOHQKYwIAxBWgu1OrNE+NXxTmEy0iZkvDX756tLKu9OH4OWE+0Yt3zlSqHwkDk0aGTVy8c2a9xXj2zlqN6x9uXrk759ObBz6oUWne3vdK8xzycPycoaHjReTR0fPthyg1FkVsrzEzrv2T8r7cUGI/6dmsFlu1/kyN3pjz/am4hN5+vS/prjYnlZOI1JQZO3DwI0YEUFpB63hPmQUAiCsAmmeVQ4XJS3b9TokWSSNfWJY8+1Bh8jUhY8P9B2cW71OrNIOCRubof1SyitlqfmbjLUqGeXLcwsU7Z5ptZrWT5paBSUoUaXWK1fv/KiJePfyXJc8+uwOh3pEPDH9uxd757VRaUrcW7N2QU19rUn70DdHFTAz16+1utdj2vp/zw8Zc3xCdxlVdfrx2wPXBwxPD07YVZP23WNnfv4/Hrc/E2YONobL+2P7S79Zl21vrFx/YzvhYLbbPFh7KTdHf+kxc1Ogg++kqigwiotaoht/Zd8wDUd+tzS7MrBARz4Aehsr6wswK5bw+vXT2w6PHBptN1u3/SKutqO9zjd+hrQX1taZ9Hxzb98Ex3xDdzbNig6K8+EJCQZkFAIgrAERELFazElQUp2pOhPlEuzm7/1Syv/B0Tmzw6MzifcGefQPde395eL3yZk3KQmXnXdkfjQ6/Ndx/cLY+VUQ+/+nds7OKkoj8dEHFVfltdqC0ttBsNSknanOH79ZmH9ycP/3V+KAor/++e+Tglvz+1wUNv6Ov8ml5QY1aoxp1T7/oscH2gDFkcp+xSf01Lurq0jNfvJF2cHP+pCcHi0hNmXHH8kx3X5fH/j1e46I+kV7x2d9TzyvUaVRePd1UaieLySoiyunMJuuqmbsPfXZ86O19lN3G/2aAEjmqS8+sfX7vuuf23v3yyFZNlWRXGWtMd7w4NCzO74OX9veLD5zywlC+h2iTvcySefzAjFtm61w9GBMAIK4A3U6od+Ss8Yu0apfGAGAoUWLMTyU/jAyb6ObsHhN8raGhOq8sw1cXpFKpHx09v/nhAe69lLhyLva00+anDWbjK9t/NTdh1ZKp26w2S6sbycwma2ludcggH/8wdxGJHBV4cEu+Pr+mVSNePd3s71Vqpxq9ccf/ZSrlDhGxmKzmeotKo0r9/Lh3sJt9artXzx6+ITpXd+d2Oq9SO3kH63JT9FWn6oKivJxd1aExvv59PEREpXIKivKqN5iVUxQfOa3sIyKegT2u/1X0V//MqNaf8Q7WiejtDfqGutusNmcXtbufq0u7pwbk5zLLzkNbXvzPr2fcMnto1BjGBACIK0C3yypf/LTqm+yN8vMcFeWjXdkfjY2YMiZi8qCgkd/mbq4z1fqKWK2WFftb37il1bi2cwoft0CNSnOyKvdcOzSYjXM/v1caJ7HMbZVYLCZrYWZF9r5ToTG+e9bnOLuoJ/5vTJtZQn6+d+t4avnE38bc/fJIpQBSWWQw1VtMVQ0ZO4uaT22vLTcWHzmthJl2JpD4hbkr1RURMRkthZkVZcdr/Hq7q9ROvWP9yk/UKvu0Oqq8oGn6jf1wlcpJ20N9ptpkqrfw3cP5u3HolGFRY5Ztmv9t5peUWQCga+C5K8AFU5Ybbp4isvWpk2N+08sz/Meib0WkuDq/tPbEjf2nX1CzQ0PHF5zObvM+sVYq60obzC2eMa9xViU8FRs1uuf2pekrn0g21pqmLRjZw1N7rhZKjp7OTdH7hblHXdvTarEVZVY0GBuDgZuPi9ZVXZpbnbIp74L6X15QazFbq07VtdputdhOF9dlfFVYdeqMEk4qiwzKR8dTyzJ3FcVPi4gaHXS62GA/PCv5ZPbeU6dyqpSwVF9rqikzlmRX7VqRpcQe4Fy83f3mJi2L6TP8xf/8+lD2HgYEADo7qitA2/x0QX+e8pHyPrc8c1ny7J1HP7wz9vE7Yx+32ix78rYO7Nk03eJQYXLzsGGxmpcmz35q/KIlU7cpOygrfRkaqtuJQFEBQ9qZRt98WTAR+TT93813tlpsBz7NO1NtmvzckJ79PD1bLvtrtdhOFxvstQsRCervHTEiIDdF/+YDO0QksJ9nfa1JuXdL46ya/kr8l29m7Pvg2A8b8yxma3C095j7I4OivNsZLqvFZrVYg6O9lVOonVXB0d5aV42IWK22mrIzwdHezq6NlRll3nxgP0+tq+aul4YrBZ8RieG1lfVfLEn7Ykmab4guemywtoe6rqpBuRmsNLd6x/LM0fdFXuIqZ+gm7GWWBnPDqIE3MCAA0Hk52Ww2RgHd0LasNc3XCL5Eod6RT45buCZl4UU/IOUSW7AvzKXWqDSuavtyXvHTIuKnRTjOEsDKGgDK8l9Xov2yEzUjIsf/bvJf+Iafy6O/W/E/618foc/5xT1TAiLfuv+FFf94lEEDAHQgqivAZWCfZH9xh6tVmhv7T7+UFgyV9b3j/K5L6m8vPigBZv/HuX5h7lcoG1yEnpGesZNCw+J4PsYVl5JZmJJRePb2k9UN59/IyeqGtza0kZ+jwwMmxPdjkAEAxBWgE7A/buVcD21sn1bjOjdhldnasDblbxfXgrIccOggn6GT+9g3qtROfmEeuSn6y/ibKk+fbPMjlcrJ8zwePG9usKZ/VRg62NdxElRXFds/6J1VO9OOnHwwO7n59jtEehkqzqeFXoaKO77fIt9vab5xc/goj76hD97+ECMMACCuAJ1Dq0eyXCj7el+XKP9gWVbyyYHje4nI6ZK6zK+L0r48ET8t4jIGg4wdhfq8ahEpK2gRqzwDevQa4B1zY8gv3nXmE+zGF+bqcHHWLP7zA8/+cd1Jfc+X9666iBZ61VX8T9a25lveGpro0Td0xcKHPHQujDAAgLgC4Lx4BvZIWjRmx/LM7UvTty9NFxHfEF3PSK97Xo2/vBPT4xJ6X2ILlcV10mxlMFyVxCJ/Erm4xNIqq+waPblzZZXvs74RkVZT7XP0aTllaXw9up5I/7jIgDjGASCuAHBEHv6ud80d7vj99Al245mPnTGxdMasIiJ5JUfaiCtlaZdxmQ04kIFJxBWgS+K5KwCuHo1Wfe09/aLGBDEUVzmxlI+98U+jf9WtsgoAgLgCABcmsJ/n0Ml9eHZKJ0osZBUAAHEFAOCIiYWsAgAgrgAAHDGxkFUAAMQVAIAjJhayCgCAuAIAcMTEQlYBABBXAACOmFjIKgAA4goAwBETC1kFAEBcAQA4YmIhqwAAHBBPtQeAbp1YlGfe9zJWkVUAAMQVAIAjJpYjhgayCgCAuAIAcMTE0tBgIasAAIgrAABHTCwuzvxzAABwREy1BwAAAEBcAQAAAADiCgAAAADiCgAAAAAQVwAAAAAQVwAAAADAEbByJQB0BWWnDSkZhekZx9N/zEsrPXOlTxftq42LCes/MGzE4NDwEF/GHwBAXAEAtO3Dzw6sW/tNdFl+bH56QkV+XMXxK33GI14haV/3Odoral3QgAk3D3viNzfy5JZO6kR6RcqmPDcv7U1PDNK4qBkQAMQVwCFE+sfJwCTGoYvZY0zu49+/W/3KJ0urX5y3Pvqn/av3rvcwnblq542uKoquKpK8PSLydvbkh/cdWfLar3oFevIl7HSCB3iLiKGynqEAQFwBHCmuBMRFBsQxDl3MLd0vgr44b/1TH/99hD6nA/swI+3zCXk/PGm2vb/yt9RY2gsGnn2nD30q3G+Q1WbZkrHym+yNIvJw/Jwwn+jFO2fWmWo7pFd1lfUlOVWhg3worQBwTEy1B4DOau2mH2J/3N2xWUURXlP6wPcb/770cy7KuWg1rr8d93q5ofiPW+5+9/s/Tx70ax+3QEfrpNlk/eSVA8lvH+Z6ASCuAAAuSdlpw9r1yU/t3+Ag/Zl+NDnvvz+kZBZyadp037BnSmsL16b8rc5UW1lXaraae3lFaDWuEf6DP0l7q6NKK81ZLbafdhZ5B7td92DURRxeU2b8+q3MXSuyzPUWLjeAy4iqPQB0Sru+P3ZdUYaLxew4XZrw07e7dl8/IiaUq9NKqHfkwJ4j16QstG+x2Mwnq3InRN19uCQls3hfx3YvKNIroK+HSu0Ul9D7ohuxWW1H957yCuzB5QZAXAEASPqhnBGFWQ7VpdiK/O0/5nFpzhYTfK2hoTqvLEP50cct0EXtKiLbs9Y0jV6vMTOu/ZPyvtxQ0s5sFqvFVq0/U6M35nx/Ki6ht19v90vpm5PKSURqyoyX5TeNGBHAHBgAxBUAgBw5VvLg6SKH6lJ0VdER/RkuTStqlWZQ0Eg/XdCfp3xk31huKKk31dl/DPWOfGD4cyv2zm+n0pK6tWDvhpz6WpPyo2+ILmZiqF9vd6vFtvf9nB825vqG6DSu6vLjtQOuDx6eGJ62rSDrv8XK/v59PG59Js4ebAyV9cf2l363LtveWr/4QKvF9tnCQ7kp+lufiYseG1xTZjzwad6pY9XFR04PHN9LWea4+bkqigwiotaoht/ZN2SQz9YlafW1pn0fHNv3wTHfEN3Ns2KDory4+gCIKwDQXeNKRUN0lWPFFReLud7GlWkjrvi6BX2fv/39g0uUH58av6i4Kr958aS0ttBsNcUGjz5XXPlubfbBzfnTX40PivL677tHDm7J739d0PA7+jaGn4IatUY16p5+0WODlS1Wi23I5D5jk/prXNTVpWe+eCPt4Ob8SU8OFpGaMuOO5Znuvi6P/Xu8xkV9Ir3is7+nNvVWo/Lq6XYyq/LT1w71GuCd8FRsjd742d9Ty1/af8+r8RoXtcVkFRHlXGaTddXM3Yc+Oz709j53vjj0g5f294sPnPLCUC46AOIKAACdhsVmTi/eq7wP9uwb6N77y8Prm+/QYDa+sv1XcxNWLZm6zWqzvL3vlea5xWyyluZWhwzy8Q9zF5HIUYEHt+Tr82tancWrp5v9vUrtVKM37vi/zMLMisY+mKzmeotKo0r9/Lh3sNu4h/ord2159ezhG6JzdXdWqZ28g3W5KfryE7X7NuTU15ryUvQFqeV+fdzra03lRktZQW1QlJezqzo0xte/j4eIqFROQVFe9QaziLj7ubq4O3OtARBXAADoTALdQ13UTRPQb+w//WR13tlVlAazce7n90rjJJa5rRKLxWQtzKzI3ncqNMZ3z/ocZxf1xP+NsScTJWZUnapT7r9Sbus6nlo+8bcxd788UqmBVBYZTPUWU1VDxs6i5hPia8uNxUdOK2HGL8xdrVFptKoGoyUwwlMpp7Tqp8loKcysKDte49fbXaV26h3rV36ilqsM4MphIWMAAK4g5UavYM8+apXmztjHYoNHr/nh9Xb2r6wrbTC3eMa8xlmV8FRs1Oie25emr3wi2VhrmrZgZA9P7blaKDl6OjdF7xfmHnVtT6vFVpRZ0WBsXFzYzcdF66ouza1O2dTGogjlBbUWs9XcYFX2yd53qv1fzWqxnS6uy/iqsOrUmdpyY32tqabMWJJdtWtFFhkGwOVCdQUAgCuowWz84NA/kka+MDnmN8XV+f/a81JlXWmrfZovCyYin6b/u3lpxWqxHfg070y1afJzQ3r28/RsuViw1WI7XWxQ5pwoW4L6e0eMCMhN0b/5wA4RCeznWV9rUm7f0jirpr8S/+WbGfs+OPbDxjyL2Roc7T3m/sigKG+r1Wa1WIOjvf16u9/z51Hbl6ZvX5qef7BMo1Xl7C8N6OMx4bGBfr3d1c6q4GhvratGRKxWW03ZmeBob2dXtbOL1sXduTS3esfyzNH3RV7iemUAYOdkszEvEgA6nyHT3kjd+IzD9WrqktSPn3aQzry/618ict+EJ5pv3Ja1pvnywZ2Cfc0utUalcVXbl/OKnxYRPy2ChYMVCQOTbhmYxDgAXQ/VFQAAHJqhsr53nN91Sf3tJQslwOz/ONcvzN2+GhgAdEnMXQEAwHFVl55ZM3tPYUZF89urVGonvzAPBgcAcQUAAHS8/INlWcknlfenS+q+W5ud9uWJ+GkRlFYAdHncDAYA3Y9WKy+/LLNmiZubiMj27XL//VJZycA4IM/AHkmLxuxYnqnMfRcR3xBdz0ive16NZzo7AOIKAKDL0enk++8lOlqefVaWLZNhw2T3btm8WcaNY2wck4e/611zhzMOAIgrAICuTquVnTslOlqmTpUtW0REMjIkI0NGjJCwMCkoYIQAAA6FuSsA0J3MmSPx8bJ6dWNWsdNo5JprGB4AAHEFANBBdDp58kkxGmXBAgYDAEBcAQA4kueek4AAWbeuxU1fzs4SHi5ms/z4IyMEACCuAAA6glYrt90mZrNs2tRie3S06HQMDwDAMTHVHgC6B6WKotHI5s1tfJqXJzU1DBIAwNFQXQGA7mHSJAkIkG+/FSenFq/33xcR2bWL564AAIgrAIAOoiz8dfRoi406ndx0k4hIZiYjBAAgrgAAOlSrWKKUXIxG+egjxgYAQFwBAHSQAQPa2HjvvSLSeq0wAACIKwCADjZsmNxxB49hAQA4MlYGA4Du4fDhFj9qtbJ8ubi5yezZlFYAAA6L6goAdA9btkhdncycKT4+otXKqlUSHy9vvy2LFzM2AADiCgCgQx08KOPGSV2dVFRIfb0MGSITJsgjjzAwAABHxs1gANCdEsvgwQwDAKAToboCAAAAgLgCAAAAAMQVAAAAAMQVAAAAACCuAAAAACCuAAAAAIAjYCFjAEDXpHP1OHtjpH+cDExicLqeSP84BgEgrgAAHIW/1qnM1cPfWMNQnMuU0Q+08UdtQFxkAH/XAkCnwc1gANApxYb7pfv2daguHfEKifbVcmkAAMQVAOj2cWVEdHpgP4fqUp5HYHioH5cGAEBcAYDubsTg0JS+QxyqSwf6xA2/diCXBgBAXAGA7i6uf3DfEYM2R17nIP1J8+1zJHb09ASmhQAAiCsAAJHnn77jnfhpZW2tf3WV1as182767WsL7ueiAACIKwAAEREPncsf/zD9scR53/Uc0IHdSPPt8/DUl5+bndgr0JOLAgC4vJxsNhujAACdV9lpw7xXP/T48cANh7+LrioKrym9Ouc96eab5xH4TeSoI7GjF7w0PTzEl2sBACCuAADasO3bI998nXokT59XY746Z+zlpgrv6XnDpGHMVwEAEFcANKkx1P/tX1+9/OztDAUAAOjamLsCdL6s8syz/9n8XQ5DAQAAiCsAHC6rPL/hNYYCAAAQVwA4YlaJripiNAAAAHEFAFkFAACAuAKArAIAAEBcAcgqAAAAxBUAZBUAAADiCkBWAQAAIK4AIKsAAAAQVwCyClkFAAAQVwCQVQAAAIgrAMgqAAAAxBWArAIAAEBcAUBWAQAAIK4AZBUAAADiCgCyCgAAQAfTMARAZ8wqHjbTkGlvMHoAAKAriQ7oseGtJ5pvcbLZbIwL0LmyCgAAQJc0ZOqS1I+fbr6Fm8EAsgoAAICDIq4AZBUAAADiCgCyCgAAAHEFIKsAAAAQVwCQVQAAAIgrAFkFAACAuAKArAKgqxk2TAwG2b27E3QyN1d8fLhiAIgrAFkFQEfT6aS0VGy2Fq+sLJk1i7EBAOGp9gBZBUDHM5tlzx4xGEREwsIkJkaWLhVnZ1m8mLEB0M1RXQHIKgAcIK489JDcdpvcdpsMHiyPPCIiMnMm90QBAHEFIKsAcDAbNoheL8HB4uHBYAAgrgAgqwBweAMGyOrVYjA0zW+ZMqWN3WbMkLy8xn1OnpTly89ZoklMbJrXnpgoNlvrifjz5p1z48qV59srZfb8ypUybJhkZIjNJrm5EhYmIqLVymuvNR5rMsnq1eLry3UG0JoNwBVQXWt85PFlh71CbCK8ePHidc6XTmcrLbWdOWMLC2vaOG+ezWaz7d7dtOX2220Gg81ms2Vl2bZutaWm2mw2m8lkmzKlRWvr1zduT062bd3aeMizz9pEbMOG2QyGpjYTE1u00GY3lNZyc20+Pi022o86n14p501ObtwzL6/pLPbe2o9VtDojL168utPrmqlLWv1NRVwByCq8ePHq6LhiDxhbt9oyMmw2m+3rr1v8yZ6YaPv6a9sNN7QXaZQEUlDQInI89FDjUc3jivK+Va5QwoOSbewda167NCwAAATzSURBVBU/lI32OHE+vVLOdXYIUXrbPCDFxjaekbjCixdxpRluBgO4BwxAR9No5Prr5dZb5dZbJSZGROT662XBgqYdNm2Sm26Sb75p2rJli9TVtWjk3ntFRN54QwoKmja+916Lo5S7s3bvFq1Wpk6VLVuath8+LCJy112NP06aJAEB8sUXotFIYmKLjUVFUll5vr1SGI1yww2NRzXv7bp1Tb1NT5dbbmn7cADd+X8gGQLg8nrmD+/9zyf/IKsAuABGo0RHN/3hPmOGLFsms2ZJfn6LtYwHDJCbbpLJkxsTjptb00darUREiNks2dntnahfP9m9W1Sq1llFSRq//72EhIiPj1RWyjXXiNks770nI0bIhAmNG5WM8cknLQ5sp1d2KSktQpS9t5s2cfEBEFeAq+r5p+/8W0nJkk/+4mE6w2gAuBhvvy0VFfLJJzJzprzzjlRWilYrGzY0VTnO5uws4eFiNsuPP7bXckGBODlJfLwkJraOKxkZkpEhw4bJ2LGyfbvcdpucOCG7dklensTFiYeHGAwSESFGo3z0UVPqaL9XAHDJuBkMuMyiwwOef+2JZ+76Q41zD0YDwEUqKJC6uqa1jFetksREycuTCRPEyUmcnGT48Bb3TZlMkpcnGo1cc017zZpMcuONotfLjBny7LMtPmpokK1bG2/9GjxYBg+WXbukpES2bhVXV7n77saNzeskv9grACCuACQWAF2c/dap3/2u9USU5mEjN1c0GomK+oXWDAZ5/HERkddfb73osDLzZMIEGTJE3NwkM7Np4113yZQp4ubWdCfY+fTqXM6/twCIKwwBQGIB4HD55Pnnxc2t9ZSPs3doTpkrP3Nmiwet3H+/3HBD68M3bZL580WjkX/8o8XOyv1gwcHy0ENNN30pG0eMkOnTW9wJdp69OpcNG1r3VlkD4DwPB9BtMHcFuMKJRYR5LAB+6V9jjbz3nhgMjT+OHy9ubnLihDz4oMjPt2nFx8vGjbJnj9TXy3XXtfFn/V//KrfdJvHxUloqe/aIwdDYzuzZbVQ/FiyQAQPkvvtk82YZN65xo/1EN9wg337bmJSUSkh8vMTENG08/16dy9atsn9/Y2+/+kp69ZJrrpETJyQvj8QCoAUekQFcUYdzSx+555Vq5x6spM6LF69zPnellZMnbcuXt372yB//2PgAE+WxjLffbistbfGEExGbVmt77bWm3Zq30+oxkcqplWe8zJnTxmNSVq5s/YyU5k9lOf9enX3e5r1dvbrxWJPJtnSpTau1ff89z13hxYvnrjTnZLPZyGzAFXUkT/+3F/9FjQUAAKB9Q6YuSf346eZbmLsCXHHMYwEAALg4xBWAxAIAAEBcAUgsJBYAAADiCkBiAQAAIK4AILEAAAAQVwASCwAAAHEFAIkFAACAuAKQWEgsAAAAxBWAxAIAANDZaBgCoOMTi8iFPvP+3jvnH1F7MYAAAKAr8XBRE1eArpBYjqi9Uj9+mtEDAABdGzeDAQ6TWLgrDAAAgLgCkFgAAACIKwBILAAAAMQVgMQCAABAXAFAYgEAACCuACQWEgsAACCuACCxAAAAEFcAkFgAAACIKwCJBQAAgLgCgMQCAABAXAFILAAAAMQVACQWAAAA4goAEgsAAABxBSCxAAAAdCIahgDofIlFRMwMBgAA6PqorgCdMrH08nZlKAAAQJf3/+ogbJEGVt68AAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af26a3b96b7614769a6d6e9f0dc33871",
     "grade": false,
     "grade_id": "deep_intro",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Problem 3: Neural Networks (45 points)\n",
    "\n",
    "\n",
    "In this final problem, we'll be implementing our own Neural Networks framework and use it to build a Multi-Layer Perceptron.\n",
    "The MLP is a sequence of linear projections and activation functions, each of which will be implemented as a layer.\n",
    "\n",
    "Each layer will have its own parameters (none for the activations), a `forward` method that applies the transformation,\n",
    "and a `backward` method that back-propagates the gradient and computes the parameters gradients.\n",
    "\n",
    "![network.png](attachment:network.png)\n",
    "To understand how the mechanism works, let's consider the neural network that consists of one layer $f_\\theta:  \\mathbb{R}^d \\mapsto \\mathbb{R}^q$ where the parameter is optimized to minimize the loss $L$.\n",
    "\n",
    "Our dataset consists of samples $(x_i)$ with $d$ features and a q-dimensional targets $(y_i)$. $f_\\theta$ transforms  $(x_i)$ into $(z_i)$. We'll be using the Mean Squared Error (MSE) for the loss function $L$.\n",
    "\n",
    "The neural network will have two passes:\n",
    " - forward pass where we transform the input into output,\n",
    " - and backward pass where we backpropagates the gradient and compute the gradient of the loss w.r.t to parameters.\n",
    " \n",
    "Note that the gradient computation might require saving the input data from the forward pass since we won't be providing any data during the backward pass. We'll deal with that later.\n",
    "\n",
    "Now, let's start from the layer $f_\\theta: \\mathbb{R}^d \\mapsto \\mathbb{R}^q$, with parameter $\\theta$.\n",
    "\n",
    "In order to compute the gradient for $\\theta$, we first need the derivative of the loss w.r.t the layer's output $\\frac{\\partial L}{\\partial z}$\n",
    "\n",
    "We'll only deal with MSE loss defined as:\n",
    "\\begin{align}\n",
    "MSE(y, z) = \\frac{1}{m} \\sum_{i=1}^{m} ||f_\\psi(x_i) - y_i ||^2\n",
    "\\end{align}\n",
    ", where $m$ is the sample size and $z_i = f_\\theta(x_i)$.\n",
    "\n",
    "The gradient of the loss w.r.t to its input $z$:\n",
    "\n",
    "\\begin{align}\n",
    " \\frac{\\partial MSE(y, z)}{\\partial z}  = \\frac{2}{m} (z - y)\n",
    "\\end{align}\n",
    "\n",
    "- **3.1 [2 points]** Complete `MSE`'s `forward` method that returns the MSE between `y_pred` and `y_true`\n",
    "- **3.2 [3 points]** Complete `MSE`'s `backward` method that returns the derivative w.r.t to the input `z`.\n",
    "\n",
    "_Hint_: Notice that no argument is provided for the loss backward pass. You'll have to cache `y_pred` and `y_true` into your object-level `saved_arrays` variable during the `forward` call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2b7087fa8a52a22eb5f4708f97d317f",
     "grade": true,
     "grade_id": "mse_code",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MSE:\n",
    "    saved_arrays = []\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        Compute the MSE loss\n",
    "        @param y_pred: shape (m,q)\n",
    "        @param y_true: shape (m,q)\n",
    "        @return: scalar\n",
    "        \"\"\"\n",
    "        # Workspace 3.1\n",
    "        mse = 0\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return mse\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Compute the gradient w.r.t to the prediction y_pred\n",
    "        You'll have to cache the necessary quantities into your object-level \n",
    "            `saved_arrays` variable during the forward pass\n",
    "        @return: shape (m,q)\n",
    "        \"\"\"\n",
    "        # Workspace 3.2\n",
    "        grad_input = None\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing MSE\n",
    "mock_X = np.array([[-0.4838731, 0.08083195], [0.93456167, -0.50316134]])\n",
    "expected_mse = 0.17090547876852463\n",
    "expected_grad = np.array([[-0.24193655, 0.04041597], [0.46728084, -0.25158067]])\n",
    "mse = MSE()\n",
    "assert np.isclose(mse.forward(mock_X, mock_X / 2), expected_mse)\n",
    "assert np.alltrue(np.isclose(mse.backward(), expected_grad))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4201d32335d43a203ed02677a1a4b2f5",
     "grade": false,
     "grade_id": "gradients",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that we have the `grad_input` of `MSE`,  it's going to be `grad_output` from the perspective of the layer $f_\\theta$.\n",
    "- `grad_output` of layer $f_\\theta$ is the derivative of the loss w.r.t to the layer's output (which is the next layer's input)\n",
    "- `grad_input` of layer $f_\\theta$ is the derivative of the loss w.r.t the layer's input\n",
    "\n",
    "The `forward` method of a layer applies the transformation and keeps track of any relevant quantity for the gradient backpropagation.\n",
    "\n",
    "The `backward` method is expected to return the gradient of the loss w.r.t to the layer's input using the chain rule.\n",
    "\n",
    "In our implementation, we want to compute in each layer $f_\\theta$:\n",
    "- $\\frac{\\partial L }{\\partial \\theta} = \\frac{\\partial L }{\\partial z} \\frac{\\partial z }{\\partial \\theta}$ is the `parameter.gradient` (if any)\n",
    "- $\\frac{\\partial L }{\\partial x} = \\frac{\\partial L}{\\partial z} \\frac{\\partial f_\\theta(x)}{\\partial x}$, the the `grad_input` of layer $f$ and return it\n",
    "\n",
    "The backward pass consists of sequentially doing what we've just mentioned for $f_\\theta$\n",
    "\n",
    "1. get the initial `grad_output` from loss layer (top layer)\n",
    "2. In reverse order:\n",
    "    - pass current `grad_output` to the next layer's backward\n",
    "    - inside the layer's backward: compute `grad_input` and `parameter.gradient` (if there are any parameters)\n",
    "    - `grad_output` <- `grad_input`\n",
    "    - repeat 2\n",
    "3. Loop through the parameters and apply the gradient\n",
    "\n",
    "We'll apply this to our first layers: `sigmoid` and `ReLU`.\n",
    "We don't have to worry about `parameter.gradient` since they don't have any parameters.\n",
    "\n",
    "- **3.3 [5 points]** Complete the Sigmoid activation layer. `forward` method applies the activation and `backward` should use the\n",
    "chain rule to compute `grad_input` of the layer. You'll need to save the activation values to use them in `backward` call, for that you should use `self.saved_arrays` to cache them.\n",
    "\n",
    "- **3.4 [5 points]** In a similar way, complete the ReLU activation layer. Note that $\\frac{\\partial \\text{ReLU}(x)}{\\partial x} = 1_{x\\geq 0}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2e021237b180a2331934e8357ce3ab1",
     "grade": true,
     "grade_id": "activations_code",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Layer(object):\n",
    "    \"\"\"\n",
    "    Template Layer that will be used to implement all other layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"\"):\n",
    "        self.saved_arrays = []  # You might need them for the backward pass\n",
    "        self.parameters = []\n",
    "        self.name = name  # to identify the layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive an array containing the input and return an array containing the output.\n",
    "        You can cache arbitrary objects for use in the backward pass in self.saved_arrays\n",
    "        @param x: input array of size (batch_size, d)\n",
    "        @return: output array\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive an array containing the gradient of the loss with respect to the output,\n",
    "        and we need to compute the gradient of the loss with respect to the input and the gradient of the weights (default as 0)\n",
    "        @param grad_output:\n",
    "        @return: grad\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class Sigmoid(Layer):\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Apply the sigmoid function to x. Don't forget to clip x to the interval [-25.0, 25.]\n",
    "         before applying the activation\n",
    "        @param x: input array of shape (batch_size, q)\n",
    "        @return: element-size sigmoid of shape (batch_size, q)\n",
    "        \"\"\"\n",
    "        sigmoid = np.zeros_like(x)\n",
    "        # Workspace 3.3.a\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return sigmoid\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Compute the grad_input and grad_parameters. Activations don't have parameters\n",
    "        @param grad_output: input array of shape (batch_size, q)\n",
    "        @return: grad_input of shape (batch_size, q)\n",
    "        \"\"\"\n",
    "        grad_parameters = 0\n",
    "        grad_input = 0\n",
    "\n",
    "        # Workspace 3.3.b\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "class ReLU(Layer):\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Apply the ReLU function to x.\n",
    "        @param x: input array of shape (batch_size, q)\n",
    "        @return: element-size ReLU of shape (batch_size, q)\n",
    "        \"\"\"\n",
    "        relu = 0\n",
    "        # Workspace 3.4.a\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return relu\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Compute the grad_input and grad_parameters. Activations don't have parameters\n",
    "        @param grad_output: input array of shape (batch_size, q)\n",
    "        @return:grad_input: of shape (batch_size, q)\n",
    "        \"\"\"\n",
    "        grad_input = 0\n",
    "        grad_parameters = 0\n",
    "        # Workspace 3.4.b\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid Tests\n",
    "mock_X = np.array([[-0.4838731, 0.08083195], [0.93456167, -0.50316134]])\n",
    "grad_output = np.array([[0.19960269, 0.20993069], [-0.85814751, -0.41418101]])\n",
    "sig_x = np.array([[0.38133797, 0.52019699], [0.71799983, 0.37679803]])\n",
    "grad_sig_x = np.array([[0.04709013, 0.05239704], [-0.17375434, -0.09725851]])\n",
    "sigmoid = Sigmoid()\n",
    "assert np.alltrue(np.isclose(sigmoid.forward(mock_X), sig_x))\n",
    "assert np.alltrue(np.isclose(sigmoid.backward(grad_output), grad_sig_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU Tests\n",
    "relu_x = np.array([[-0., 0.08083195], [0.93456167, -0.]])\n",
    "grad_relu_x = np.array([[0., 0.20993069], [-0.85814751, -0.]])\n",
    "relu = ReLU()\n",
    "assert np.alltrue(np.isclose(relu.forward(mock_X), relu_x))\n",
    "assert np.alltrue(np.isclose(relu.backward(grad_output), grad_relu_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we'll move to the exciting part. We'll implement our own _dense_ (linear) layer that has two parameters $\\theta=(w,b)$,\n",
    "with $w$ being the weights array and $b$ the bias.\n",
    "This layer $f_\\theta$ projects a $d$ dimensional input into an $q$ dimensional space as follows:\n",
    "\n",
    "\\begin{align}\n",
    "f_\\theta(x) = xw + b\n",
    "\\end{align}\n",
    "\n",
    "and its derivatives are:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial f_\\theta}{\\partial x} &= w \\\\\n",
    "\\frac{\\partial f_\\theta}{\\partial w} &= x^T \\\\\n",
    "\\frac{\\partial f_\\theta}{\\partial b} &= 1_m\n",
    "\\end{align}\n",
    "\n",
    "where $1_q$ is the ones vector with the same dimension as $b$\n",
    "\n",
    "\n",
    "To help you keep track of the gradient, we will be wrapping the parameters numpy arrays using the `Parameter` class.\n",
    "`Parameter` instances are an extension of numpy arrays, but they have additional:\n",
    " - attribute `gradient`: initialized with zeros and has the same shape as the array\n",
    " - method `zero_gradient`: resets the gradient values to zero\n",
    " - method `apply_gradient(grad)`: adds `grad` to the array\n",
    " - optional attribute `name`: This is going to be useful when implementing the bonus `Adam` optimizer\n",
    "\n",
    "_Hint_: At this level, our implementation imitates Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "833cbafd619836abcf00b9ae8e005baa",
     "grade": false,
     "grade_id": "parameter_class",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Parameter(np.ndarray):\n",
    "    def __new__(cls, input_array, name=\"\"):\n",
    "        array = np.asarray(input_array).view(cls)\n",
    "        array.gradient = np.zeros(array.shape)\n",
    "        array.name = name\n",
    "        return array\n",
    "\n",
    "    def __array_finalize__(self, array):\n",
    "        if array is None: return\n",
    "        self.gradient = getattr(array, \"gradient\", None)\n",
    "        self.name = getattr(array, \"name\", None)\n",
    "\n",
    "    def zero_gradient(self):\n",
    "        self.gradient = self.gradient * 0.0\n",
    "\n",
    "    def apply_gradient(self, grad):\n",
    "        self[:] = self[:] + grad[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# demo on how to use Parameter\n",
    "w = Parameter(np.ones(3, ), name=\"W_0\")\n",
    "print(\"Initial w:\", w, id(w))  # object memory identifier, same id = same object\n",
    "print(\"Name of w:\", w.name)\n",
    "print(\"Initial gradient:\", w.gradient)\n",
    "w.gradient = np.array([0.1, 0.2, 0.3])\n",
    "print(\"Gradient:\", w.gradient)\n",
    "w.apply_gradient(-0.2*w.gradient) # learning rate 0.2\n",
    "w.zero_gradient()\n",
    "print(\"Final w:\", w, id(w))\n",
    "print(\"Final gradient:\", w.gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5964cab26f5285fc4f2cca2861088e3",
     "grade": false,
     "grade_id": "q35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- **3.5 [6 points]** Complete the `Dense` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "791a15cb876dfe38ca0db8d51fb24af3",
     "grade": true,
     "grade_id": "a3_5",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "\n",
    "    def __init__(self, input_dimension, output_dimension, name=\"\"):\n",
    "        \"\"\"\n",
    "        Initialize the layer's parameters\n",
    "        :param input_dimension: The dimension of the input data\n",
    "        :param output_dimension: the dimension of the output\n",
    "        :param name: optional, name to identify the layer\n",
    "        \"\"\"\n",
    "        super().__init__(name)\n",
    "        # Do not change the initialization method\n",
    "        self.bias = Parameter(np.random.randn(1, output_dimension) / output_dimension ** 0.5)\n",
    "        self.weights = Parameter(np.random.randn(input_dimension, output_dimension) /\n",
    "                                 (output_dimension * input_dimension) ** 0.5)\n",
    "        self.parameters = [self.bias, self.weights]\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Apply the linear projection and save the necessary objects for the backward pass\n",
    "        @param x of shape (m, input_dimension)\n",
    "        @param z = xw + b of shape (m, output_dimension)\n",
    "        \"\"\"\n",
    "        output = 0\n",
    "        # Workspace 3.5.a\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Compute the gradients using the aforementioned formulas. Do not change the return signature\n",
    "        Update the parameters gradient attribute directly\n",
    "        @param grad_output: shape (m, output_dimension)\n",
    "        @return: grad_input of shape (m, input_dimension)\n",
    "        \"\"\"\n",
    "        self.weights.zero_gradient()\n",
    "        self.bias.zero_gradient()\n",
    "        # Workspace 3.5.b\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return grad_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layer test\n",
    "mock_X = np.array([[-0.4838731, 0.08083195], [0.93456167, -0.50316134]])\n",
    "np.random.seed(42)\n",
    "dense = Dense(2, 2)\n",
    "dense.forward(mock_X)\n",
    "gradient_input = dense.backward(grad_output)\n",
    "dense_x = np.array([[0.18506688, -0.47570709], [0.71279085, 0.67281937]])\n",
    "grad_dense_x = np.array([[0.22450554, -0.04794509], [-0.59331118, 0.14895661]])\n",
    "grad_dense_weights = np.array([[-0.89857414, -0.48865751], [0.44792093, 0.22536898]])\n",
    "grad_dense_bias = np.array([[-0.65854482, -0.20425032]])\n",
    "assert np.alltrue(np.isclose(dense_x, dense.forward(mock_X)))\n",
    "assert np.alltrue(np.isclose(grad_dense_x, gradient_input))\n",
    "assert np.alltrue(np.isclose(grad_dense_weights, dense.weights.gradient))\n",
    "assert np.alltrue(np.isclose(grad_dense_bias, dense.bias.gradient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aac3947fdf9a77ccb04a49ee9ab494df",
     "grade": false,
     "grade_id": "q3_6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that we implemented the layers, we need 2 more ingredients:\n",
    "   - Optimizer: to manage how to update the layers parameters using the computed gradients\n",
    "   - Network: to store our stack of layers and manage the forward and backward passes\n",
    "\n",
    "<br>\n",
    "\n",
    "- **3.6 [4 points]** Complete the `SGD` class following the details provided in the docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f77f4e761733948fae2b0a3f8b8123d",
     "grade": true,
     "grade_id": "a3_6",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SGD(object):\n",
    "\n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layers = None\n",
    "\n",
    "    def set_layers(self, layers):\n",
    "        \"\"\"\n",
    "        Saves the layers stack\n",
    "        @param layers: list of Layer instances (the same stack stored in the network)\n",
    "        @return: None\n",
    "        \"\"\"\n",
    "        self.layers = layers\n",
    "\n",
    "    def apply_gradients(self):\n",
    "        \"\"\"\n",
    "        Multiply the gradients by the learning_rate before applying then to the layers' parameters\n",
    "        It's good practive to zero out the parameter gradient after the update\n",
    "        @return: None\n",
    "        \"\"\"\n",
    "        # Workspace 3.6\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38d4175ec83bc8707c9b2fefa96c92a1",
     "grade": false,
     "grade_id": "q3_7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- **3.7 [9 points]** Complete the `forward` and `backward` methods of the `Network` class\n",
    "\n",
    "We're providing the rest of the methods as a sanity check for the previous questions.\n",
    "The network forward and backward pass should work without raising an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d3d050672ba99c805efd2ea94750f0b",
     "grade": true,
     "grade_id": "a3_7",
     "locked": false,
     "points": 9,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "\n",
    "    def __init__(self, optimizer, loss):\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.layers = []\n",
    "        self.optimizer.set_layers(self.layers)\n",
    "\n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Given input x, apply the self.layers in the natural order and return the output\n",
    "        @param x: shape (m,d)\n",
    "        @return: array of shape (m,p) where p is the output dimension of the last linear layer\n",
    "        \"\"\"\n",
    "        output = x\n",
    "        # Workspace 3.7.a\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return output\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Perform the backward pass, starts with the loss to get the first grad_output\n",
    "        Loop through the layers in backward pass by providing the grad_output\n",
    "        Warning: should only be called after a forward call\n",
    "        @return: None\n",
    "        \"\"\"\n",
    "        grad_output = self.loss.backward()\n",
    "        # Workspace 3.7.b\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "\n",
    "\n",
    "    def fit_batch(self, batch_x, batch_y):\n",
    "        \"\"\"\n",
    "        Perform single batch fit.\n",
    "        First, forward pass using batch_x\n",
    "        Compute the loss using the output and batch_y\n",
    "        Then call self.backward and self.optimzer to apply the gradient\n",
    "        @param x: input sample of shape (batch_size, m)\n",
    "        @param y: target array of shape (batch_size, 1)\n",
    "        @return: Loss value\n",
    "        \"\"\"\n",
    "        # Workspace 3.7.c\n",
    "        \n",
    "        output = self.forward(batch_x)\n",
    "        loss = 0\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        return loss\n",
    "\n",
    "    def fit(self, X, y, batch_size=32, epochs=1, shuffle=True):\n",
    "        \"\"\"\n",
    "        Multiple fit passes over the data\n",
    "        \n",
    "        @param x: input sample of shape (batch_size, m)\n",
    "        @param y: target array of shape (batch_size, 1)\n",
    "        @return: Loss value\n",
    "        \"\"\"\n",
    "        permutation = np.arange(X.shape[0])\n",
    "        losses = []\n",
    "        for _ in range(epochs):\n",
    "            n_batches = 0\n",
    "            loss = 0.0\n",
    "            if shuffle:\n",
    "                np.random.shuffle(permutation)\n",
    "            for start_idx in range(0, permutation.shape[0], batch_size):\n",
    "                batch_idxs = permutation[start_idx:start_idx+batch_size]\n",
    "                batch_x = X[batch_idxs]\n",
    "                batch_y = y[batch_idxs]\n",
    "                loss += self.fit_batch(batch_x, batch_y)\n",
    "                n_batches += 1\n",
    "            losses.append(loss/n_batches)\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing SGD optimizer\n",
    "mock_X = np.array([[-0.4838731, 0.08083195], [0.93456167, -0.50316134]])\n",
    "mock_y = 0 * mock_X + 1\n",
    "expected_weights = np.array([[0.25573477, 0.5835771], [-0.12784404, -0.10800216]])\n",
    "sgd_network = Network(SGD(1e-1), MSE())\n",
    "np.random.seed(42); sgd_network.add_layer(Dense(2, 2))\n",
    "for _ in range(4):\n",
    "    sgd_network.fit_batch(mock_X, mock_y)\n",
    "assert np.alltrue(np.isclose(sgd_network.layers[0].weights, expected_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f12b3ca6c621b3ac26b141f9b305c6b",
     "grade": false,
     "grade_id": "q3_8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- **3.8 [6 points]** Create a neural network with your own choice of layers and activations. The last output should have dimension 1 to match that of our target. Since our target variable is either 0 or 1, you should use Sigmoid activation as the last layer to get outpouts in interval $[0,1]$. You'll be tweaking this to find a good choice of layers for the next questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "186c0233d99911ee67b2c59d25608395",
     "grade": true,
     "grade_id": "a3_8",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Workspace 3.8\n",
    "network = Network(optimizer=SGD(learning_rate=0.2), loss=MSE())\n",
    "#BEGIN \n",
    "# code here\n",
    "#END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "39ee969b9494921c2a0be801b19ac199",
     "grade": false,
     "grade_id": "q3_9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- **3.9 [5 points]** Using a batch size of 16, train for 200 epochs on circles' training parition to minimize the MSE. Plot the MSE at the end of each epoch on the entire dataset (using `circles.X` and `circles.labels`). You might need to go back and tweak the neural network (layers, learning rate of SGD) to get good performance.\n",
    "\n",
    "You'll have to try different learning rates to find the right one. You should expect an MSE ~ 0.1 at the end of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "557ac579c691e8ed74e088469f82f410",
     "grade": true,
     "grade_id": "cell-7512b0c741f87886",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 200\n",
    "losses = []\n",
    "# Workspace 3.9\n",
    "#BEGIN \n",
    "# code here\n",
    "#END\n",
    "tests.show_decision_surface(network, circles.X, circles.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f3b731d3406ead368df82635fdf154c",
     "grade": false,
     "grade_id": "adam",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Adam : Adaptive moment estimation (Bonus)\n",
    "SGD optimizer the simplest we can use. However, the batch estimation of the gradient can be noisy. [Adam](https://arxiv.org/pdf/1412.6980.pdf) optimizer smoothes out the gradient\n",
    "using a moving average of past gradients (first moment) and scales them using a moving average estimate of their norm (second moment).\n",
    "It works as follows:\n",
    "\n",
    "- Parameters: learning rate $\\alpha$, decay rates $\\beta_1$ and $\\beta_2$.\n",
    "- Initialize: $t=0$, $m = 0$, $v = 0$ (each network parameter should have its corresponding $m$ and $v$)\n",
    "- For each `apply_gradient` call given gradient $g$ do:\n",
    "    - $t \\leftarrow t+1$\n",
    "    - $m \\leftarrow \\beta_1 m + (1-\\beta_1) g$\n",
    "    - $v \\leftarrow \\beta_2 v + (1-\\beta_2) g^2$\n",
    "    - $\\hat{m} \\leftarrow \\frac{1}{1 - \\beta_1 ^ t} m$\n",
    "    - $\\hat{v} \\leftarrow \\frac{1}{1 - \\beta_2 ^ t} v$\n",
    "    - apply gradient $\\alpha .\\hat{m} / (\\sqrt{\\hat{v}} + \\epsilon)$ (division and sqrt are element wise, epsilon is a small constant to avoid zero division, we'll use $\\epsilon =10^{-8}$)\n",
    "Refer to the original paper is there is any confusion around the iterations\n",
    "\n",
    "**3.10 (Bonus Question) [5 points]** Complete Adam optimizer class and redo 3.9 using Adam optimizer instead. Try a learning rate that gave a bad performance using SGD.\n",
    "Which optimizer is better? why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "771a3945b441c2a412872682f742b431",
     "grade": true,
     "grade_id": "a3_10_1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Adam(SGD):\n",
    "    def __init__(self, learning_rate, beta_1, beta_2):\n",
    "        super(Adam, self).__init__(learning_rate)\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.first_moment = None\n",
    "        self.second_moment = None\n",
    "        self.time_step = 0\n",
    "        self.gradients = []\n",
    "\n",
    "    def apply_gradients(self):\n",
    "        # Workspace 3.10.a\n",
    "        #BEGIN \n",
    "        # code here\n",
    "        #END\n",
    "        self.gradients = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Adam optimizer\n",
    "mock_X = np.array([[-0.4838731, 0.08083195], [0.93456167, -0.50316134]])\n",
    "mock_y = 0 * mock_X + 1\n",
    "expected_weights = np.array([[-0.07104128, 0.36260954], [-0.50247728, -0.46956692]])\n",
    "adam_network = Network(Adam(1e-1, 0.9, 0.99), MSE())\n",
    "np.random.seed(42), adam_network.add_layer(Dense(2, 2))\n",
    "for _ in range(4):\n",
    "    adam_network.fit(mock_X, mock_y)\n",
    "assert np.alltrue(np.isclose(adam_network.layers[0].weights, expected_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe44fdb1eaea76cb8310274402e2f372",
     "grade": true,
     "grade_id": "cell-b8511b5d5947a05b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 200\n",
    "losses = []\n",
    "network = Network(optimizer=Adam(1e-1, 0.9, 0.99), loss=MSE())\n",
    "# Workspace 3.10.b\n",
    "#BEGIN \n",
    "# code here\n",
    "#END\n",
    "tests.show_decision_surface(network, circles.X, circles.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workspace 3.10.c\n",
    "% Which optimizer is better\n",
    "\n",
    "%BEGIN\n",
    "\n",
    "%END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Bonus Problem: Deep Q-Learning (10 points)\n",
    "\n",
    "This problem has a low [#points / effort] ratio, but we promise it's going to be fun and rewarding.\n",
    "We'll start first by explaining two elements of Markov Decision Process (MDP): policy $\\pi$ and its state-action functions $Q_\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2b8e3acc4bee749ee7c9cec74c2b944",
     "grade": false,
     "grade_id": "rl_imports",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import data\n",
    "import tests\n",
    "import tqdm.notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "environment = data.GRID(grid_size=16, max_time=2000)\n",
    "environment.reset()\n",
    "environment.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "We'll be using a _4-rooms_ environment where the goal of the agent (white square) is to reach the target (red square).\n",
    "The grid is 16 by 16, so there are 256 states. Not all the states are accessible, since the agent can't cross the blue walls.\n",
    "Each state $s$ is represented as a tuple $(x_s, y_s)$ that reflects the position of the agent.\n",
    "\n",
    "There are 4 possible actions at each state (clockwise): Up (0), Right(1), Down(2), Left(3).\n",
    "The agent gets a penalty (reward = -1) if it hits the blue walls and a reward = 1 if it reaches the target.\n",
    "The episode ends (game over) when the target is reached or the agent has taken 2000 steps.\n",
    "\n",
    "We will be using Q-learning to find a good policy that will allow us to reach the target before the time runs out.\n",
    "\n",
    "At step $t$, the agent is located at state $s_t$ and chooses an action $a_t = \\pi(s_t)$ following the policy $\\pi$\n",
    "\n",
    "The agent then gets reward $r_t$ and moves to state $s_{t+1}$. The process repeats until we reach a final state $s_T$ (`game_over == True`)\n",
    "\n",
    "We'll call a replay a sequence of tuples $(s_t, a_t, r_t, s_{t+1})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# How to create a replay with one element\n",
    "# repeat as long as game_over is false\n",
    "replay = []\n",
    "current_state = environment.reset()\n",
    "action = 2\n",
    "print(\"Initial state:{}\".format(current_state))\n",
    "new_state, reward, game_over = environment.step(action)  # down\n",
    "replay.append((current_state, action, reward, new_state))\n",
    "current_state = new_state\n",
    "print(\"Took action: {}\".format(data.grid.ACTIONS_NAMES[action]))\n",
    "print(\"New state: {}\\nReward: {}\\nGame over:{}\".format(new_state, reward, game_over))\n",
    "environment.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Starting at time $t=0$, The agent's goal is to maximize the expected discounted rewards:\n",
    "\\begin{align}\n",
    "\\eta_\\pi = \\sum_{t | a_t =\\pi(s_t)} \\gamma^t r_t\n",
    "\\end{align}\n",
    "$0<\\gamma<1$ is the discount rate. We'll be using $\\gamma = 0.95$\n",
    "\n",
    "The main role of discounting the rewards is to motivate the agent to achieve the goal as early as possible (no procrastination).\n",
    "\n",
    "It makes reaching the goal at $t=1$, for example, more desirable than at $t=100$: $r_1=1$ contributes $\\gamma^1 =0.95$ while $r_{100} = 1$ will only count as $\\gamma^{100} =0.006$ in $\\eta_\\pi$.\n",
    "\n",
    "$Q_\\pi(s_t, a_t)$ is defined as the expected discounted rewards if we start at state $s_t$, take an initial actions $a_t$, and\n",
    "follow the policy $\\pi$ to decide the remaining action $(a_{t+1},..... a_{T-1})$.\n",
    "\n",
    "\\begin{align}\n",
    "Q_\\pi(s,a) = \\eta_\\pi, \\text{ such that } s_0 = s \\text{ and } a_0 = a\n",
    "\\end{align}\n",
    "\n",
    "The principle behind Q-learning, as the name suggests, is to learn the optimal $Q^*$.\n",
    "Since at each instant $t$, we want to pick the action that yields the best expected rewards, the optimal policy $\\pi^*$ would be:\n",
    "\\begin{align}\n",
    "\\pi^*(s) = \\arg\\max_a Q^*(s, a)\n",
    "\\end{align}\n",
    "\n",
    "__So how do we learn the optimal $Q^*$?__\n",
    "\n",
    "By exploring the environment and saving a replay $\\text{Replay} = \\{(s_t, a_t, r_t, s_{t+1})| t\\leq T\\}$ (one that reaches the goal, hopefully),\n",
    "\n",
    "we can use _Bellman equations_ to update our estimate of the $Q$ function in the following way:\n",
    "\\begin{align}\n",
    "Q_{new}(s_t, a_t) \\leftarrow r_t + \\gamma \\max_a Q_{old}(s_{t+1}, a), \\;\\;\\; \\forall \\; (s_t, a_t, r_t, s_{t+1})\\in \\text{Replay}\n",
    "\\end{align}\n",
    "\n",
    "We can prove that repeating this update will make our estimate converge to a unique optimal state-action value function $Q^*$.\n",
    "\n",
    "Instead of \"brutally\" updating Q, we'll use a learning rate $\\alpha$, so that the update would be :\n",
    "\\begin{align}\n",
    "Q_{new}(s_t, a_t) \\leftarrow  (1-\\alpha)Q_{old}(s_t, a_t) + \\alpha\\big[r_t + \\gamma \\max_a Q_{old}(s_{t+1}, a) \\big]\n",
    "\\end{align}\n",
    "\n",
    "In this first part, we'll use an array `Q` of shape (16 x 16 x 4) to store $Q$, and the value $Q(s,a)$ would be accessed via `Q[x_s, y_s, a]`.\n",
    "\n",
    "- 4.1 **[3 points]** Complete the class method `TabularQ.update` to apply _Bellman_ updates provided a replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "972003c3038066ec3f5148682ec01a1f",
     "grade": true,
     "grade_id": "tabularq",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TabularQ:\n",
    "    def __init__(self, gamma=0.95, learning_rate=0.01):\n",
    "        self.Q = np.zeros((16, 16, 4))\n",
    "        self.gamma = gamma\n",
    "        self.alpha = learning_rate\n",
    "\n",
    "    def update(self, replay):\n",
    "        for s_t, a_t, r_t, s_t_p_1 in replay:\n",
    "            # Workspace 4.1\n",
    "            #BEGIN \n",
    "            # code here\n",
    "            #END\n",
    "\n",
    "    def best_action(self, s):\n",
    "        action = np.argmax(self.Q[s[0], s[1]])\n",
    "        return action\n",
    "\n",
    "    def save(self, checkpoint_name):\n",
    "        np.savez_compressed(checkpoint_name, Q=self.Q)\n",
    "\n",
    "    def load(self, checkpoint_name):\n",
    "        self.Q = np.load(checkpoint_name +\".npz\" )[\"Q\"]\n",
    "\n",
    "class Policy():\n",
    "\n",
    "    def __init__(self, Q, epsilon=1):\n",
    "        self.Q = Q\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.uniform(0, 1) <= self.epsilon:\n",
    "            return np.random.choice([0, 1, 2, 3])\n",
    "        else:\n",
    "            return self.Q.best_action(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we have to address a different question: when we explore the environment, how should we choose the actions?\n",
    "\n",
    "One approach is to follow a $\\epsilon$-greedy policy, where we choose a random action with probability $\\epsilon$ and the best action according to Q with probability $1-\\epsilon$.\n",
    "\n",
    "For instance, if $\\epsilon=1$, all actions are chosen randomly. For $\\epsilon=0$, all actions are chosen _greedily_.\n",
    "A common practice is to start with $\\epsilon=1$ and decay it to 0 as we generate replays. How fast we decay it is related to the famous _exploration-exploitation_ dilemma in Reinforcement Learning.\n",
    "\n",
    "4.2 **[2 points]** Complete the cell below to generate replays and update `tabular_Q` for `n_episodes`. You're free to choose your own decaying rate for $epsilon$ (including a 0 decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_Q = TabularQ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "919ab5bd9f0fc91f03a2a91712b10806",
     "grade": true,
     "grade_id": "a42",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_episodes = 20\n",
    "greedy_policy = Policy(tabular_Q, epsilon=1.0)\n",
    "decay = 0.995\n",
    "def play(environment, policy):\n",
    "    # Returns one episode's replay and the total accumulated rewards\n",
    "    replay = []\n",
    "    current_state = environment.reset()\n",
    "    game_over = False\n",
    "    total_rewards = 0\n",
    "    while not game_over:\n",
    "        action = policy.act(current_state)\n",
    "        new_state, reward, game_over = environment.step(action)\n",
    "        replay.append((current_state, action, reward, new_state))\n",
    "        current_state = new_state\n",
    "        total_rewards += reward\n",
    "    return replay, total_rewards\n",
    "\n",
    "for _ in range(n_episodes):\n",
    "    # Workspace 4.2\n",
    "    #BEGIN \n",
    "    # code here\n",
    "    #END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's examine how the agent behaves a following random policy vs our Q-learning policy.\n",
    "\n",
    "You should notice that if you run Q-learning multiple times, you might get different policies (different ways to reach the target) : we've mentioned before that $Q^*$ is unique, it's not the case for $\\pi^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = play(environment, Policy(tabular_Q, epsilon=1.0)) # completely random policy\n",
    "tests.save_frames(environment.episode, target_mp4=\"uniform\") # saves the episode to uniform.mp4\n",
    "tests.display_video(\"uniform\") # display uniform.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Hint_ : if trained properly, you should expect \"Best policy reached target after\" < 30 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "episode_length = len(play(environment, Policy(tabular_Q, epsilon=0.0))[0]) # optimal policy\n",
    "tests.save_frames(environment.episode, target_mp4=\"best_tabular\")\n",
    "tests.display_video(\"best_tabular\") # best_tabular.mp4\n",
    "print(\"Best policy reached target after {} steps\".format(episode_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- 4.3 **[1 point]** To get the full credit of the previous questions, you'll have to submit a zip file `q_learning.zip` that includes `uniform.mp4`, `best_tabular.mp4` from previous cells and `best_tabular.npz` from the cell below\n",
    "\n",
    "_Hint_:  If cells ran correctly, the files should appear in the same path as the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tabular_Q.save(\"best_tabular\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "What made the tabular Q-learning more approachable is our knowledge of the state space. Our grid is 16 by 16, so there are 256 states in total (not all of them are accessible, due to the environment restrictions.)\n",
    "\n",
    "In the next Deep Q-learning section, we add randomness to our environment. In our _random_ grid, the target and the agents are randomly located, that yields $256^2 = 65536$ states. Not outside the realm of a tabular Q, but we will try to avoid that.\n",
    "\n",
    "When the grid is _random_, the state is no longer the (x,y) coordinates, but a 16x16 image of the environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random_environment = data.GRID(grid_size=16, random=True, max_time=200)\n",
    "s = random_environment.reset()\n",
    "print(s.shape, s.max(), s.min())\n",
    "plt.imshow(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In Deep Q learning, we model Q as neural network $Q_\\theta$ where $\\theta$ represent the network parameters.\n",
    "The neural network takes the state image as input and outputs a 4-dimensional array $Q(s)$ where $Q(s)_i = Q(s, i) $ for $i\\in[0,1,2,3]$.\n",
    "\n",
    "Given a replay $Replay$, we will call an iteration:\n",
    "- Get the current $Q$ values of the states $s_t$ : `Q_s`\n",
    "- Get the current $Q$ values of the states $s_{t+1}$: `Q_s_p`\n",
    "- Updates the element of `Q_s` following __Bellman__ method (you'll have to use `Q_s_p`, the replay actions and the rewards)\n",
    "- Fit the neural network using the replays states and the computed `Q_s` for a single epoch\n",
    "\n",
    "A single update might consist of several iterations ( do not confuse this with the neural network fit's epoch)\n",
    "\n",
    "We'll be minimizing the objective\n",
    "\\begin{align}\n",
    "    \\mathcal{L}_\\theta(\\text{Replay}) = \\sum_{(s_t, a_t, r_t, s_{t+1}) \\in \\text{Replay}} \\mathcal{L}\\big(Q_{\\theta}(s_t, a_t) - \\big[r_t + \\gamma \\max_a Q_\\theta(s_{t+1}, a) \\big] \\big)\n",
    "\\end{align}\n",
    "where $\\mathcal{L}$ is a loss function.\n",
    "\n",
    "In our implementation, we'll be using `Huber` loss. You're free to change the loss, the learning rate, and the network architecture. The ones provided bellow have been tested, and they're guaranteed to work\n",
    "\n",
    "- 4.4 **[4 points]** Complete `DeepQ.update` to perform _Bellman_ iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d75aac719b448c6fcfcb65d1e8ce7641",
     "grade": true,
     "grade_id": "a44",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "\n",
    "class DeepQ:\n",
    "    def __init__(self, gamma=0.95):\n",
    "        self.neural_net = models.Sequential([layers.InputLayer(input_shape=(16, 16, 3)),\n",
    "                                             data.get_inception_layer(32, 32, 32),\n",
    "                                             layers.Conv2D(64, 2, 2, activation=\"relu\"),\n",
    "                                             data.get_inception_layer(32, 32, 32),\n",
    "                                             layers.Conv2D(128, 2, 2, activation=\"relu\"),\n",
    "                                             layers.Conv2D(256, 2, 2, activation=\"relu\"),\n",
    "                                             layers.Flatten(),\n",
    "                                             layers.Dense(256, activation=\"tanh\"),\n",
    "                                             layers.Dense(512),\n",
    "                                             layers.Dense(4)])  # Do not change the model\n",
    "        optimizer = optimizers.adam_v2.Adam(learning_rate=1e-4)  # You can change the learning rate\n",
    "        self.neural_net.compile(loss=losses.Huber(), optimizer=optimizer)  # You can also change the loss function\n",
    "        self.neural_net.summary()\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def update(self, replay, iterations=2, batch_size=32):\n",
    "        current_states = np.array([r[0] for r in replay])\n",
    "        actions = np.array([r[1] for r in replay])\n",
    "        rewards = np.array([r[2] for r in replay])\n",
    "        next_states = np.array([r[3] for r in replay])\n",
    "\n",
    "        loss = 0\n",
    "        for _ in range(iterations):\n",
    "            # Workspace 4.4\n",
    "            # Todo: predict Q_s and Q_s_p\n",
    "            # Use Q_s_p, actions, rewards to update Q_s and fit self.neural_network for one epoch\n",
    "            Q_s = None\n",
    "            \n",
    "            #BEGIN \n",
    "            # code here\n",
    "            #END\n",
    "            history = self.neural_net.fit(current_states, Q_s, epochs=1, batch_size=batch_size)\n",
    "            loss += history.history[\"loss\"][0]\n",
    "        print(\"Loss:\", loss / iterations)\n",
    "\n",
    "    def best_action(self, s):\n",
    "        # We want to allow some noise in the estimation\n",
    "        q = self.neural_net.predict(s[None, :])[0]\n",
    "        q_max = np.max(q)\n",
    "        possible_actions = np.where(np.abs(q - q_max) < 0.05 * np.std(q))[0]\n",
    "        return np.random.choice(possible_actions)\n",
    "\n",
    "    def checkpoint(self, checkpoint_path):\n",
    "        self.neural_net.save_weights(checkpoint_path)\n",
    "\n",
    "    def load(self, checkpoint_path):\n",
    "        self.neural_net.load_weights(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "deep_Q = DeepQ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Feel free to tweak the training parameters if you think it would improve learning. The provided ones have been tested and they should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "greedy_policy = Policy(deep_Q, epsilon=1.0)\n",
    "# Tweak the next parameters to improve the learning\n",
    "n_episodes = 75\n",
    "steps_per_replay = 8000\n",
    "decay= 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for e in range(n_episodes):\n",
    "    replay = []\n",
    "    episode = []\n",
    "    rewards = 0\n",
    "    pbar = tqdm.notebook.tqdm(desc=\"Generating replay\", total=steps_per_replay)\n",
    "    while len(replay) < steps_per_replay:\n",
    "        rep, rew = play(random_environment, greedy_policy)\n",
    "        episode += random_environment.episode\n",
    "        replay += rep\n",
    "        rewards += rew\n",
    "        pbar.update(len(rep))\n",
    "    pbar.close()\n",
    "    tests.save_frames(episode, \"currently_training\") # save video of last episodes played\n",
    "\n",
    "    print(\"episode\", e + 1,\"/\",n_episodes,\", eps:\", greedy_policy.epsilon, \"total rewards:\", rewards)\n",
    "    deep_Q.update(replay, iterations=4)\n",
    "    greedy_policy.epsilon *= decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4.5 [**1 point**] To be considered for full credit, include `deep_q.mp4` and the `checkpoint` folder in your submitted `q_learning.zip`\n",
    "\n",
    "_Hint_ : if trained properly, you should expect `\"Total rewards over 10 episodes` > 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "short_random_environment = data.GRID(random=True, max_time=100)\n",
    "episodes = []\n",
    "deep_best_policy = Policy(deep_Q, epsilon=0)\n",
    "rewards = 0\n",
    "for _ in tqdm.notebook.tqdm(range(10)):\n",
    "    rewards += play(short_random_environment, deep_best_policy)[1]\n",
    "    episodes += short_random_environment.episode\n",
    "print(\"Total rewards over 10 episodes:\", rewards)\n",
    "tests.save_frames(episodes, \"deep_q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tests.display_video(\"deep_q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "deep_Q.checkpoint(\"checkpoint/deep_q\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
